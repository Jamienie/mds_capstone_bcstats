{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Procedure and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook details the machine learning procedure and results for training a classification model on the BCStats WES Comment data. The purpose of this notebook is to illustrate the details of the code in a digestable format.\n",
    "\n",
    "This analysis notebook best accompanies the [MDS Final Report]() which introduces the problem and more formally describes the methodology and results. To learn how to implement the data on future WES comments see the [WES Classification USAGE]() notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aaronquinton/Documents/UBC-MDS/Capstone/BCstats/DSCI_591_capstone-BCStats'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change working directory to be project root\n",
    "import os\n",
    "#os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "# Custom functions for preprocessing, data preparation, and evaluation\n",
    "from src.data.preprocessing_text import (\n",
    "    clean_text, clean_numbers, replace_typical_misspell, remove_stopwords,\n",
    "    preprocess_for_embed, preprocess_for_bow\n",
    ")\n",
    "\n",
    "from src.features.word_vectors import (\n",
    "    build_vocab, check_coverage, get_average_embeddings\n",
    ")\n",
    "\n",
    "from src.models.eval import theme_results, investigate_results\n",
    "\n",
    "# Functions for preprocessing, data preparation, and evaluation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Training Word embeddings and pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Keras Deep learning functions for LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Conv1D, GlobalAveragePooling1D\n",
    "from keras.layers import GRU, concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# Classification alogrithms\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Read in Data and Embeddings </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Filepaths\n",
    "# Data Files\n",
    "fname_rawdata2018 = \"data/interim/train_2018-qualitative-data.csv\"\n",
    "fname_quant = \"data/processed/tidy_quant_questions.csv\"\n",
    "fname_legend = \"references/data-dictionaries/survey_mc_legend.csv\"\n",
    "\n",
    "# Pre-trained Embeddings\n",
    "fname_fasttext_crawl = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                       \"crawl-300d-2M.vec\"\n",
    "fname_fasttext_wiki = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                      \"wiki-news-300d-1M.vec\"\n",
    "fname_w2v_googlenews = \"./references/pretrained_embeddings.nosync/\" \\\n",
    "                       \"GoogleNews-vectors-negative300.bin\"\n",
    "fname_glove_twitter = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.twitter.27B.200d.w2v.txt\"\n",
    "fname_glove_wiki = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.6B.300d.w2v.txt\"\n",
    "fname_glove_crawl = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.840B.300d.w2v.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "df = pd.read_csv(fname_rawdata2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to load embeddings: 2958.4 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Read in pre-trained embeddings\n",
    "w2v_google_news = KeyedVectors.load_word2vec_format(fname_w2v_googlenews,\n",
    "                                                    binary=True)\n",
    "fasttext_crawl = KeyedVectors.load_word2vec_format(fname_fasttext_crawl,\n",
    "                                                   unicode_errors='ignore')\n",
    "fasttext_wiki = KeyedVectors.load_word2vec_format(fname_fasttext_wiki,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_twitter = KeyedVectors.load_word2vec_format(fname_glove_twitter,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_wiki = KeyedVectors.load_word2vec_format(fname_glove_wiki,\n",
    "                                               unicode_errors='ignore')\n",
    "glove_crawl = KeyedVectors.load_word2vec_format(fname_glove_crawl,\n",
    "                                                unicode_errors='ignore')\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Elapsed time to load embeddings: %.1f s\" % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Preprocessing and Data Preperation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userid = df[['_telkey', '2018 Comment']]\n",
    "df_userid = df_userid.rename(columns = {'_telkey':'USERID'})\n",
    "\n",
    "df = df[['2018 Comment']].join(df.loc[:,'CPD':'OTH'])\n",
    "df = df.rename(columns = {'2018 Comment' : 'comment'})\n",
    "\n",
    "Y = np.array(df.loc[:,\"CPD\":\"OTH\"])\n",
    "\n",
    "themes = df.loc[:,'CPD':'OTH'].columns.tolist()\n",
    "\n",
    "# Split the data\n",
    "df_X_train, df_X_valid, Y_train, Y_valid = train_test_split(\n",
    "        df.comment, Y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958,)\n",
      "(9958, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Quantitative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant = pd.read_csv(fname_quant).query(\"survey_year == 2018\")\n",
    "df_legend = pd.read_csv(fname_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant_train = df_userid.loc[df_X_train.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')\n",
    "\n",
    "df_quant_valid = df_userid.loc[df_X_valid.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_quant = np.array(df_quant_train.iloc[:,3:20])\n",
    "X_valid_quant = np.array(df_quant_valid.iloc[:,3:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean response for that column\n",
    "for i in range(X_train_quant.shape[1]):\n",
    "    mean_replace = np.nanmean(X_train_quant, axis = 0)[i]\n",
    "    X_train_quant[:,i][np.isnan(X_train_quant[:,i])] = mean_replace\n",
    "    X_valid_quant[:,i][np.isnan(X_valid_quant[:,i])] = mean_replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 17)\n",
      "(3320, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_quant.shape)\n",
    "print(X_valid_quant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = preprocess_for_embed(df.comment, 'w2v_base_model')\n",
    "\n",
    "w2v_base_model = Word2Vec(comments, \n",
    "                     size=300, \n",
    "                     window=5, \n",
    "                     min_count=1,\n",
    "                     sg=1, \n",
    "                     negative=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pretrained embeddings\n",
    "embeddings = {'w2v_base_model': w2v_base_model,\n",
    "              'w2v_google_news': w2v_google_news, \n",
    "              'fasttext_crawl': fasttext_crawl,\n",
    "              'fasttext_wiki': fasttext_wiki,\n",
    "              'glove_twitter': glove_twitter,\n",
    "              'glove_wiki': glove_wiki,\n",
    "              'glove_crawl': glove_crawl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Vocab Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13278/13278 [00:00<00:00, 86084.02it/s]\n",
      "100%|██████████| 13673/13673 [00:00<00:00, 40466.79it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88164.98it/s]\n",
      "100%|██████████| 17246/17246 [00:03<00:00, 5679.35it/s] \n",
      "100%|██████████| 13278/13278 [00:00<00:00, 91469.55it/s]\n",
      "100%|██████████| 17500/17500 [00:01<00:00, 10368.71it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88333.35it/s]\n",
      "100%|██████████| 17500/17500 [00:02<00:00, 6214.14it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 90237.65it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4575.48it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 92607.72it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4979.80it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 89359.93it/s]\n",
      "100%|██████████| 17500/17500 [00:06<00:00, 2735.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>vocab_coverage</th>\n",
       "      <th>text_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>0.939870</td>\n",
       "      <td>0.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.953943</td>\n",
       "      <td>0.997412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>0.938514</td>\n",
       "      <td>0.996345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.887954</td>\n",
       "      <td>0.990666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.913479</td>\n",
       "      <td>0.994892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>0.997421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  vocab_coverage  text_coverage\n",
       "0   w2v_base_model        1.000000       1.000000\n",
       "1  w2v_google_news        0.939870       0.996661\n",
       "2   fasttext_crawl        0.953943       0.997412\n",
       "3    fasttext_wiki        0.938514       0.996345\n",
       "4    glove_twitter        0.887954       0.990666\n",
       "5       glove_wiki        0.913479       0.994892\n",
       "6      glove_crawl        0.953543       0.997421"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage of vocab words in embedding\n",
    "oov = {}\n",
    "vocab_coverage = []\n",
    "text_coverage = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    comments = preprocess_for_embed(df.comment, embedding)\n",
    "    vocab = build_vocab(comments)\n",
    "        \n",
    "    a, b, oov[embedding] = check_coverage(vocab, embeddings[embedding])\n",
    "    \n",
    "    vocab_coverage.append(a)\n",
    "    text_coverage.append(b)\n",
    "\n",
    "pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "              'vocab_coverage': vocab_coverage, \n",
    "              'text_coverage': text_coverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_base_model\n",
      "[]\n",
      "w2v_google_news\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('BCWS', 23)]\n",
      "fasttext_crawl\n",
      "[('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32)]\n",
      "fasttext_wiki\n",
      "[('MCFD', 128), ('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33)]\n",
      "glove_twitter\n",
      "[('2', 402), ('1', 302), ('3', 236), ('4', 171), ('5', 151)]\n",
      "glove_wiki\n",
      "[('####', 181), ('mcfd', 131), ('cymh', 54), ('#####', 49), ('bcts', 37)]\n",
      "glove_crawl\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('STIIP', 20)]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the out of vocab words for each embedding\n",
    "for i in oov.keys():\n",
    "    print(i)\n",
    "    print(oov[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Feature Engineering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Count Vectorizer to build bag of word arrays to train on\n",
    "vectorizer = CountVectorizer(stop_words= 'english',\n",
    "                             ngram_range=(1,5), \n",
    "                             min_df=2)   \n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(preprocess_for_bow(df_X_train))\n",
    "X_valid_bow = vectorizer.transform(preprocess_for_bow(df_X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 31422)\n",
      "(3320, 31422)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_valid_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Average Word Vectors per Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_avg_wv = {}\n",
    "X_valid_avg_wv = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    # Adjust features based on twitter embeddings \n",
    "    if embedding == 'glove_twitter':\n",
    "        n_features = 200\n",
    "    else:\n",
    "        n_features = 300\n",
    "    \n",
    "    # Preprocess comment data\n",
    "    comments_train = preprocess_for_embed(df_X_train, embedding)\n",
    "    comments_valid = preprocess_for_embed(df_X_valid, embedding)\n",
    "    \n",
    "    # Get average embeddings for each comment\n",
    "    # train\n",
    "    X_train_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_train])\n",
    "    \n",
    "    # valid\n",
    "    X_valid_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 300)\n",
      "(3320, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_avg_wv['w2v_base_model'].shape)\n",
    "print(X_valid_avg_wv['glove_twitter'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Classification Models </span>\n",
    "### Baseline Classifier - BOW | Linear SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyper Parameters for BOW | Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.02, 0.1, 0.5, 2.5, 12.5, 1]\n",
      "tol: [8e-05, 0.0004, 0.002, 0.01, 0.05, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for BOW | Linear SVC\n",
      "{'classifier': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=2000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.05,\n",
      "     verbose=0), 'classifier__C': 0.5, 'classifier__tol': 0.05} 0.4243824061056437\n",
      "Elapsed Training time: 5454.6 s \n",
      "Elapsed Predict time: 0.1 s\n"
     ]
    }
   ],
   "source": [
    "# t_start = time.time()\n",
    "# print(\"Grid Search for BOW | Linear SVC\")\n",
    "\n",
    "# parameters = [\n",
    "#     {\n",
    "#         'classifier':[LinearSVC(max_iter=2000)],\n",
    "#         'classifier__tol': tol,\n",
    "#         'classifier__C': C,    \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# clf1 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "# clf1.fit(X_train_bow, Y_train)\n",
    "\n",
    "# t_end_train = time.time()\n",
    "\n",
    "# print(clf1.best_params_, clf1.best_score_)\n",
    "# # Calculate and print elapsed time\n",
    "# t_end = time.time()\n",
    "# print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final BOW | Linear SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bag of words Model with Linear SVC\n",
      "Elapsed Training time: 71.4 s \n",
      "Elapsed Predict time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Training Bag of words Model with Linear SVC\")\n",
    "\n",
    "model_bow = BinaryRelevance(\n",
    "    classifier = LinearSVC(C = 0.5, tol = 0.2)\n",
    ")\n",
    "\n",
    "model_bow.fit(X_train_bow, Y_train)\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_bow = model_bow.predict(X_valid_bow).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bow = pd.DataFrame({'Model': 'BOW | LinearSVC',\n",
    "                            'train_time': [71.4],\n",
    "                            'predict_time': [13.1],\n",
    "                            'overall_accuracy': [metrics.accuracy_score(Y_valid, \n",
    "                                                                       Y_pred_bow)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4512 \n",
      "Hamming Loss: 0.0721 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.112048</td>\n",
       "      <td>0.073193</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.926807</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.652482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.174096</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>0.141566</td>\n",
       "      <td>0.956928</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.854812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.932229</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.432143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.089157</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.918675</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.538012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.974096</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.082229</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.934036</td>\n",
       "      <td>0.684982</td>\n",
       "      <td>0.584375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.426056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.111145</td>\n",
       "      <td>0.105723</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>0.598916</td>\n",
       "      <td>0.521226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.134639</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.884940</td>\n",
       "      <td>0.689038</td>\n",
       "      <td>0.558984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.211145</td>\n",
       "      <td>0.071687</td>\n",
       "      <td>0.156928</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>0.871612</td>\n",
       "      <td>0.805007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.113855</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.112048  0.073193    0.054217  0.926807   \n",
       "1     CB      0.184639         0.174096  0.043072    0.141566  0.956928   \n",
       "2    EWC      0.084337         0.056325  0.067771    0.016566  0.932229   \n",
       "3   Exec      0.103012         0.089157  0.081325    0.021687  0.918675   \n",
       "4    FWE      0.062048         0.054217  0.025904    0.036145  0.974096   \n",
       "5     SP      0.096386         0.082229  0.065964    0.030422  0.934036   \n",
       "6     RE      0.085542         0.062952  0.075602    0.009940  0.924398   \n",
       "7    Sup      0.127711         0.111145  0.105723    0.021988  0.894277   \n",
       "8     SW      0.165964         0.134639  0.115060    0.050904  0.884940   \n",
       "9   TEPE      0.228614         0.211145  0.071687    0.156928  0.928313   \n",
       "10   VMG      0.135542         0.108434  0.113855    0.021687  0.886145   \n",
       "11   OTH      0.027711         0.017470  0.026506    0.001205  0.973494   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.741935  0.652482  \n",
       "1    0.906574  0.854812  \n",
       "2    0.647059  0.432143  \n",
       "3    0.621622  0.538012  \n",
       "4    0.833333  0.728155  \n",
       "5    0.684982  0.584375  \n",
       "6    0.578947  0.426056  \n",
       "7    0.598916  0.521226  \n",
       "8    0.689038  0.558984  \n",
       "9    0.871612  0.805007  \n",
       "10   0.600000  0.480000  \n",
       "11   0.534483  0.336957  "
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, Y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_pred: (3320, 12)\n",
      "Zeros predicted: (466, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_pred:\",Y_pred_bow.shape)\n",
    "print(\"Zeros predicted:\",Y_pred_bow[Y_pred_bow.sum(axis = 1) == 0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Vectors | LogReg SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyperparameters for Avg WV | LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding in embeddings.keys():\n",
    "    \n",
    "#     print(\"Grid Search on: \", embedding)\n",
    "#     t_start = time.time()\n",
    "\n",
    "#     parameters = [\n",
    "#         {\n",
    "#             'classifier':[LogisticRegression(solver = 'lbfgs', max_iter=500)],\n",
    "#             'classifier__tol': tol,\n",
    "#             'classifier__C': C,\n",
    "        \n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     clf2 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "#     clf2.fit(X_train_avg_wv[embedding], Y_train)\n",
    "\n",
    "#     t_end_train = time.time()\n",
    "\n",
    "#     print(clf2.best_params_, clf2.best_score_)\n",
    "#     # Calculate and print elapsed time\n",
    "#     t_end = time.time()\n",
    "#     print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Avg WV | LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>6.191823</td>\n",
       "      <td>0.065399</td>\n",
       "      <td>0.360843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4.602850</td>\n",
       "      <td>0.222380</td>\n",
       "      <td>0.406325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>5.089044</td>\n",
       "      <td>0.190777</td>\n",
       "      <td>0.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4.718872</td>\n",
       "      <td>0.276683</td>\n",
       "      <td>0.398795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>7.091348</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>9.596981</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>8.432222</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.409337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model    6.191823      0.065399          0.360843\n",
       "1  w2v_google_news    4.602850      0.222380          0.406325\n",
       "2   fasttext_crawl    5.089044      0.190777          0.421687\n",
       "3    fasttext_wiki    4.718872      0.276683          0.398795\n",
       "4    glove_twitter    7.091348      0.339133          0.354217\n",
       "5       glove_wiki    9.596981      0.359630          0.406024\n",
       "6      glove_crawl    8.432222      0.280792          0.409337"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_avg_wv = {}\n",
    "model_avg_wv = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "\n",
    "    clf = BinaryRelevance(\n",
    "        classifier = LogisticRegression(solver = 'lbfgs', max_iter=500, C = 7.5,\n",
    "                                        tol = 0.05)\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_avg_wv[embedding], Y_train)\n",
    "    t_end_train = time.time()\n",
    "\n",
    "    Y_pred_avg_wv[embedding] = clf.predict_proba(X_valid_avg_wv[embedding]) \\\n",
    "                                  .toarray()\n",
    "    model_avg_wv[embedding] = clf\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_avg_wv[embedding])))\n",
    "\n",
    "results_avg_wv = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                               'train_time': train_time,\n",
    "                               'predict_time': predict_time,\n",
    "                               'overall_accuracy': accuarcies})\n",
    "\n",
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Build Embedding Matrices and prepare data for deep \n",
    "# learning Models\n",
    "max_words = 12000\n",
    "maxlen = 700\n",
    "\n",
    "# dictionaries for each embedding\n",
    "embedding_matrix = {}\n",
    "tokenizer = {}\n",
    "X_train_lstm = {}\n",
    "X_valid_lstm = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "\n",
    "    # Preprocess text data based on embedding\n",
    "    X_train = np.array(preprocess_for_embed(df_X_train,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    X_valid = np.array(preprocess_for_embed(df_X_valid,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    # Tokenize and pad numbers for LSTM Model\n",
    "    tokenizer[embedding] = Tokenizer(num_words=max_words)\n",
    "    tokenizer[embedding].fit_on_texts(X_train)\n",
    "    \n",
    "    tokenized_train = tokenizer[embedding].texts_to_sequences(X_train)\n",
    "    tokenized_test = tokenizer[embedding].texts_to_sequences(X_valid)\n",
    "\n",
    "    X_train_lstm[embedding] = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "    X_valid_lstm[embedding] = pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "    \n",
    "    \n",
    "    # Build Embedding Matrices\n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "\n",
    "    word_index = tokenizer[embedding].word_index\n",
    "    \n",
    "    num_words = min(max_words, len(word_index) + 1)\n",
    "    embedding_matrix[embedding] = np.zeros((num_words, embed_size),\n",
    "                                           dtype='float32')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "\n",
    "        if i >= max_words:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embedding_vector = embeddings[embedding][word]\n",
    "\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[embedding][i] = embedding_vector\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM on the  w2v_base_model\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 366s 37ms/step - loss: 0.3358 - acc: 0.8864 - val_loss: 0.2613 - val_acc: 0.9042\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 344s 35ms/step - loss: 0.2441 - acc: 0.9103 - val_loss: 0.2177 - val_acc: 0.9189\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 345s 35ms/step - loss: 0.2159 - acc: 0.9196 - val_loss: 0.2066 - val_acc: 0.9223\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 338s 34ms/step - loss: 0.2029 - acc: 0.9239 - val_loss: 0.1973 - val_acc: 0.9254\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 331s 33ms/step - loss: 0.1956 - acc: 0.9262 - val_loss: 0.1930 - val_acc: 0.9269\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 328s 33ms/step - loss: 0.1880 - acc: 0.9295 - val_loss: 0.1898 - val_acc: 0.9280\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 344s 35ms/step - loss: 0.1827 - acc: 0.9310 - val_loss: 0.1878 - val_acc: 0.9287\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 341s 34ms/step - loss: 0.1779 - acc: 0.9323 - val_loss: 0.1854 - val_acc: 0.9285\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 334s 34ms/step - loss: 0.1741 - acc: 0.9335 - val_loss: 0.1839 - val_acc: 0.9301\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 339s 34ms/step - loss: 0.1686 - acc: 0.9360 - val_loss: 0.1813 - val_acc: 0.9306\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 331s 33ms/step - loss: 0.1644 - acc: 0.9375 - val_loss: 0.1830 - val_acc: 0.9310\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 426s 43ms/step - loss: 0.1600 - acc: 0.9393 - val_loss: 0.1801 - val_acc: 0.9318\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 303s 30ms/step - loss: 0.1552 - acc: 0.9405 - val_loss: 0.1819 - val_acc: 0.9311\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 303s 30ms/step - loss: 0.1519 - acc: 0.9422 - val_loss: 0.1813 - val_acc: 0.9312\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1474 - acc: 0.9437 - val_loss: 0.1810 - val_acc: 0.9314\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1439 - acc: 0.9452 - val_loss: 0.1819 - val_acc: 0.9323\n",
      "Training LSTM on the  w2v_google_news\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 313s 31ms/step - loss: 0.3628 - acc: 0.8784 - val_loss: 0.2793 - val_acc: 0.9030\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 302s 30ms/step - loss: 0.2501 - acc: 0.9104 - val_loss: 0.2181 - val_acc: 0.9183\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.2147 - acc: 0.9203 - val_loss: 0.2019 - val_acc: 0.9238\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.1971 - acc: 0.9260 - val_loss: 0.1926 - val_acc: 0.9283\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1841 - acc: 0.9306 - val_loss: 0.1825 - val_acc: 0.9308\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.1731 - acc: 0.9345 - val_loss: 0.1786 - val_acc: 0.9335\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.1653 - acc: 0.9376 - val_loss: 0.1741 - val_acc: 0.9345\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.1588 - acc: 0.9397 - val_loss: 0.1718 - val_acc: 0.9346\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1513 - acc: 0.9422 - val_loss: 0.1701 - val_acc: 0.9354\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.1462 - acc: 0.9438 - val_loss: 0.1686 - val_acc: 0.9355\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1397 - acc: 0.9465 - val_loss: 0.1677 - val_acc: 0.9365\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1351 - acc: 0.9484 - val_loss: 0.1671 - val_acc: 0.9372\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1295 - acc: 0.9507 - val_loss: 0.1690 - val_acc: 0.9358\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1250 - acc: 0.9525 - val_loss: 0.1700 - val_acc: 0.9362\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1191 - acc: 0.9539 - val_loss: 0.1701 - val_acc: 0.9369\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1138 - acc: 0.9565 - val_loss: 0.1712 - val_acc: 0.9348\n",
      "Training LSTM on the  fasttext_crawl\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 307s 31ms/step - loss: 0.3515 - acc: 0.8804 - val_loss: 0.2609 - val_acc: 0.9059\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.2326 - acc: 0.9148 - val_loss: 0.2055 - val_acc: 0.9250\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 292s 29ms/step - loss: 0.1960 - acc: 0.9262 - val_loss: 0.1852 - val_acc: 0.9313\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1784 - acc: 0.9325 - val_loss: 0.1767 - val_acc: 0.9334\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1650 - acc: 0.9373 - val_loss: 0.1693 - val_acc: 0.9356\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 293s 29ms/step - loss: 0.1555 - acc: 0.9407 - val_loss: 0.1645 - val_acc: 0.9379\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 292s 29ms/step - loss: 0.1466 - acc: 0.9431 - val_loss: 0.1655 - val_acc: 0.9365\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1391 - acc: 0.9464 - val_loss: 0.1619 - val_acc: 0.9390\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1324 - acc: 0.9485 - val_loss: 0.1668 - val_acc: 0.9372\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.1263 - acc: 0.9515 - val_loss: 0.1646 - val_acc: 0.9380\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1194 - acc: 0.9534 - val_loss: 0.1661 - val_acc: 0.9371\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1129 - acc: 0.9562 - val_loss: 0.1654 - val_acc: 0.9382\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1068 - acc: 0.9594 - val_loss: 0.1693 - val_acc: 0.9386\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1002 - acc: 0.9619 - val_loss: 0.1697 - val_acc: 0.9377\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.0943 - acc: 0.9639 - val_loss: 0.1685 - val_acc: 0.9387\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.0886 - acc: 0.9665 - val_loss: 0.1747 - val_acc: 0.9363\n",
      "Training LSTM on the  fasttext_wiki\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 323s 32ms/step - loss: 0.3823 - acc: 0.8651 - val_loss: 0.3001 - val_acc: 0.8934\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 299s 30ms/step - loss: 0.2654 - acc: 0.9054 - val_loss: 0.2310 - val_acc: 0.9152\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.2229 - acc: 0.9169 - val_loss: 0.2041 - val_acc: 0.9223\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.2010 - acc: 0.9242 - val_loss: 0.1895 - val_acc: 0.9290\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 299s 30ms/step - loss: 0.1882 - acc: 0.9289 - val_loss: 0.1829 - val_acc: 0.9307\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1759 - acc: 0.9338 - val_loss: 0.1766 - val_acc: 0.9339\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1683 - acc: 0.9360 - val_loss: 0.1732 - val_acc: 0.9350\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1618 - acc: 0.9381 - val_loss: 0.1704 - val_acc: 0.9354\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1560 - acc: 0.9400 - val_loss: 0.1655 - val_acc: 0.9367\n",
      "Epoch 10/16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1507 - acc: 0.9423 - val_loss: 0.1671 - val_acc: 0.9364\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1463 - acc: 0.9439 - val_loss: 0.1675 - val_acc: 0.9367\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1411 - acc: 0.9458 - val_loss: 0.1644 - val_acc: 0.9376\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1371 - acc: 0.9475 - val_loss: 0.1653 - val_acc: 0.9373\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1320 - acc: 0.9491 - val_loss: 0.1641 - val_acc: 0.9376\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1284 - acc: 0.9510 - val_loss: 0.1637 - val_acc: 0.9372\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 294s 30ms/step - loss: 0.1248 - acc: 0.9522 - val_loss: 0.1677 - val_acc: 0.9372\n",
      "Training LSTM on the  glove_twitter\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 260s 26ms/step - loss: 0.3600 - acc: 0.8732 - val_loss: 0.2841 - val_acc: 0.9020\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 244s 25ms/step - loss: 0.2602 - acc: 0.9064 - val_loss: 0.2307 - val_acc: 0.9163\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 246s 25ms/step - loss: 0.2239 - acc: 0.9173 - val_loss: 0.2106 - val_acc: 0.9225\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 248s 25ms/step - loss: 0.2014 - acc: 0.9252 - val_loss: 0.1969 - val_acc: 0.9273\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1884 - acc: 0.9302 - val_loss: 0.1898 - val_acc: 0.9298\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1759 - acc: 0.9339 - val_loss: 0.1851 - val_acc: 0.9304\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1650 - acc: 0.9377 - val_loss: 0.1853 - val_acc: 0.9315\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1572 - acc: 0.9407 - val_loss: 0.1793 - val_acc: 0.9339\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 244s 24ms/step - loss: 0.1475 - acc: 0.9444 - val_loss: 0.1820 - val_acc: 0.9330\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1405 - acc: 0.9465 - val_loss: 0.1780 - val_acc: 0.9347\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 249s 25ms/step - loss: 0.1313 - acc: 0.9499 - val_loss: 0.1817 - val_acc: 0.9331\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 247s 25ms/step - loss: 0.1251 - acc: 0.9525 - val_loss: 0.1805 - val_acc: 0.9346\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1172 - acc: 0.9550 - val_loss: 0.1810 - val_acc: 0.9337\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.1092 - acc: 0.9590 - val_loss: 0.1833 - val_acc: 0.9348\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 246s 25ms/step - loss: 0.1021 - acc: 0.9614 - val_loss: 0.1942 - val_acc: 0.9309\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 245s 25ms/step - loss: 0.0966 - acc: 0.9640 - val_loss: 0.1899 - val_acc: 0.9338\n",
      "Training LSTM on the  glove_wiki\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 310s 31ms/step - loss: 0.3513 - acc: 0.8773 - val_loss: 0.2717 - val_acc: 0.9057\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.2452 - acc: 0.9112 - val_loss: 0.2152 - val_acc: 0.9206\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.2063 - acc: 0.9231 - val_loss: 0.1934 - val_acc: 0.9282\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1857 - acc: 0.9299 - val_loss: 0.1858 - val_acc: 0.9314\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1712 - acc: 0.9355 - val_loss: 0.1783 - val_acc: 0.9319\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1590 - acc: 0.9400 - val_loss: 0.1763 - val_acc: 0.9327\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1492 - acc: 0.9436 - val_loss: 0.1772 - val_acc: 0.9332\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1392 - acc: 0.9468 - val_loss: 0.1733 - val_acc: 0.9342\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 296s 30ms/step - loss: 0.1291 - acc: 0.9502 - val_loss: 0.1725 - val_acc: 0.9352\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1205 - acc: 0.9538 - val_loss: 0.1748 - val_acc: 0.9352\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 295s 30ms/step - loss: 0.1111 - acc: 0.9582 - val_loss: 0.1759 - val_acc: 0.9349\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 304s 31ms/step - loss: 0.1024 - acc: 0.9612 - val_loss: 0.1789 - val_acc: 0.9338\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.0941 - acc: 0.9648 - val_loss: 0.1832 - val_acc: 0.9345\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.0864 - acc: 0.9677 - val_loss: 0.1869 - val_acc: 0.9342\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.0780 - acc: 0.9714 - val_loss: 0.1895 - val_acc: 0.9338\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.0703 - acc: 0.9749 - val_loss: 0.1959 - val_acc: 0.9332\n",
      "Training LSTM on the  glove_crawl\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/16\n",
      "9958/9958 [==============================] - 307s 31ms/step - loss: 0.3547 - acc: 0.8756 - val_loss: 0.2701 - val_acc: 0.9041\n",
      "Epoch 2/16\n",
      "9958/9958 [==============================] - 299s 30ms/step - loss: 0.2433 - acc: 0.9106 - val_loss: 0.2164 - val_acc: 0.9186\n",
      "Epoch 3/16\n",
      "9958/9958 [==============================] - 298s 30ms/step - loss: 0.2044 - acc: 0.9236 - val_loss: 0.1943 - val_acc: 0.9279\n",
      "Epoch 4/16\n",
      "9958/9958 [==============================] - 297s 30ms/step - loss: 0.1828 - acc: 0.9311 - val_loss: 0.1835 - val_acc: 0.9314\n",
      "Epoch 5/16\n",
      "9958/9958 [==============================] - 325s 33ms/step - loss: 0.1679 - acc: 0.9362 - val_loss: 0.1762 - val_acc: 0.9330\n",
      "Epoch 6/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1576 - acc: 0.9402 - val_loss: 0.1727 - val_acc: 0.9341\n",
      "Epoch 7/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1465 - acc: 0.9445 - val_loss: 0.1704 - val_acc: 0.9354\n",
      "Epoch 8/16\n",
      "9958/9958 [==============================] - 302s 30ms/step - loss: 0.1372 - acc: 0.9470 - val_loss: 0.1730 - val_acc: 0.9346\n",
      "Epoch 9/16\n",
      "9958/9958 [==============================] - 304s 31ms/step - loss: 0.1287 - acc: 0.9508 - val_loss: 0.1716 - val_acc: 0.9352\n",
      "Epoch 10/16\n",
      "9958/9958 [==============================] - 299s 30ms/step - loss: 0.1210 - acc: 0.9541 - val_loss: 0.1704 - val_acc: 0.9364\n",
      "Epoch 11/16\n",
      "9958/9958 [==============================] - 301s 30ms/step - loss: 0.1130 - acc: 0.9570 - val_loss: 0.1714 - val_acc: 0.9367\n",
      "Epoch 12/16\n",
      "9958/9958 [==============================] - 303s 30ms/step - loss: 0.1041 - acc: 0.9603 - val_loss: 0.1741 - val_acc: 0.9376\n",
      "Epoch 13/16\n",
      "9958/9958 [==============================] - 299s 30ms/step - loss: 0.0969 - acc: 0.9638 - val_loss: 0.1752 - val_acc: 0.9366\n",
      "Epoch 14/16\n",
      "9958/9958 [==============================] - 304s 31ms/step - loss: 0.0891 - acc: 0.9668 - val_loss: 0.1789 - val_acc: 0.9353\n",
      "Epoch 15/16\n",
      "9958/9958 [==============================] - 300s 30ms/step - loss: 0.0823 - acc: 0.9693 - val_loss: 0.1849 - val_acc: 0.9356\n",
      "Epoch 16/16\n",
      "9958/9958 [==============================] - 305s 31ms/step - loss: 0.0745 - acc: 0.9723 - val_loss: 0.1898 - val_acc: 0.9368\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model and train and validate\n",
    "Y_pred_lstm = {}\n",
    "model_lstm = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "    print(\"Training LSTM on the \", embedding)\n",
    "    \n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "    \n",
    "    # Deep Learning Architecture\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(max_words, embed_size, \n",
    "                  weights=[embedding_matrix[embedding]], \n",
    "                  trainable=False)(inp)\n",
    "\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1,\n",
    "                          recurrent_dropout=0.1))(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, padding=\"valid\", \n",
    "               kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    preds = Dense(12, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train and Predict Model\n",
    "    batch_size = 128\n",
    "    epochs = 16\n",
    "    model.fit(X_train_lstm[embedding],\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, \n",
    "              validation_data = (X_valid_lstm[embedding],\n",
    "                                 Y_valid))\n",
    "    t_end_train = time.time()\n",
    "    \n",
    "    Y_pred_lstm[embedding] = model.predict(X_valid_lstm[embedding])\n",
    "    model_lstm[embedding] = model\n",
    "\n",
    "    # Calculate and report results\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_lstm[embedding])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>5403.565991</td>\n",
       "      <td>51.442252</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4783.540461</td>\n",
       "      <td>44.722496</td>\n",
       "      <td>0.498795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>4740.266720</td>\n",
       "      <td>44.296958</td>\n",
       "      <td>0.510542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>5182.704977</td>\n",
       "      <td>45.970474</td>\n",
       "      <td>0.506928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>3965.183014</td>\n",
       "      <td>35.402969</td>\n",
       "      <td>0.489157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>4786.450105</td>\n",
       "      <td>46.403053</td>\n",
       "      <td>0.495181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>4865.703469</td>\n",
       "      <td>52.608429</td>\n",
       "      <td>0.515361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  5403.565991     51.442252          0.475000\n",
       "1  w2v_google_news  4783.540461     44.722496          0.498795\n",
       "2   fasttext_crawl  4740.266720     44.296958          0.510542\n",
       "3    fasttext_wiki  5182.704977     45.970474          0.506928\n",
       "4    glove_twitter  3965.183014     35.402969          0.489157\n",
       "5       glove_wiki  4786.450105     46.403053          0.495181\n",
       "6      glove_crawl  4865.703469     52.608429          0.515361"
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lstm = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                             'train_time': train_time,\n",
    "                             'predict_time': predict_time,\n",
    "                             'overall_accuracy': accuarcies})\n",
    "\n",
    "results_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5075 \n",
      "Hamming Loss: 0.0631 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.124699</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.935843</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.737589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.178614</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.149699</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.919056</td>\n",
       "      <td>0.889070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.062349</td>\n",
       "      <td>0.058735</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.705314</td>\n",
       "      <td>0.521429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.105120</td>\n",
       "      <td>0.076205</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.627507</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.047289</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>0.885350</td>\n",
       "      <td>0.674757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.088253</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>0.703072</td>\n",
       "      <td>0.643750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.077108</td>\n",
       "      <td>0.072892</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.927108</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.524648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.109940</td>\n",
       "      <td>0.094880</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.905120</td>\n",
       "      <td>0.649315</td>\n",
       "      <td>0.558962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.136145</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.906325</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.627949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.214759</td>\n",
       "      <td>0.056024</td>\n",
       "      <td>0.172590</td>\n",
       "      <td>0.943976</td>\n",
       "      <td>0.901823</td>\n",
       "      <td>0.847167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.126807</td>\n",
       "      <td>0.096084</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>0.903916</td>\n",
       "      <td>0.655582</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.976506</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.124699  0.064157    0.063253  0.935843   \n",
       "1     CB      0.184639         0.178614  0.034940    0.149699  0.965060   \n",
       "2    EWC      0.084337         0.062349  0.058735    0.025602  0.941265   \n",
       "3   Exec      0.103012         0.105120  0.076205    0.026807  0.923795   \n",
       "4    FWE      0.062048         0.047289  0.025602    0.036446  0.974398   \n",
       "5     SP      0.096386         0.088253  0.060542    0.035843  0.939458   \n",
       "6     RE      0.085542         0.077108  0.072892    0.012651  0.927108   \n",
       "7    Sup      0.127711         0.109940  0.094880    0.032831  0.905120   \n",
       "8     SW      0.165964         0.136145  0.093675    0.072289  0.906325   \n",
       "9   TEPE      0.228614         0.214759  0.056024    0.172590  0.943976   \n",
       "10   VMG      0.135542         0.126807  0.096084    0.039458  0.903916   \n",
       "11   OTH      0.027711         0.009036  0.023494    0.004217  0.976506   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.753623  0.737589  \n",
       "1    0.919056  0.889070  \n",
       "2    0.705314  0.521429  \n",
       "3    0.627507  0.640351  \n",
       "4    0.885350  0.674757  \n",
       "5    0.703072  0.643750  \n",
       "6    0.582031  0.524648  \n",
       "7    0.649315  0.558962  \n",
       "8    0.765487  0.627949  \n",
       "9    0.901823  0.847167  \n",
       "10   0.655582  0.613333  \n",
       "11   0.733333  0.239130  "
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_lstm['fasttext_crawl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOW | LinearSVC</td>\n",
       "      <td>71.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.451205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  train_time  predict_time  overall_accuracy\n",
       "0  BOW | LinearSVC        71.4          13.1          0.451205"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>6.191823</td>\n",
       "      <td>0.065399</td>\n",
       "      <td>0.360843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4.602850</td>\n",
       "      <td>0.222380</td>\n",
       "      <td>0.406325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>5.089044</td>\n",
       "      <td>0.190777</td>\n",
       "      <td>0.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4.718872</td>\n",
       "      <td>0.276683</td>\n",
       "      <td>0.398795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>7.091348</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>9.596981</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>8.432222</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.409337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model    6.191823      0.065399          0.360843\n",
       "1  w2v_google_news    4.602850      0.222380          0.406325\n",
       "2   fasttext_crawl    5.089044      0.190777          0.421687\n",
       "3    fasttext_wiki    4.718872      0.276683          0.398795\n",
       "4    glove_twitter    7.091348      0.339133          0.354217\n",
       "5       glove_wiki    9.596981      0.359630          0.406024\n",
       "6      glove_crawl    8.432222      0.280792          0.409337"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>3879.478145</td>\n",
       "      <td>50.835208</td>\n",
       "      <td>0.463253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>3545.128112</td>\n",
       "      <td>50.347810</td>\n",
       "      <td>0.502108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>3841.778025</td>\n",
       "      <td>57.008378</td>\n",
       "      <td>0.507530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>3767.888280</td>\n",
       "      <td>53.533103</td>\n",
       "      <td>0.490060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>2847.951580</td>\n",
       "      <td>40.823633</td>\n",
       "      <td>0.488855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>3199.954429</td>\n",
       "      <td>46.572131</td>\n",
       "      <td>0.498795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>3316.253327</td>\n",
       "      <td>51.455602</td>\n",
       "      <td>0.507530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  3879.478145     50.835208          0.463253\n",
       "1  w2v_google_news  3545.128112     50.347810          0.502108\n",
       "2   fasttext_crawl  3841.778025     57.008378          0.507530\n",
       "3    fasttext_wiki  3767.888280     53.533103          0.490060\n",
       "4    glove_twitter  2847.951580     40.823633          0.488855\n",
       "5       glove_wiki  3199.954429     46.572131          0.498795\n",
       "6      glove_crawl  3316.253327     51.455602          0.507530"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_stack = (Y_pred_lstm['fasttext_crawl'] +\n",
    "                Y_pred_lstm['glove_crawl'] +\n",
    "                Y_pred_lstm['glove_wiki'] +\n",
    "                Y_pred_lstm['w2v_google_news'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5386 \n",
      "Hamming Loss: 0.0588 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.113855</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.709220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.178012</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.149699</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.887439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.098795</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.930120</td>\n",
       "      <td>0.667683</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.041867</td>\n",
       "      <td>0.979819</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.771845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.940060</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.937048</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.517606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>0.083735</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.916265</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.584906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.090060</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.909940</td>\n",
       "      <td>0.761411</td>\n",
       "      <td>0.666062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.223494</td>\n",
       "      <td>0.050301</td>\n",
       "      <td>0.178313</td>\n",
       "      <td>0.949699</td>\n",
       "      <td>0.898922</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.110241</td>\n",
       "      <td>0.089157</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>0.910843</td>\n",
       "      <td>0.710383</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.976506</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.271739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.113855  0.060542    0.066867  0.939458   \n",
       "1     CB      0.184639         0.178012  0.034940    0.149699  0.965060   \n",
       "2    EWC      0.084337         0.044880  0.060542    0.023795  0.939458   \n",
       "3   Exec      0.103012         0.098795  0.069880    0.033133  0.930120   \n",
       "4    FWE      0.062048         0.053916  0.020181    0.041867  0.979819   \n",
       "5     SP      0.096386         0.087048  0.059940    0.036446  0.940060   \n",
       "6     RE      0.085542         0.065964  0.062952    0.022590  0.937048   \n",
       "7    Sup      0.127711         0.105422  0.083735    0.043976  0.916265   \n",
       "8     SW      0.165964         0.145181  0.090060    0.075904  0.909940   \n",
       "9   TEPE      0.228614         0.223494  0.050301    0.178313  0.949699   \n",
       "10   VMG      0.135542         0.110241  0.089157    0.046386  0.910843   \n",
       "11   OTH      0.027711         0.010843  0.023494    0.004217  0.976506   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.793651  0.709220  \n",
       "1    0.920474  0.887439  \n",
       "2    0.765101  0.407143  \n",
       "3    0.667683  0.640351  \n",
       "4    0.888268  0.771845  \n",
       "5    0.709343  0.640625  \n",
       "6    0.671233  0.517606  \n",
       "7    0.708571  0.584906  \n",
       "8    0.761411  0.666062  \n",
       "9    0.898922  0.878788  \n",
       "10   0.710383  0.577778  \n",
       "11   0.694444  0.271739  "
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the Precision! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "prob_adj = []\n",
    "non_zero_percent = []\n",
    "\n",
    "for i in np.arange(-0.49,0.5,0.01):\n",
    "    \n",
    "    prob_adj.append(min((0.5 + i),1))\n",
    "    predictions = np.round(Y_pred_stack - i)\n",
    "    \n",
    "    size = predictions.shape[0]\n",
    "    zero_size = (predictions[predictions.sum(axis = 1) == 0,:].shape[0])\n",
    "    \n",
    "    non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "    non_zero_valid = Y_valid[predictions.sum(axis = 1) != 0,:]\n",
    "    \n",
    "    accuracy.append(metrics.accuracy_score(non_zero_valid, non_zero_pred))\n",
    "    non_zero_percent.append(round(1 - zero_size/size, 4))\n",
    "\n",
    "results_tradeoff = pd.DataFrame({'prob_adj': prob_adj,\n",
    "                                 'accuracy':accuracy,\n",
    "                                 'non_zero_percent':non_zero_percent})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = results_tradeoff.plot.scatter(x = 'non_zero_percent',\n",
    "                              y = 'accuracy',\n",
    "                              c = 'prob_adj')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5386 \n",
      "Hamming Loss: 0.0588 \n",
      "Hamming Loss (pred. zeros): 0.1191\n",
      "Total comments: 3320 \n",
      "Total Predictions: 3042 \n",
      "Percent Pred non-zero: 0.9163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.113855</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.709220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.178012</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.149699</td>\n",
       "      <td>0.965060</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.887439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.060542</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.939458</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.098795</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.033133</td>\n",
       "      <td>0.930120</td>\n",
       "      <td>0.667683</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.041867</td>\n",
       "      <td>0.979819</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.771845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.940060</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.937048</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.517606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>0.083735</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.916265</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.584906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.145181</td>\n",
       "      <td>0.090060</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.909940</td>\n",
       "      <td>0.761411</td>\n",
       "      <td>0.666062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.223494</td>\n",
       "      <td>0.050301</td>\n",
       "      <td>0.178313</td>\n",
       "      <td>0.949699</td>\n",
       "      <td>0.898922</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.110241</td>\n",
       "      <td>0.089157</td>\n",
       "      <td>0.046386</td>\n",
       "      <td>0.910843</td>\n",
       "      <td>0.710383</td>\n",
       "      <td>0.577778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.023494</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.976506</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.271739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.113855  0.060542    0.066867  0.939458   \n",
       "1     CB      0.184639         0.178012  0.034940    0.149699  0.965060   \n",
       "2    EWC      0.084337         0.044880  0.060542    0.023795  0.939458   \n",
       "3   Exec      0.103012         0.098795  0.069880    0.033133  0.930120   \n",
       "4    FWE      0.062048         0.053916  0.020181    0.041867  0.979819   \n",
       "5     SP      0.096386         0.087048  0.059940    0.036446  0.940060   \n",
       "6     RE      0.085542         0.065964  0.062952    0.022590  0.937048   \n",
       "7    Sup      0.127711         0.105422  0.083735    0.043976  0.916265   \n",
       "8     SW      0.165964         0.145181  0.090060    0.075904  0.909940   \n",
       "9   TEPE      0.228614         0.223494  0.050301    0.178313  0.949699   \n",
       "10   VMG      0.135542         0.110241  0.089157    0.046386  0.910843   \n",
       "11   OTH      0.027711         0.010843  0.023494    0.004217  0.976506   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.793651  0.709220  \n",
       "1    0.920474  0.887439  \n",
       "2    0.765101  0.407143  \n",
       "3    0.667683  0.640351  \n",
       "4    0.888268  0.771845  \n",
       "5    0.709343  0.640625  \n",
       "6    0.671233  0.517606  \n",
       "7    0.708571  0.584906  \n",
       "8    0.761411  0.666062  \n",
       "9    0.898922  0.878788  \n",
       "10   0.710383  0.577778  \n",
       "11   0.694444  0.271739  "
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.round(Y_pred_stack)\n",
    "\n",
    "a = theme_results(Y_valid, predictions)\n",
    "size = predictions.shape[0]\n",
    "zero_size = (predictions[predictions.sum(axis = 1) == 0,:].shape[0])\n",
    "print(\"Total comments:\", size, \n",
    "      \"\\nTotal Predictions:\", size - zero_size, \n",
    "      \"\\nPercent Pred non-zero:\", round(1 - zero_size/size, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5825 \n",
      "Hamming Loss: 0.0557 \n",
      "Hamming Loss (pred. zeros): 0.1215\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.128534</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.072978</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.767263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.197239</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.033859</td>\n",
       "      <td>0.163379</td>\n",
       "      <td>0.966141</td>\n",
       "      <td>0.920474</td>\n",
       "      <td>0.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.081854</td>\n",
       "      <td>0.048981</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>0.025970</td>\n",
       "      <td>0.944116</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.457831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103879</td>\n",
       "      <td>0.107824</td>\n",
       "      <td>0.067719</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.932281</td>\n",
       "      <td>0.667683</td>\n",
       "      <td>0.693038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.065746</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.045694</td>\n",
       "      <td>0.979947</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>0.060158</td>\n",
       "      <td>0.039776</td>\n",
       "      <td>0.939842</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.674342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.083169</td>\n",
       "      <td>0.071992</td>\n",
       "      <td>0.058514</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.941486</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.581028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.123274</td>\n",
       "      <td>0.115056</td>\n",
       "      <td>0.075279</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.924721</td>\n",
       "      <td>0.708571</td>\n",
       "      <td>0.661333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.170283</td>\n",
       "      <td>0.158448</td>\n",
       "      <td>0.087442</td>\n",
       "      <td>0.082840</td>\n",
       "      <td>0.912558</td>\n",
       "      <td>0.761411</td>\n",
       "      <td>0.708494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.241289</td>\n",
       "      <td>0.243918</td>\n",
       "      <td>0.046680</td>\n",
       "      <td>0.194609</td>\n",
       "      <td>0.953320</td>\n",
       "      <td>0.898922</td>\n",
       "      <td>0.908719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135766</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.085141</td>\n",
       "      <td>0.050625</td>\n",
       "      <td>0.914859</td>\n",
       "      <td>0.710383</td>\n",
       "      <td>0.629540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>0.022025</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.977975</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.308642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.128534         0.124260  0.055556    0.072978  0.944444   \n",
       "1     CB      0.197239         0.194280  0.033859    0.163379  0.966141   \n",
       "2    EWC      0.081854         0.048981  0.055884    0.025970  0.944116   \n",
       "3   Exec      0.103879         0.107824  0.067719    0.036160  0.932281   \n",
       "4    FWE      0.065746         0.058843  0.020053    0.045694  0.979947   \n",
       "5     SP      0.099934         0.095003  0.060158    0.039776  0.939842   \n",
       "6     RE      0.083169         0.071992  0.058514    0.024655  0.941486   \n",
       "7    Sup      0.123274         0.115056  0.075279    0.047995  0.924721   \n",
       "8     SW      0.170283         0.158448  0.087442    0.082840  0.912558   \n",
       "9   TEPE      0.241289         0.243918  0.046680    0.194609  0.953320   \n",
       "10   VMG      0.135766         0.120316  0.085141    0.050625  0.914859   \n",
       "11   OTH      0.026627         0.011834  0.022025    0.004602  0.977975   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.793651  0.767263  \n",
       "1    0.920474  0.906667  \n",
       "2    0.765101  0.457831  \n",
       "3    0.667683  0.693038  \n",
       "4    0.888268  0.795000  \n",
       "5    0.709343  0.674342  \n",
       "6    0.671233  0.581028  \n",
       "7    0.708571  0.661333  \n",
       "8    0.761411  0.708494  \n",
       "9    0.898922  0.908719  \n",
       "10   0.710383  0.629540  \n",
       "11   0.694444  0.308642  "
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "non_zero_valid = Y_valid[predictions.sum(axis = 1) != 0,:]\n",
    "\n",
    "theme_results(non_zero_valid, non_zero_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
