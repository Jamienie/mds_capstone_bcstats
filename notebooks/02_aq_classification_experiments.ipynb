{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aaronquinton/Documents/UBC-MDS/Capstone/BCstats/DSCI_591_capstone-BCStats'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change working directory to be project root\n",
    "import os\n",
    "#os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "# Custom functions for preprocessing and data preparation\n",
    "from src.data.preprocessing_text import (\n",
    "    clean_text, clean_numbers, replace_typical_misspell, remove_stopwords,\n",
    "    balance_themes, preprocess_for_embed, preprocess_for_bow\n",
    ")\n",
    "\n",
    "from src.features.word_vectors import (\n",
    "    build_vocab, check_coverage, get_average_embeddings\n",
    ")\n",
    "\n",
    "from src.models.eval import theme_results, investigate_results\n",
    "\n",
    "# Functions for preprocessing and data preparation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Training Word embeddings and pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Training LSTM Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Conv1D, GlobalAveragePooling1D\n",
    "from keras.layers import GRU, concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# Classification alogrithms\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import multilayer_perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Read in Data and Embeddings </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Filepaths\n",
    "fname_rawdata2015 = \"data/interim/train_2015-qualitative-data.csv\"\n",
    "fname_rawdata2018 = \"data/interim/train_2018-qualitative-data.csv\"\n",
    "fname_fasttext_crawl = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                       \"crawl-300d-2M.vec\"\n",
    "fname_fasttext_wiki = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                      \"wiki-news-300d-1M.vec\"\n",
    "fname_w2v_googlenews = \"./references/pretrained_embeddings.nosync/\" \\\n",
    "                       \"GoogleNews-vectors-negative300.bin\"\n",
    "fname_glove_twitter = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.twitter.27B.200d.w2v.txt\"\n",
    "fname_glove_wiki = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.6B.300d.w2v.txt\"\n",
    "fname_glove_crawl = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.840B.300d.w2v.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "df = pd.read_csv(fname_rawdata2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to load embeddings: 2958.4 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Read in pre-trained embeddings\n",
    "w2v_google_news = KeyedVectors.load_word2vec_format(fname_w2v_googlenews,\n",
    "                                                    binary=True)\n",
    "fasttext_crawl = KeyedVectors.load_word2vec_format(fname_fasttext_crawl,\n",
    "                                                   unicode_errors='ignore')\n",
    "fasttext_wiki = KeyedVectors.load_word2vec_format(fname_fasttext_wiki,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_twitter = KeyedVectors.load_word2vec_format(fname_glove_twitter,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_wiki = KeyedVectors.load_word2vec_format(fname_glove_wiki,\n",
    "                                               unicode_errors='ignore')\n",
    "glove_crawl = KeyedVectors.load_word2vec_format(fname_glove_crawl,\n",
    "                                                unicode_errors='ignore')\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Elapsed time to load embeddings: %.1f s\" % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Preprocessing and Data Preperation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2015 = pd.read_csv(fname_rawdata2015)\n",
    "# df_2018 = pd.read_csv(fname_rawdata2018)\n",
    "\n",
    "# df_2015['year_of_survey'] = 2015\n",
    "# df_2015.rename(columns={'2015 Comments':'comment',\n",
    "#             'Career_Personal_Development':'CPD','Compensation_Benefits':'CB',\n",
    "#             'Engagement_Workplace_Culture':'EWC','Executives':'Exec',\n",
    "#             'Flexible_Work_Environment':'FWE','Hiring_Promotion':'SP',\n",
    "#             'Recognition_Empowerment':'RE','Supervisors':'Sup',\n",
    "#             'Stress_Workload':'SW','Tools_Equipment_Physical_Environment':'TEPE',\n",
    "#             'Vision_Mission_Goals':'VMG','Other':'OTH'}, inplace=True)\n",
    "\n",
    "# selected_columns = [\"comment\",\"CPD\",\"CB\",\"EWC\",\"Exec\",\"FWE\",\"SP\",\"RE\",\n",
    "#                        \"Sup\",\"SW\",\"TEPE\",\"VMG\",\"OTH\"]\n",
    "\n",
    "# df_2015_selected = df_2015[selected_columns]\n",
    "\n",
    "# df_2018.rename(columns={'2018 Comment':'comment'}, inplace=True)\n",
    "# df_2018_selected = df_2018[selected_columns]\n",
    "\n",
    "# df = df_2015_selected.append(df_2018_selected, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['2018 Comment']].join(df.loc[:,'CPD':'OTH'])\n",
    "df = df.rename(columns = {'2018 Comment' : 'comment'})\n",
    "\n",
    "Y = np.array(df.loc[:,\"CPD\":\"OTH\"])\n",
    "\n",
    "themes = df.loc[:,'CPD':'OTH'].columns.tolist()\n",
    "\n",
    "# Split the data\n",
    "df_X_train, df_X_valid, Y_train, Y_valid = train_test_split(\n",
    "        df.comment, Y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9958,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9958, 12)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = preprocess_for_embed(df.comment, 'w2v_base_model')\n",
    "\n",
    "w2v_base_model = Word2Vec(comments, \n",
    "                     size=300, \n",
    "                     window=5, \n",
    "                     min_count=1,\n",
    "                     sg=1, \n",
    "                     negative=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pretrained embeddings\n",
    "embeddings = {'w2v_base_model': w2v_base_model,\n",
    "              'w2v_google_news': w2v_google_news, \n",
    "              'fasttext_crawl': fasttext_crawl,\n",
    "              'fasttext_wiki': fasttext_wiki,\n",
    "              'glove_twitter': glove_twitter,\n",
    "              'glove_wiki': glove_wiki,\n",
    "              'glove_crawl': glove_crawl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Vocab Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13278/13278 [00:00<00:00, 86084.02it/s]\n",
      "100%|██████████| 13673/13673 [00:00<00:00, 40466.79it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88164.98it/s]\n",
      "100%|██████████| 17246/17246 [00:03<00:00, 5679.35it/s] \n",
      "100%|██████████| 13278/13278 [00:00<00:00, 91469.55it/s]\n",
      "100%|██████████| 17500/17500 [00:01<00:00, 10368.71it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88333.35it/s]\n",
      "100%|██████████| 17500/17500 [00:02<00:00, 6214.14it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 90237.65it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4575.48it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 92607.72it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4979.80it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 89359.93it/s]\n",
      "100%|██████████| 17500/17500 [00:06<00:00, 2735.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>vocab_coverage</th>\n",
       "      <th>text_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>0.939870</td>\n",
       "      <td>0.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.953943</td>\n",
       "      <td>0.997412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>0.938514</td>\n",
       "      <td>0.996345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.887954</td>\n",
       "      <td>0.990666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.913479</td>\n",
       "      <td>0.994892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>0.997421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  vocab_coverage  text_coverage\n",
       "0   w2v_base_model        1.000000       1.000000\n",
       "1  w2v_google_news        0.939870       0.996661\n",
       "2   fasttext_crawl        0.953943       0.997412\n",
       "3    fasttext_wiki        0.938514       0.996345\n",
       "4    glove_twitter        0.887954       0.990666\n",
       "5       glove_wiki        0.913479       0.994892\n",
       "6      glove_crawl        0.953543       0.997421"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage of vocab words in embedding\n",
    "oov = {}\n",
    "vocab_coverage = []\n",
    "text_coverage = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    comments = preprocess_for_embed(df.comment, embedding)\n",
    "    vocab = build_vocab(comments)\n",
    "        \n",
    "    a, b, oov[embedding] = check_coverage(vocab, embeddings[embedding])\n",
    "    \n",
    "    vocab_coverage.append(a)\n",
    "    text_coverage.append(b)\n",
    "\n",
    "pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "              'vocab_coverage': vocab_coverage, \n",
    "              'text_coverage': text_coverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_base_model\n",
      "[]\n",
      "w2v_google_news\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('BCWS', 23)]\n",
      "fasttext_crawl\n",
      "[('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32)]\n",
      "fasttext_wiki\n",
      "[('MCFD', 128), ('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33)]\n",
      "glove_twitter\n",
      "[('2', 402), ('1', 302), ('3', 236), ('4', 171), ('5', 151)]\n",
      "glove_wiki\n",
      "[('####', 181), ('mcfd', 131), ('cymh', 54), ('#####', 49), ('bcts', 37)]\n",
      "glove_crawl\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('STIIP', 20)]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the out of vocab words for each embedding\n",
    "for i in oov.keys():\n",
    "    print(i)\n",
    "    print(oov[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Feature Engineering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Count Vectorizer to build bag of word arrays to train on\n",
    "vectorizer = CountVectorizer(stop_words= 'english',\n",
    "                             ngram_range=(1,5), \n",
    "                             min_df=2)   \n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(preprocess_for_bow(df_X_train))\n",
    "X_valid_bow = vectorizer.transform(preprocess_for_bow(df_X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 31422)\n",
      "(3320, 31422)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_valid_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Average Word Vectors per Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_avg_wv = {}\n",
    "X_valid_avg_wv = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    # Adjust features based on twitter embeddings \n",
    "    if embedding == 'glove_twitter':\n",
    "        n_features = 200\n",
    "    else:\n",
    "        n_features = 300\n",
    "    \n",
    "    # Preprocess comment data\n",
    "    comments_train = preprocess_for_embed(df_X_train, embedding)\n",
    "    comments_valid = preprocess_for_embed(df_X_valid, embedding)\n",
    "    \n",
    "    # Get average embeddings for each comment\n",
    "    # train\n",
    "    X_train_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_train])\n",
    "    \n",
    "    # valid\n",
    "    X_valid_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 300)\n",
      "(3320, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_avg_wv['w2v_base_model'].shape)\n",
    "print(X_valid_avg_wv['glove_twitter'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Classification Models </span>\n",
    "### Baseline Classifier - BOW | Linear SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bag of words Model with Linear SVC\n",
      "Elapsed Training time: 82.8 s \n",
      "Elapsed Predict time: 13.0 s\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Final Train and Predict Model                                                #\n",
    "################################################################################\n",
    "t_start = time.time()\n",
    "print(\"Training Bag of words Model with Linear SVC\")\n",
    "\n",
    "model_bow = BinaryRelevance(\n",
    "    classifier = LinearSVC()\n",
    ")\n",
    "\n",
    "model_bow.fit(X_train_bow, Y_train)\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_bow = model_bow.predict(X_valid_bow).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4509 \n",
      "Hamming Loss: 0.0737 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.113253</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.051807</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.728723</td>\n",
       "      <td>0.647754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.044578</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.955422</td>\n",
       "      <td>0.900172</td>\n",
       "      <td>0.853181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.932229</td>\n",
       "      <td>0.638191</td>\n",
       "      <td>0.453571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.090964</td>\n",
       "      <td>0.082530</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.917470</td>\n",
       "      <td>0.612583</td>\n",
       "      <td>0.540936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.055723</td>\n",
       "      <td>0.027410</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>0.972590</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.084639</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.028614</td>\n",
       "      <td>0.932229</td>\n",
       "      <td>0.669039</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.065663</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.924699</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.443662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>0.107831</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.892169</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.658947</td>\n",
       "      <td>0.568058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.215361</td>\n",
       "      <td>0.073494</td>\n",
       "      <td>0.155120</td>\n",
       "      <td>0.926506</td>\n",
       "      <td>0.860140</td>\n",
       "      <td>0.810277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>0.115663</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.884337</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>0.497778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.380435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.113253  0.075602    0.051807  0.924398   \n",
       "1     CB      0.184639         0.175000  0.044578    0.140060  0.955422   \n",
       "2    EWC      0.084337         0.059940  0.067771    0.016566  0.932229   \n",
       "3   Exec      0.103012         0.090964  0.082530    0.020482  0.917470   \n",
       "4    FWE      0.062048         0.055723  0.027410    0.034639  0.972590   \n",
       "5     SP      0.096386         0.084639  0.067771    0.028614  0.932229   \n",
       "6     RE      0.085542         0.065663  0.075301    0.010241  0.924699   \n",
       "7    Sup      0.127711         0.115060  0.107831    0.019880  0.892169   \n",
       "8     SW      0.165964         0.143072  0.120482    0.045482  0.879518   \n",
       "9   TEPE      0.228614         0.215361  0.073494    0.155120  0.926506   \n",
       "10   VMG      0.135542         0.115060  0.115663    0.019880  0.884337   \n",
       "11   OTH      0.027711         0.019880  0.026506    0.001205  0.973494   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.728723  0.647754  \n",
       "1    0.900172  0.853181  \n",
       "2    0.638191  0.453571  \n",
       "3    0.612583  0.540936  \n",
       "4    0.810811  0.728155  \n",
       "5    0.669039  0.587500  \n",
       "6    0.577982  0.443662  \n",
       "7    0.586387  0.528302  \n",
       "8    0.658947  0.568058  \n",
       "9    0.860140  0.810277  \n",
       "10   0.586387  0.497778  \n",
       "11   0.530303  0.380435  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, Y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 12)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_bow[Y_pred_bow.sum(axis = 1) == 0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3320, 12)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Vectors | Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>16.752789</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.345181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>10.903381</td>\n",
       "      <td>0.129260</td>\n",
       "      <td>0.402108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>20.404690</td>\n",
       "      <td>0.119333</td>\n",
       "      <td>0.408133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>7.214360</td>\n",
       "      <td>0.103724</td>\n",
       "      <td>0.392470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>51.912930</td>\n",
       "      <td>0.060164</td>\n",
       "      <td>0.340964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>46.241062</td>\n",
       "      <td>0.091611</td>\n",
       "      <td>0.389157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>39.054376</td>\n",
       "      <td>0.114515</td>\n",
       "      <td>0.400301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model   16.752789      0.163054          0.345181\n",
       "1  w2v_google_news   10.903381      0.129260          0.402108\n",
       "2   fasttext_crawl   20.404690      0.119333          0.408133\n",
       "3    fasttext_wiki    7.214360      0.103724          0.392470\n",
       "4    glove_twitter   51.912930      0.060164          0.340964\n",
       "5       glove_wiki   46.241062      0.091611          0.389157\n",
       "6      glove_crawl   39.054376      0.114515          0.400301"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_avg_wv = {}\n",
    "model_avg_wv = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "\n",
    "    clf = BinaryRelevance(\n",
    "        classifier = LinearSVC(max_iter = 2000)\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_avg_wv[embedding], Y_train)\n",
    "    t_end_train = time.time()\n",
    "\n",
    "    Y_pred_avg_wv[embedding] = clf.predict(X_valid_avg_wv[embedding]) \\\n",
    "                                  .toarray()\n",
    "    model_avg_wv[embedding] = clf\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             Y_pred_avg_wv[embedding]))\n",
    "\n",
    "results_avg_wv = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                               'train_time': train_time,\n",
    "                               'predict_time': predict_time,\n",
    "                               'overall_accuracy': accuarcies})\n",
    "\n",
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Build Embedding Matrices and prepare data for deep \n",
    "# learning Models\n",
    "max_words = 12000\n",
    "maxlen = 700\n",
    "\n",
    "# dictionaries for each embedding\n",
    "embedding_matrix = {}\n",
    "tokenizer = {}\n",
    "X_train_lstm = {}\n",
    "X_valid_lstm = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "\n",
    "    # Preprocess text data based on embedding\n",
    "    X_train = np.array(preprocess_for_embed(df_X_train,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    X_valid = np.array(preprocess_for_embed(df_X_valid,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    # Tokenize and pad numbers for LSTM Model\n",
    "    tokenizer[embedding] = Tokenizer(num_words=max_words)\n",
    "    tokenizer[embedding].fit_on_texts(X_train)\n",
    "    \n",
    "    tokenized_train = tokenizer[embedding].texts_to_sequences(X_train)\n",
    "    tokenized_test = tokenizer[embedding].texts_to_sequences(X_valid)\n",
    "\n",
    "    X_train_lstm[embedding] = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "    X_valid_lstm[embedding] = pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "    \n",
    "    \n",
    "    # Build Embedding Matrices\n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "\n",
    "    word_index = tokenizer[embedding].word_index\n",
    "    \n",
    "    num_words = min(max_words, len(word_index) + 1)\n",
    "    embedding_matrix[embedding] = np.zeros((num_words, embed_size),\n",
    "                                           dtype='float32')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "\n",
    "        if i >= max_words:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embedding_vector = embeddings[embedding][word]\n",
    "\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[embedding][i] = embedding_vector\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM on the  w2v_base_model\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 326s 36ms/step - loss: 0.3709 - acc: 0.8637 - val_loss: 0.2762 - val_acc: 0.9045\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 287s 32ms/step - loss: 0.2588 - acc: 0.9052 - val_loss: 0.2289 - val_acc: 0.9165\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 283s 32ms/step - loss: 0.2278 - acc: 0.9147 - val_loss: 0.2154 - val_acc: 0.9197\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 283s 32ms/step - loss: 0.2139 - acc: 0.9198 - val_loss: 0.2102 - val_acc: 0.9225\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 283s 32ms/step - loss: 0.2105 - acc: 0.9203 - val_loss: 0.2026 - val_acc: 0.9260\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 285s 32ms/step - loss: 0.1997 - acc: 0.9244 - val_loss: 0.1906 - val_acc: 0.9285\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 284s 32ms/step - loss: 0.1898 - acc: 0.9282 - val_loss: 0.1867 - val_acc: 0.9295\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 280s 31ms/step - loss: 0.1872 - acc: 0.9295 - val_loss: 0.1931 - val_acc: 0.9247\n",
      "Training LSTM on the  w2v_google_news\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 286s 32ms/step - loss: 0.3775 - acc: 0.8735 - val_loss: 0.2923 - val_acc: 0.9025\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 280s 31ms/step - loss: 0.2671 - acc: 0.9050 - val_loss: 0.2410 - val_acc: 0.9173\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 276s 31ms/step - loss: 0.2341 - acc: 0.9130 - val_loss: 0.2248 - val_acc: 0.9214\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 276s 31ms/step - loss: 0.2182 - acc: 0.9192 - val_loss: 0.2043 - val_acc: 0.9276\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 277s 31ms/step - loss: 0.2064 - acc: 0.9234 - val_loss: 0.1976 - val_acc: 0.9292\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 275s 31ms/step - loss: 0.1924 - acc: 0.9274 - val_loss: 0.1887 - val_acc: 0.9311\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 266s 30ms/step - loss: 0.1817 - acc: 0.9313 - val_loss: 0.1829 - val_acc: 0.9330\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 266s 30ms/step - loss: 0.1778 - acc: 0.9330 - val_loss: 0.1834 - val_acc: 0.9331\n",
      "Training LSTM on the  fasttext_crawl\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 295s 33ms/step - loss: 0.3548 - acc: 0.8790 - val_loss: 0.2700 - val_acc: 0.9075\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 266s 30ms/step - loss: 0.2448 - acc: 0.9108 - val_loss: 0.2126 - val_acc: 0.9245\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 266s 30ms/step - loss: 0.2089 - acc: 0.9214 - val_loss: 0.1964 - val_acc: 0.9301\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 265s 30ms/step - loss: 0.1895 - acc: 0.9284 - val_loss: 0.1846 - val_acc: 0.9316\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 264s 29ms/step - loss: 0.1754 - acc: 0.9328 - val_loss: 0.1811 - val_acc: 0.9329\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1669 - acc: 0.9364 - val_loss: 0.1761 - val_acc: 0.9343\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 264s 29ms/step - loss: 0.1598 - acc: 0.9391 - val_loss: 0.1754 - val_acc: 0.9356\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1553 - acc: 0.9401 - val_loss: 0.1708 - val_acc: 0.9363\n",
      "Training LSTM on the  fasttext_wiki\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 268s 30ms/step - loss: 0.3868 - acc: 0.8660 - val_loss: 0.3120 - val_acc: 0.8894\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.2830 - acc: 0.8997 - val_loss: 0.2479 - val_acc: 0.9121\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.2401 - acc: 0.9104 - val_loss: 0.2225 - val_acc: 0.9202\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 262s 29ms/step - loss: 0.2146 - acc: 0.9187 - val_loss: 0.2088 - val_acc: 0.9238\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.2026 - acc: 0.9236 - val_loss: 0.2131 - val_acc: 0.9226\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1964 - acc: 0.9253 - val_loss: 0.1915 - val_acc: 0.9297\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 270s 30ms/step - loss: 0.1810 - acc: 0.9309 - val_loss: 0.1812 - val_acc: 0.9328\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1754 - acc: 0.9328 - val_loss: 0.1806 - val_acc: 0.9339\n",
      "Training LSTM on the  glove_twitter\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 230s 26ms/step - loss: 0.3546 - acc: 0.8794 - val_loss: 0.2793 - val_acc: 0.9041\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 222s 25ms/step - loss: 0.2637 - acc: 0.9048 - val_loss: 0.2344 - val_acc: 0.9137\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 222s 25ms/step - loss: 0.2301 - acc: 0.9149 - val_loss: 0.2106 - val_acc: 0.9241\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 222s 25ms/step - loss: 0.2082 - acc: 0.9228 - val_loss: 0.2053 - val_acc: 0.9258\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 221s 25ms/step - loss: 0.1955 - acc: 0.9268 - val_loss: 0.1903 - val_acc: 0.9307\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 222s 25ms/step - loss: 0.1822 - acc: 0.9315 - val_loss: 0.1994 - val_acc: 0.9262\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 221s 25ms/step - loss: 0.1764 - acc: 0.9331 - val_loss: 0.1829 - val_acc: 0.9342\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 221s 25ms/step - loss: 0.1692 - acc: 0.9363 - val_loss: 0.1813 - val_acc: 0.9343\n",
      "Training LSTM on the  glove_wiki\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 268s 30ms/step - loss: 0.3504 - acc: 0.8797 - val_loss: 0.2748 - val_acc: 0.9079\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 262s 29ms/step - loss: 0.2519 - acc: 0.9093 - val_loss: 0.2257 - val_acc: 0.9209\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 262s 29ms/step - loss: 0.2133 - acc: 0.9211 - val_loss: 0.2070 - val_acc: 0.9270\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 262s 29ms/step - loss: 0.1941 - acc: 0.9269 - val_loss: 0.1962 - val_acc: 0.9280\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 264s 30ms/step - loss: 0.1813 - acc: 0.9317 - val_loss: 0.1884 - val_acc: 0.9311\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 262s 29ms/step - loss: 0.1682 - acc: 0.9362 - val_loss: 0.1812 - val_acc: 0.9337\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 265s 30ms/step - loss: 0.1582 - acc: 0.9401 - val_loss: 0.1763 - val_acc: 0.9360\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1511 - acc: 0.9425 - val_loss: 0.1792 - val_acc: 0.9358\n",
      "Training LSTM on the  glove_crawl\n",
      "Train on 8962 samples, validate on 996 samples\n",
      "Epoch 1/8\n",
      "8962/8962 [==============================] - 269s 30ms/step - loss: 0.3541 - acc: 0.8777 - val_loss: 0.2787 - val_acc: 0.9070\n",
      "Epoch 2/8\n",
      "8962/8962 [==============================] - 264s 29ms/step - loss: 0.2522 - acc: 0.9088 - val_loss: 0.2230 - val_acc: 0.9205\n",
      "Epoch 3/8\n",
      "8962/8962 [==============================] - 261s 29ms/step - loss: 0.2117 - acc: 0.9210 - val_loss: 0.1964 - val_acc: 0.9294\n",
      "Epoch 4/8\n",
      "8962/8962 [==============================] - 261s 29ms/step - loss: 0.1900 - acc: 0.9280 - val_loss: 0.1892 - val_acc: 0.9301\n",
      "Epoch 5/8\n",
      "8962/8962 [==============================] - 261s 29ms/step - loss: 0.1786 - acc: 0.9322 - val_loss: 0.1845 - val_acc: 0.9334\n",
      "Epoch 6/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1662 - acc: 0.9371 - val_loss: 0.1841 - val_acc: 0.9301\n",
      "Epoch 7/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1613 - acc: 0.9385 - val_loss: 0.1760 - val_acc: 0.9343\n",
      "Epoch 8/8\n",
      "8962/8962 [==============================] - 263s 29ms/step - loss: 0.1485 - acc: 0.9433 - val_loss: 0.1829 - val_acc: 0.9337\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model and train and validate\n",
    "Y_pred_lstm = {}\n",
    "model_lstm = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "    print(\"Training LSTM on the \", embedding)\n",
    "    \n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "    \n",
    "    # Deep Learning Architecture\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(max_words, embed_size, \n",
    "                  weights=[embedding_matrix[embedding]], \n",
    "                  trainable=False)(inp)\n",
    "\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1,\n",
    "                          recurrent_dropout=0.1))(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, padding=\"valid\", \n",
    "               kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    preds = Dense(12, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train and Predict Model\n",
    "    batch_size = 128\n",
    "    epochs = 16\n",
    "    model.fit(X_train_lstm[embedding],\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, \n",
    "              validation_split=0.15)\n",
    "    t_end_train = time.time()\n",
    "    \n",
    "    Y_pred_lstm[embedding] = model.predict(X_valid_lstm[embedding])\n",
    "    model_lstm[embedding] = model\n",
    "\n",
    "    # Calculate and report results\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_lstm[embedding])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>2324.503006</td>\n",
       "      <td>44.884675</td>\n",
       "      <td>0.441566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>2215.871378</td>\n",
       "      <td>42.849580</td>\n",
       "      <td>0.470181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>2403.690729</td>\n",
       "      <td>44.079534</td>\n",
       "      <td>0.490964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>2126.471193</td>\n",
       "      <td>43.266172</td>\n",
       "      <td>0.460241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>1796.038347</td>\n",
       "      <td>35.112366</td>\n",
       "      <td>0.474398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>2120.624354</td>\n",
       "      <td>44.435506</td>\n",
       "      <td>0.472892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>2115.557431</td>\n",
       "      <td>44.032099</td>\n",
       "      <td>0.480723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  2324.503006     44.884675          0.441566\n",
       "1  w2v_google_news  2215.871378     42.849580          0.470181\n",
       "2   fasttext_crawl  2403.690729     44.079534          0.490964\n",
       "3    fasttext_wiki  2126.471193     43.266172          0.460241\n",
       "4    glove_twitter  1796.038347     35.112366          0.474398\n",
       "5       glove_wiki  2120.624354     44.435506          0.472892\n",
       "6      glove_crawl  2115.557431     44.032099          0.480723"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lstm = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                             'train_time': train_time,\n",
    "                             'predict_time': predict_time,\n",
    "                             'overall_accuracy': accuarcies})\n",
    "\n",
    "results_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack_wv = np.hstack(tuple(Y_pred_avg_wv.values()))\n",
    "\n",
    "X_train_stack_lstm = np.hstack(tuple(Y_pred_lstm.values()))\n",
    "\n",
    "X_train_stack_bow = Y_pred_bow\n",
    "\n",
    "X_train_stack = np.hstack((X_train_stack_bow,\n",
    "                           X_train_stack_wv,\n",
    "                           X_train_stack_lstm))\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3320, 180)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogReg on Stack\n",
      "Elapsed Training time: 6.1 s \n",
      "Elapsed Predict time: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Final Train and Predict Model                                                #\n",
    "################################################################################\n",
    "t_start = time.time()\n",
    "print(\"Training LogReg on Stack\")\n",
    "\n",
    "model_stack = BinaryRelevance(\n",
    "    classifier = LogisticRegression(solver = 'liblinear', penalty='l1')\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(model_stack, X_train_stack, Y_valid, cv = 10)\n",
    "t_end_train = time.time()\n",
    "\n",
    "#Y_pred_bow = model_bow.predict(X_valid_bow).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.70575595, 0.60740614, 0.56916618, 0.55413079, 0.55089784,\n",
       "        0.58229303, 0.5561769 , 0.56042814, 0.58310485, 0.55386686]),\n",
       " 'score_time': array([0.01045513, 0.00864315, 0.00819778, 0.00856209, 0.00759125,\n",
       "        0.00755572, 0.00776291, 0.00739312, 0.00740504, 0.00758815]),\n",
       " 'test_score': array([0.49096386, 0.54819277, 0.5       , 0.50903614, 0.46686747,\n",
       "        0.52409639, 0.51506024, 0.5       , 0.53313253, 0.52710843]),\n",
       " 'train_score': array([0.54250335, 0.53781794, 0.54618474, 0.54718876, 0.55087015,\n",
       "        0.54484605, 0.541834  , 0.54718876, 0.54250335, 0.54317269])}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w2v_base_model': array([[7.52391756e-01, 3.34253572e-02, 3.46884574e-03, ...,\n",
       "         1.54801635e-02, 2.49574939e-03, 1.09362903e-04],\n",
       "        [8.92291218e-02, 7.26498605e-04, 3.59270684e-02, ...,\n",
       "         1.00768614e-03, 6.30116642e-01, 6.39148429e-03],\n",
       "        [3.40824714e-04, 7.77504581e-04, 5.06505417e-03, ...,\n",
       "         2.06370965e-01, 4.92959082e-01, 7.18037947e-04],\n",
       "        ...,\n",
       "        [2.71791779e-03, 1.53935154e-03, 7.52969272e-03, ...,\n",
       "         1.03432089e-02, 1.68368369e-01, 1.44813256e-03],\n",
       "        [5.85450158e-02, 1.96871050e-02, 3.46192658e-01, ...,\n",
       "         3.75147127e-02, 6.53807865e-03, 1.09878345e-03],\n",
       "        [3.25757498e-03, 1.23962655e-03, 3.19494233e-02, ...,\n",
       "         9.94157605e-03, 2.71991566e-02, 2.67792889e-03]], dtype=float32),\n",
       " 'w2v_google_news': array([[6.6701716e-01, 9.1943191e-03, 1.6319435e-03, ..., 2.5237944e-02,\n",
       "         2.0723536e-03, 1.1605593e-04],\n",
       "        [2.3216338e-01, 3.1242725e-03, 1.0765996e-01, ..., 3.7268500e-03,\n",
       "         4.2385617e-01, 7.1659036e-02],\n",
       "        [5.2120695e-03, 1.2748173e-03, 2.4716970e-02, ..., 7.2148959e-03,\n",
       "         9.2534566e-01, 4.8073605e-04],\n",
       "        ...,\n",
       "        [9.2422619e-04, 2.7624143e-03, 3.0922810e-02, ..., 8.2667620e-04,\n",
       "         9.6174532e-01, 1.9124923e-04],\n",
       "        [2.2296537e-02, 6.1366608e-04, 2.8938197e-02, ..., 8.2957158e-03,\n",
       "         2.5382537e-02, 6.0228555e-04],\n",
       "        [2.7094549e-03, 8.0770603e-04, 2.0636253e-01, ..., 7.6734927e-03,\n",
       "         4.2436197e-02, 1.1806773e-03]], dtype=float32),\n",
       " 'fasttext_crawl': array([[7.9693675e-01, 3.1738880e-03, 1.3536994e-03, ..., 8.6271996e-03,\n",
       "         6.3914695e-04, 1.5114278e-04],\n",
       "        [6.1014020e-01, 3.6824279e-04, 6.8939090e-02, ..., 7.2068567e-03,\n",
       "         8.4492570e-01, 7.4878860e-01],\n",
       "        [5.5502902e-04, 3.3543757e-04, 1.7247078e-03, ..., 1.4185283e-04,\n",
       "         9.0241927e-01, 2.4582751e-04],\n",
       "        ...,\n",
       "        [3.6917304e-04, 6.7011826e-02, 7.5756287e-04, ..., 2.5388005e-04,\n",
       "         8.7478966e-01, 6.5920474e-03],\n",
       "        [2.3361493e-03, 3.0357335e-04, 1.1283642e-02, ..., 3.7254195e-04,\n",
       "         1.5467909e-02, 2.4115530e-04],\n",
       "        [4.5378099e-04, 7.3883188e-04, 9.8710127e-02, ..., 8.5421529e-04,\n",
       "         1.3267007e-02, 1.2207116e-03]], dtype=float32),\n",
       " 'fasttext_wiki': array([[5.7535797e-01, 1.0645151e-02, 1.6678782e-02, ..., 1.2822976e-02,\n",
       "         1.1131362e-02, 2.4107541e-03],\n",
       "        [4.6619830e-01, 4.9692590e-04, 1.8736768e-01, ..., 2.7327187e-04,\n",
       "         7.8593928e-01, 1.8123996e-01],\n",
       "        [9.2944026e-04, 3.4356501e-04, 9.0307156e-03, ..., 8.2408935e-03,\n",
       "         6.5775979e-01, 4.6413615e-03],\n",
       "        ...,\n",
       "        [2.4891116e-03, 9.8208981e-03, 8.0724768e-03, ..., 7.6489279e-04,\n",
       "         9.3848723e-01, 1.8430075e-03],\n",
       "        [8.3132491e-02, 1.2064547e-03, 8.9088745e-02, ..., 6.8223075e-04,\n",
       "         3.0354256e-02, 2.3330607e-02],\n",
       "        [1.6058643e-03, 2.3976716e-03, 2.2157790e-01, ..., 1.6529890e-03,\n",
       "         1.9839322e-02, 1.8659061e-02]], dtype=float32),\n",
       " 'glove_twitter': array([[4.6677387e-01, 9.3822414e-04, 1.3758609e-03, ..., 1.8465163e-03,\n",
       "         7.0013152e-03, 1.2891146e-04],\n",
       "        [8.4074777e-01, 2.2810529e-04, 1.4013885e-01, ..., 2.7008937e-03,\n",
       "         4.5469928e-01, 4.5762144e-02],\n",
       "        [1.8765231e-03, 4.7772267e-04, 1.9482503e-03, ..., 1.2538347e-03,\n",
       "         7.0810801e-01, 1.5230901e-03],\n",
       "        ...,\n",
       "        [5.8860744e-05, 9.6101388e-02, 2.4540693e-04, ..., 1.8321474e-03,\n",
       "         9.5809507e-01, 7.1944180e-04],\n",
       "        [2.3163290e-01, 2.3741834e-04, 9.7236462e-02, ..., 1.6326965e-03,\n",
       "         4.3463069e-03, 7.4154406e-05],\n",
       "        [7.8987767e-04, 3.5098235e-03, 5.9779093e-02, ..., 7.6248460e-03,\n",
       "         5.7483166e-03, 8.5089641e-04]], dtype=float32),\n",
       " 'glove_wiki': array([[6.78069472e-01, 4.09007596e-04, 3.34168959e-04, ...,\n",
       "         1.19707431e-04, 2.32859422e-03, 2.87845050e-05],\n",
       "        [5.00780523e-01, 2.75109895e-04, 4.62571755e-02, ...,\n",
       "         4.07662382e-03, 7.11002424e-02, 2.45482311e-01],\n",
       "        [1.44890917e-03, 7.02005400e-06, 6.96810777e-04, ...,\n",
       "         7.65863166e-04, 4.46846187e-01, 1.41267665e-05],\n",
       "        ...,\n",
       "        [2.12258426e-03, 2.87992228e-03, 1.56849797e-04, ...,\n",
       "         8.43131542e-03, 6.52549028e-01, 5.34711173e-04],\n",
       "        [4.83148098e-02, 1.70352359e-04, 9.15276706e-02, ...,\n",
       "         9.82238096e-04, 7.05352722e-05, 1.80133409e-03],\n",
       "        [1.41353509e-03, 2.68629356e-03, 1.26828970e-02, ...,\n",
       "         4.91336547e-03, 1.94209684e-02, 2.92570941e-04]], dtype=float32),\n",
       " 'glove_crawl': array([[5.2300036e-01, 7.2388147e-04, 1.3947675e-03, ..., 1.4065062e-03,\n",
       "         1.3103617e-04, 6.8946360e-07],\n",
       "        [1.7917410e-01, 1.1128520e-04, 2.4284773e-02, ..., 3.9560217e-04,\n",
       "         9.7665137e-01, 8.0415204e-02],\n",
       "        [7.8663306e-04, 4.5540834e-05, 3.0066221e-04, ..., 1.8293521e-03,\n",
       "         9.8246944e-01, 1.0479340e-04],\n",
       "        ...,\n",
       "        [5.5853475e-04, 4.1712452e-02, 2.4179814e-03, ..., 2.1928937e-04,\n",
       "         9.8039150e-01, 1.5304916e-04],\n",
       "        [1.9740288e-03, 3.0321672e-04, 6.0906809e-02, ..., 4.1953591e-04,\n",
       "         1.2404273e-03, 1.1411020e-04],\n",
       "        [6.9113396e-04, 2.3806354e-03, 2.1793038e-02, ..., 1.2666652e-03,\n",
       "         5.1108478e-03, 4.4504571e-04]], dtype=float32)}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_stack.fit(X_train_stack,Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test.classifiers_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69109725,  3.14212075,  0.27725472,  0.        ,  3.30882647,\n",
       "       -5.07801455,  1.76126742,  0.97567224,  0.02674363, -0.4414858 ,\n",
       "        0.37500527, -0.15995709,  0.6882352 ,  0.13877029,  0.47648083])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.coef_[0,np.arange(0,180, 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['w2v_base_model', 'w2v_google_news', 'fasttext_crawl', 'fasttext_wiki', 'glove_twitter', 'glove_wiki', 'glove_crawl'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta, X_valid_meta, Y_train_meta, Y_valid_meta = train_test_split(\n",
    "    X_train_stack, Y_valid, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587, 180)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Stack\n",
      "Elapsed Training time: 1.0 s \n",
      "Elapsed Predict time: 0.3 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Training on Stack\")\n",
    "\n",
    "model_stack = BinaryRelevance(\n",
    "    classifier = LogisticRegression(penalty='l1', solver='liblinear')\n",
    ")\n",
    "\n",
    "#cv_results = cross_validate(model_stack, X_train_stack_lstm, Y_valid, cv = 10)\n",
    "model_stack.fit(X_train_meta, Y_train_meta)\n",
    "\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_stack = model_stack.predict_proba(X_valid_meta).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4094 \n",
      "Hamming Loss: 0.0778 \n",
      "Hamming Loss (pred. zeros): 0.129\n",
      "average Precision:  0.904857942114193\n",
      "(1529, 12)\n",
      "(512, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.139961</td>\n",
       "      <td>0.068672</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.060824</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.462617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.164814</td>\n",
       "      <td>0.141269</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.126880</td>\n",
       "      <td>0.962067</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.813492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.092871</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.079137</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.211268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.135383</td>\n",
       "      <td>0.033355</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.896664</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.241546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.041203</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>0.017005</td>\n",
       "      <td>0.024199</td>\n",
       "      <td>0.982995</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.121648</td>\n",
       "      <td>0.052322</td>\n",
       "      <td>0.073250</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.926750</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.413978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.102681</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.083715</td>\n",
       "      <td>0.018967</td>\n",
       "      <td>0.916285</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.216561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>0.052976</td>\n",
       "      <td>0.115762</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.884238</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.293103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.206017</td>\n",
       "      <td>0.080445</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>0.067364</td>\n",
       "      <td>0.861347</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.358730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.213211</td>\n",
       "      <td>0.170046</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.150425</td>\n",
       "      <td>0.937214</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.751534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.148463</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.121648</td>\n",
       "      <td>0.026815</td>\n",
       "      <td>0.878352</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.198238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.021583</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.139961         0.068672  0.079137    0.060824  0.920863   \n",
       "1     CB      0.164814         0.141269  0.037933    0.126880  0.962067   \n",
       "2    EWC      0.092871         0.025507  0.079137    0.013734  0.920863   \n",
       "3   Exec      0.135383         0.033355  0.103336    0.032047  0.896664   \n",
       "4    FWE      0.041203         0.028123  0.017005    0.024199  0.982995   \n",
       "5     SP      0.121648         0.052322  0.073250    0.048398  0.926750   \n",
       "6     RE      0.102681         0.025507  0.083715    0.018967  0.916285   \n",
       "7    Sup      0.151733         0.052976  0.115762    0.035971  0.884238   \n",
       "8     SW      0.206017         0.080445  0.138653    0.067364  0.861347   \n",
       "9   TEPE      0.213211         0.170046  0.062786    0.150425  0.937214   \n",
       "10   VMG      0.148463         0.032047  0.121648    0.026815  0.878352   \n",
       "11   OTH      0.029431         0.011772  0.021583    0.007848  0.978417   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.942857  0.462617  \n",
       "1    0.949074  0.813492  \n",
       "2    0.769231  0.211268  \n",
       "3    0.980392  0.241546  \n",
       "4    0.930233  0.634921  \n",
       "5    0.962500  0.413978  \n",
       "6    0.871795  0.216561  \n",
       "7    0.839506  0.293103  \n",
       "8    0.918699  0.358730  \n",
       "9    0.942308  0.751534  \n",
       "10   0.918367  0.198238  \n",
       "11   0.833333  0.333333  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.round(Y_pred_stack-0.40)\n",
    "\n",
    "a = theme_results(Y_valid_meta, predictions)\n",
    "print('average Precision: ', a.Precision.mean())\n",
    "print(predictions.shape)\n",
    "print(predictions[predictions.sum(axis = 1) == 0,:].shape)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.6087 \n",
      "Hamming Loss: 0.0549 \n",
      "Hamming Loss (pred. zeros): 0.1318\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.155359</td>\n",
       "      <td>0.103245</td>\n",
       "      <td>0.063913</td>\n",
       "      <td>0.091445</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.626582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.190757</td>\n",
       "      <td>0.968535</td>\n",
       "      <td>0.949074</td>\n",
       "      <td>0.907080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.941003</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.113078</td>\n",
       "      <td>0.050147</td>\n",
       "      <td>0.064897</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.935103</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.050147</td>\n",
       "      <td>0.042281</td>\n",
       "      <td>0.013766</td>\n",
       "      <td>0.036382</td>\n",
       "      <td>0.986234</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.125860</td>\n",
       "      <td>0.078663</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>0.946903</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.094395</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>0.934120</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.073746</td>\n",
       "      <td>0.054081</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.523077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.207473</td>\n",
       "      <td>0.120944</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.101278</td>\n",
       "      <td>0.893805</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.535545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.273353</td>\n",
       "      <td>0.255654</td>\n",
       "      <td>0.047198</td>\n",
       "      <td>0.226155</td>\n",
       "      <td>0.952802</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.881295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.104228</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.063913</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>0.936087</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.424528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.984267</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.155359         0.103245  0.063913    0.091445  0.936087   \n",
       "1     CB      0.222222         0.212389  0.031465    0.190757  0.968535   \n",
       "2    EWC      0.079646         0.038348  0.058997    0.020649  0.941003   \n",
       "3   Exec      0.113078         0.050147  0.064897    0.048181  0.935103   \n",
       "4    FWE      0.050147         0.042281  0.013766    0.036382  0.986234   \n",
       "5     SP      0.125860         0.078663  0.053097    0.072763  0.946903   \n",
       "6     RE      0.094395         0.038348  0.065880    0.028515  0.934120   \n",
       "7    Sup      0.127827         0.079646  0.073746    0.054081  0.926254   \n",
       "8     SW      0.207473         0.120944  0.106195    0.101278  0.893805   \n",
       "9   TEPE      0.273353         0.255654  0.047198    0.226155  0.952802   \n",
       "10   VMG      0.104228         0.048181  0.063913    0.040315  0.936087   \n",
       "11   OTH      0.027532         0.017699  0.015733    0.011799  0.984267   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.942857  0.626582  \n",
       "1    0.949074  0.907080  \n",
       "2    0.769231  0.370370  \n",
       "3    0.980392  0.434783  \n",
       "4    0.930233  0.784314  \n",
       "5    0.962500  0.601562  \n",
       "6    0.871795  0.354167  \n",
       "7    0.839506  0.523077  \n",
       "8    0.918699  0.535545  \n",
       "9    0.942308  0.881295  \n",
       "10   0.918367  0.424528  \n",
       "11   0.833333  0.535714  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_true = Y_valid_meta[predictions.sum(axis = 1) != 0,:]\n",
    "non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "\n",
    "theme_results(non_zero_true, non_zero_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = investigate_results(df_X_valid, Y_valid, Y_pred_bow)\n",
    "\n",
    "indices_bow = set(df_results \\\n",
    "               .query(\"correct == False\") \\\n",
    "               .base_index \\\n",
    "               .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Y_pred_avg_wv['w2v_base_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    df_results = investigate_results(df_X_valid, Y_valid, Y_pred_avg_wv[embedding])\n",
    "    \n",
    "    wrong_index[embedding] = set(df_results \\\n",
    "                                .query(\"correct == False\") \\\n",
    "                                .base_index \\\n",
    "                                .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2177\n",
      "1862\n",
      "1739\n",
      "1693\n",
      "1665\n",
      "1641\n",
      "1604\n"
     ]
    }
   ],
   "source": [
    "indices_wv = wrong_index['w2v_base_model']\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    indices_wv = indices_wv.intersection(wrong_index[embedding])\n",
    "    print(len(indices_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6828313253012048"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 1053/3320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5195783132530121"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 1595/3320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1053"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_wv.intersection(indices_bow).intersection(indices_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = investigate_results(df_X_valid, Y_valid, Y_pred_bow)\n",
    "\n",
    "indices_bow = set(df_results \\\n",
    "                  .query(\"correct == False\") \\\n",
    "                  .base_index \\\n",
    "                  .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_index = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    df_results = investigate_results(df_X_valid, Y_valid, np.round(Y_pred_lstm[embedding]))\n",
    "    \n",
    "    wrong_index[embedding] = set(df_results \\\n",
    "                                .query(\"correct == False\") \\\n",
    "                                .base_index \\\n",
    "                                .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investigate_results(df_X_valid, Y_valid, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3052\n",
      "2540\n",
      "2280\n",
      "2148\n",
      "2035\n",
      "1917\n",
      "1829\n"
     ]
    }
   ],
   "source": [
    "indices_lstm = wrong_index['w2v_base_model']\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    indices_lstm = indices_lstm.intersection(wrong_index[embedding])\n",
    "    print(len(indices_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7009483322432963"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 1829/6116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6116, 12)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
