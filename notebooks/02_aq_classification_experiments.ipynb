{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Procedure and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook details the machine learning procedure, experiments, and results for the MDS 2019 Capstone project. The purpose of this notebook is to illustrate the details of the code in a digestable format.\n",
    "\n",
    "This analysis notebook best accompanies the [MDS Final Report]() which introduces the problem and more formally describes the methodology and results. To learn how to implement the data on future WES comments see the [WES Classification USAGE]() notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aaronquinton/Documents/UBC-MDS/Capstone/BCstats/DSCI_591_capstone-BCStats'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change working directory to be project root\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "# Custom functions for preprocessing, data preparation, and evaluation\n",
    "from src.data.preprocessing_text import (\n",
    "    clean_text, clean_numbers, replace_typical_misspell, remove_stopwords,\n",
    "    preprocess_for_embed, preprocess_for_bow, build_vocab, check_coverage\n",
    ")\n",
    "\n",
    "from src.features.avg_embeddings import (\n",
    "     get_average_embeddings\n",
    ")\n",
    "\n",
    "from src.models.eval_metrics import theme_results, investigate_results\n",
    "\n",
    "# Functions for preprocessing, data preparation, and evaluation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Training Word embeddings and pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Keras Deep learning functions for LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Conv1D, GlobalAveragePooling1D\n",
    "from keras.layers import GRU, concatenate\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# Classification alogrithms\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Read in Data and Embeddings </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Filepaths\n",
    "# Data Files\n",
    "fname_rawdata2018 = \"data/interim/train_2018-qualitative-data.csv\"\n",
    "fname_quant = \"data/processed/tidy_quant_questions.csv\"\n",
    "fname_legend = \"references/data-dictionaries/survey_mc_legend.csv\"\n",
    "\n",
    "# Pre-trained Embeddings\n",
    "fname_fasttext_crawl = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                       \"crawl-300d-2M.vec\"\n",
    "fname_fasttext_wiki = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                      \"wiki-news-300d-1M.vec\"\n",
    "fname_w2v_googlenews = \"./references/pretrained_embeddings.nosync/w2v/\" \\\n",
    "                       \"GoogleNews-vectors-negative300.bin\"\n",
    "fname_glove_twitter = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.twitter.27B.200d.w2v.txt\"\n",
    "fname_glove_wiki = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.6B.300d.w2v.txt\"\n",
    "fname_glove_crawl = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.840B.300d.w2v.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "df = pd.read_csv(fname_rawdata2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to load embeddings: 3242.8 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Read in pre-trained embeddings\n",
    "w2v_google_news = KeyedVectors.load_word2vec_format(fname_w2v_googlenews,\n",
    "                                                    binary=True)\n",
    "fasttext_crawl = KeyedVectors.load_word2vec_format(fname_fasttext_crawl,\n",
    "                                                   unicode_errors='ignore')\n",
    "fasttext_wiki = KeyedVectors.load_word2vec_format(fname_fasttext_wiki,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_twitter = KeyedVectors.load_word2vec_format(fname_glove_twitter,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_wiki = KeyedVectors.load_word2vec_format(fname_glove_wiki,\n",
    "                                               unicode_errors='ignore')\n",
    "glove_crawl = KeyedVectors.load_word2vec_format(fname_glove_crawl,\n",
    "                                                unicode_errors='ignore')\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Elapsed time to load embeddings: %.1f s\" % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Preprocessing and Data Preperation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userid = df[['_telkey', '2018 Comment']]\n",
    "df_userid = df_userid.rename(columns = {'_telkey':'USERID'})\n",
    "\n",
    "df = df[['2018 Comment']].join(df.loc[:,'CPD':'OTH'])\n",
    "df = df.rename(columns = {'2018 Comment' : 'comment'})\n",
    "\n",
    "Y = np.array(df.loc[:,\"CPD\":\"OTH\"])\n",
    "\n",
    "themes = df.loc[:,'CPD':'OTH'].columns.tolist()\n",
    "\n",
    "# Split the data\n",
    "df_X_train, df_X_valid, Y_train, Y_valid = train_test_split(\n",
    "        df.comment, Y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958,)\n",
      "(9958, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Quantitative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant = pd.read_csv(fname_quant).query(\"survey_year == 2018\")\n",
    "df_legend = pd.read_csv(fname_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant_train = df_userid.loc[df_X_train.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')\n",
    "\n",
    "df_quant_valid = df_userid.loc[df_X_valid.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_quant = np.array(df_quant_train.iloc[:,3:20])\n",
    "X_valid_quant = np.array(df_quant_valid.iloc[:,3:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean response for that column\n",
    "for i in range(X_train_quant.shape[1]):\n",
    "    mean_replace = np.nanmean(X_train_quant, axis = 0)[i]\n",
    "    X_train_quant[:,i][np.isnan(X_train_quant[:,i])] = mean_replace\n",
    "    X_valid_quant[:,i][np.isnan(X_valid_quant[:,i])] = mean_replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 17)\n",
      "(3320, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_quant.shape)\n",
    "print(X_valid_quant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = preprocess_for_embed(df.comment, 'w2v_base_model')\n",
    "\n",
    "w2v_base_model = Word2Vec(comments, \n",
    "                     size=300, \n",
    "                     window=5, \n",
    "                     min_count=1,\n",
    "                     sg=1, \n",
    "                     negative=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pretrained embeddings\n",
    "embeddings = {'w2v_base_model': w2v_base_model,\n",
    "              'w2v_google_news': w2v_google_news, \n",
    "              'fasttext_crawl': fasttext_crawl,\n",
    "              'fasttext_wiki': fasttext_wiki,\n",
    "              'glove_twitter': glove_twitter,\n",
    "              'glove_wiki': glove_wiki,\n",
    "              'glove_crawl': glove_crawl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Vocab Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13278/13278 [00:00<00:00, 103425.74it/s]\n",
      "100%|██████████| 13673/13673 [00:00<00:00, 48631.15it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 109039.80it/s]\n",
      "100%|██████████| 17246/17246 [00:05<00:00, 3215.21it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 107180.12it/s]\n",
      "100%|██████████| 17500/17500 [00:05<00:00, 3140.22it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 107207.56it/s]\n",
      "100%|██████████| 17500/17500 [00:08<00:00, 2070.60it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 109264.21it/s]\n",
      "100%|██████████| 13673/13673 [00:08<00:00, 1622.04it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 107913.44it/s]\n",
      "100%|██████████| 13673/13673 [00:04<00:00, 3180.99it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 93958.25it/s]\n",
      "100%|██████████| 17500/17500 [00:10<00:00, 1624.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>vocab_coverage</th>\n",
       "      <th>text_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>0.939870</td>\n",
       "      <td>0.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.953943</td>\n",
       "      <td>0.997412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>0.938514</td>\n",
       "      <td>0.996345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.887954</td>\n",
       "      <td>0.990666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.913479</td>\n",
       "      <td>0.994892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>0.997421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  vocab_coverage  text_coverage\n",
       "0   w2v_base_model        1.000000       1.000000\n",
       "1  w2v_google_news        0.939870       0.996661\n",
       "2   fasttext_crawl        0.953943       0.997412\n",
       "3    fasttext_wiki        0.938514       0.996345\n",
       "4    glove_twitter        0.887954       0.990666\n",
       "5       glove_wiki        0.913479       0.994892\n",
       "6      glove_crawl        0.953543       0.997421"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage of vocab words in embedding\n",
    "oov = {}\n",
    "vocab_coverage = []\n",
    "text_coverage = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    comments = preprocess_for_embed(df.comment, embedding)\n",
    "    vocab = build_vocab(comments)\n",
    "        \n",
    "    a, b, oov[embedding] = check_coverage(vocab, embeddings[embedding])\n",
    "    \n",
    "    vocab_coverage.append(a)\n",
    "    text_coverage.append(b)\n",
    "\n",
    "pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "              'vocab_coverage': vocab_coverage, \n",
    "              'text_coverage': text_coverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_base_model\n",
      "[]\n",
      "w2v_google_news\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('BCWS', 23)]\n",
      "fasttext_crawl\n",
      "[('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32)]\n",
      "fasttext_wiki\n",
      "[('MCFD', 128), ('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33)]\n",
      "glove_twitter\n",
      "[('2', 402), ('1', 302), ('3', 236), ('4', 171), ('5', 151)]\n",
      "glove_wiki\n",
      "[('####', 181), ('mcfd', 131), ('cymh', 54), ('#####', 49), ('bcts', 37)]\n",
      "glove_crawl\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('STIIP', 20)]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the out of vocab words for each embedding\n",
    "for i in oov.keys():\n",
    "    print(i)\n",
    "    print(oov[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Feature Engineering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Count Vectorizer to build bag of word arrays to train on\n",
    "vectorizer = CountVectorizer(stop_words= 'english',\n",
    "                             ngram_range=(1,5), \n",
    "                             min_df=2)   \n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(preprocess_for_bow(df_X_train))\n",
    "X_valid_bow = vectorizer.transform(preprocess_for_bow(df_X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 31422)\n",
      "(3320, 31422)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_valid_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Average Word Vectors per Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_avg_wv = {}\n",
    "X_valid_avg_wv = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    # Adjust features based on twitter embeddings \n",
    "    if embedding == 'glove_twitter':\n",
    "        n_features = 200\n",
    "    else:\n",
    "        n_features = 300\n",
    "    \n",
    "    # Preprocess comment data\n",
    "    comments_train = preprocess_for_embed(df_X_train, embedding)\n",
    "    comments_valid = preprocess_for_embed(df_X_valid, embedding)\n",
    "    \n",
    "    # Get average embeddings for each comment\n",
    "    # train\n",
    "    X_train_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_train])\n",
    "    \n",
    "    # valid\n",
    "    X_valid_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 300)\n",
      "(3320, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_avg_wv['w2v_base_model'].shape)\n",
    "print(X_valid_avg_wv['glove_twitter'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Embedding Matrices and Encode text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Build Embedding Matrices and prepare data for deep \n",
    "# learning Models\n",
    "max_words = 12000\n",
    "maxlen = 700\n",
    "\n",
    "# dictionaries for each embedding\n",
    "embedding_matrix = {}\n",
    "tokenizer = {}\n",
    "X_train_embed = {}\n",
    "X_valid_embed = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "\n",
    "    # Preprocess text data based on embedding\n",
    "    X_train = np.array(preprocess_for_embed(df_X_train,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    X_valid = np.array(preprocess_for_embed(df_X_valid,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    # Tokenize and pad numbers for LSTM Model\n",
    "    tokenizer[embedding] = Tokenizer(num_words=max_words)\n",
    "    tokenizer[embedding].fit_on_texts(X_train)\n",
    "    \n",
    "    tokenized_train = tokenizer[embedding].texts_to_sequences(X_train)\n",
    "    tokenized_test = tokenizer[embedding].texts_to_sequences(X_valid)\n",
    "\n",
    "    X_train_embed[embedding] = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "    X_valid_embed[embedding] = pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "    \n",
    "    \n",
    "    # Build Embedding Matrices\n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "\n",
    "    word_index = tokenizer[embedding].word_index\n",
    "    \n",
    "    num_words = min(max_words, len(word_index) + 1)\n",
    "    embedding_matrix[embedding] = np.zeros((num_words, embed_size),\n",
    "                                           dtype='float32')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "\n",
    "        if i >= max_words:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embedding_vector = embeddings[embedding][word]\n",
    "\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[embedding][i] = embedding_vector\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Classification Models </span>\n",
    "### Baseline Classifier - BOW | Linear SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyper Parameters for BOW | Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.02, 0.1, 0.5, 2.5, 12.5, 1]\n",
      "tol: [8e-05, 0.0004, 0.002, 0.01, 0.05, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for BOW | Linear SVC\n",
      "{'classifier': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=2000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.05,\n",
      "     verbose=0), 'classifier__C': 0.5, 'classifier__tol': 0.05} 0.4243824061056437\n",
      "Elapsed Training time: 5454.6 s \n",
      "Elapsed Predict time: 0.1 s\n"
     ]
    }
   ],
   "source": [
    "# t_start = time.time()\n",
    "# print(\"Grid Search for BOW | Linear SVC\")\n",
    "\n",
    "# parameters = [\n",
    "#     {\n",
    "#         'classifier':[LinearSVC(max_iter=2000)],\n",
    "#         'classifier__tol': tol,\n",
    "#         'classifier__C': C,    \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# clf1 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "# clf1.fit(X_train_bow, Y_train)\n",
    "\n",
    "# t_end_train = time.time()\n",
    "\n",
    "# print(clf1.best_params_, clf1.best_score_)\n",
    "# # Calculate and print elapsed time\n",
    "# t_end = time.time()\n",
    "# print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final BOW | Linear SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bag of words Model with Linear SVC\n",
      "Elapsed Training time: 71.4 s \n",
      "Elapsed Predict time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Training Bag of words Model with Linear SVC\")\n",
    "\n",
    "model_bow = BinaryRelevance(\n",
    "    classifier = LinearSVC(C = 0.5, tol = 0.2)\n",
    ")\n",
    "\n",
    "model_bow.fit(X_train_bow, Y_train)\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_bow = model_bow.predict(X_valid_bow).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bow = pd.DataFrame({'Model': 'BOW | LinearSVC',\n",
    "                            'train_time': [71.4],\n",
    "                            'predict_time': [13.1],\n",
    "                            'overall_accuracy': [metrics.accuracy_score(Y_valid, \n",
    "                                                                       Y_pred_bow)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4512 \n",
      "Hamming Loss: 0.0721 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.112048</td>\n",
       "      <td>0.073193</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.926807</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.652482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.174096</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>0.141566</td>\n",
       "      <td>0.956928</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.854812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.932229</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.432143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.089157</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.918675</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.538012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.974096</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.082229</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.934036</td>\n",
       "      <td>0.684982</td>\n",
       "      <td>0.584375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.426056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.111145</td>\n",
       "      <td>0.105723</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>0.598916</td>\n",
       "      <td>0.521226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.134639</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.884940</td>\n",
       "      <td>0.689038</td>\n",
       "      <td>0.558984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.211145</td>\n",
       "      <td>0.071687</td>\n",
       "      <td>0.156928</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>0.871612</td>\n",
       "      <td>0.805007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.113855</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.112048  0.073193    0.054217  0.926807   \n",
       "1     CB      0.184639         0.174096  0.043072    0.141566  0.956928   \n",
       "2    EWC      0.084337         0.056325  0.067771    0.016566  0.932229   \n",
       "3   Exec      0.103012         0.089157  0.081325    0.021687  0.918675   \n",
       "4    FWE      0.062048         0.054217  0.025904    0.036145  0.974096   \n",
       "5     SP      0.096386         0.082229  0.065964    0.030422  0.934036   \n",
       "6     RE      0.085542         0.062952  0.075602    0.009940  0.924398   \n",
       "7    Sup      0.127711         0.111145  0.105723    0.021988  0.894277   \n",
       "8     SW      0.165964         0.134639  0.115060    0.050904  0.884940   \n",
       "9   TEPE      0.228614         0.211145  0.071687    0.156928  0.928313   \n",
       "10   VMG      0.135542         0.108434  0.113855    0.021687  0.886145   \n",
       "11   OTH      0.027711         0.017470  0.026506    0.001205  0.973494   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.741935  0.652482  \n",
       "1    0.906574  0.854812  \n",
       "2    0.647059  0.432143  \n",
       "3    0.621622  0.538012  \n",
       "4    0.833333  0.728155  \n",
       "5    0.684982  0.584375  \n",
       "6    0.578947  0.426056  \n",
       "7    0.598916  0.521226  \n",
       "8    0.689038  0.558984  \n",
       "9    0.871612  0.805007  \n",
       "10   0.600000  0.480000  \n",
       "11   0.534483  0.336957  "
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, Y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_pred: (3320, 12)\n",
      "Zeros predicted: (466, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_pred:\",Y_pred_bow.shape)\n",
    "print(\"Zeros predicted:\",Y_pred_bow[Y_pred_bow.sum(axis = 1) == 0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Vectors | LogReg SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyperparameters for Avg WV | LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding in embeddings.keys():\n",
    "    \n",
    "#     print(\"Grid Search on: \", embedding)\n",
    "#     t_start = time.time()\n",
    "\n",
    "#     parameters = [\n",
    "#         {\n",
    "#             'classifier':[LogisticRegression(solver = 'lbfgs', max_iter=500)],\n",
    "#             'classifier__tol': tol,\n",
    "#             'classifier__C': C,\n",
    "        \n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     clf2 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "#     clf2.fit(X_train_avg_wv[embedding], Y_train)\n",
    "\n",
    "#     t_end_train = time.time()\n",
    "\n",
    "#     print(clf2.best_params_, clf2.best_score_)\n",
    "#     # Calculate and print elapsed time\n",
    "#     t_end = time.time()\n",
    "#     print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Avg WV | LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>6.191823</td>\n",
       "      <td>0.065399</td>\n",
       "      <td>0.360843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4.602850</td>\n",
       "      <td>0.222380</td>\n",
       "      <td>0.406325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>5.089044</td>\n",
       "      <td>0.190777</td>\n",
       "      <td>0.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4.718872</td>\n",
       "      <td>0.276683</td>\n",
       "      <td>0.398795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>7.091348</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>9.596981</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>8.432222</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.409337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model    6.191823      0.065399          0.360843\n",
       "1  w2v_google_news    4.602850      0.222380          0.406325\n",
       "2   fasttext_crawl    5.089044      0.190777          0.421687\n",
       "3    fasttext_wiki    4.718872      0.276683          0.398795\n",
       "4    glove_twitter    7.091348      0.339133          0.354217\n",
       "5       glove_wiki    9.596981      0.359630          0.406024\n",
       "6      glove_crawl    8.432222      0.280792          0.409337"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_avg_wv = {}\n",
    "model_avg_wv = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "\n",
    "    clf = BinaryRelevance(\n",
    "        classifier = LogisticRegression(solver = 'lbfgs', max_iter=500, C = 7.5,\n",
    "                                        tol = 0.05)\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_avg_wv[embedding], Y_train)\n",
    "    t_end_train = time.time()\n",
    "\n",
    "    Y_pred_avg_wv[embedding] = clf.predict_proba(X_valid_avg_wv[embedding]) \\\n",
    "                                  .toarray()\n",
    "    model_avg_wv[embedding] = clf\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_avg_wv[embedding])))\n",
    "\n",
    "results_avg_wv = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                               'train_time': train_time,\n",
    "                               'predict_time': predict_time,\n",
    "                               'overall_accuracy': accuarcies})\n",
    "\n",
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv1d = {}\n",
    "Y_pred_conv1d = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1d Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/10\n",
      "8464/8464 [==============================] - 153s 18ms/step - loss: 0.3937 - acc: 0.8712 - val_loss: 0.3376 - val_acc: 0.8881\n",
      "Epoch 2/10\n",
      "8464/8464 [==============================] - 145s 17ms/step - loss: 0.2891 - acc: 0.8991 - val_loss: 0.2400 - val_acc: 0.9156\n",
      "Epoch 3/10\n",
      "8464/8464 [==============================] - 137s 16ms/step - loss: 0.2173 - acc: 0.9205 - val_loss: 0.2075 - val_acc: 0.9261\n",
      "Epoch 4/10\n",
      "8464/8464 [==============================] - 136s 16ms/step - loss: 0.1770 - acc: 0.9327 - val_loss: 0.1956 - val_acc: 0.9292\n",
      "Epoch 5/10\n",
      "8464/8464 [==============================] - 139s 16ms/step - loss: 0.1476 - acc: 0.9442 - val_loss: 0.1837 - val_acc: 0.9318\n",
      "Epoch 6/10\n",
      "8464/8464 [==============================] - 134s 16ms/step - loss: 0.1216 - acc: 0.9534 - val_loss: 0.1812 - val_acc: 0.9328\n",
      "Epoch 7/10\n",
      "8464/8464 [==============================] - 137s 16ms/step - loss: 0.0984 - acc: 0.9634 - val_loss: 0.1851 - val_acc: 0.9322\n",
      "Epoch 8/10\n",
      "8464/8464 [==============================] - 137s 16ms/step - loss: 0.0799 - acc: 0.9710 - val_loss: 0.1917 - val_acc: 0.9317\n",
      "Epoch 9/10\n",
      "8464/8464 [==============================] - 135s 16ms/step - loss: 0.0622 - acc: 0.9780 - val_loss: 0.2030 - val_acc: 0.9298\n",
      "Epoch 10/10\n",
      "8464/8464 [==============================] - 136s 16ms/step - loss: 0.0474 - acc: 0.9840 - val_loss: 0.2156 - val_acc: 0.9325\n"
     ]
    }
   ],
   "source": [
    "max_features = 12000\n",
    "maxlen = 700\n",
    "batch_size = 128\n",
    "embed_size = 300\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features,\n",
    "                    embed_size,\n",
    "                    input_length = maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_embed['glove_crawl'],\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs, \n",
    "          validation_split=0.15)\n",
    "\n",
    "model_conv1d['base'] = model\n",
    "\n",
    "Y_pred_conv1d['base'] = model.predict(X_valid_embed['glove_crawl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w2v_base_model': <keras.engine.sequential.Sequential at 0x1db127e710>,\n",
       " 'w2v_google_news': <keras.engine.sequential.Sequential at 0x1db11f3198>,\n",
       " 'fasttext_crawl': <keras.engine.sequential.Sequential at 0x1db24d2588>,\n",
       " 'fasttext_wiki': <keras.engine.sequential.Sequential at 0x1db161f048>,\n",
       " 'glove_twitter': <keras.engine.sequential.Sequential at 0x1db1773f98>,\n",
       " 'glove_wiki': <keras.engine.sequential.Sequential at 0x1db17734a8>,\n",
       " 'glove_crawl': <keras.engine.sequential.Sequential at 0x1db1a859e8>}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5054 \n",
      "Hamming Loss: 0.0666 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_count</th>\n",
       "      <th>Pred_count</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>423</td>\n",
       "      <td>441</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.932530</td>\n",
       "      <td>0.725624</td>\n",
       "      <td>0.756501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>613</td>\n",
       "      <td>587</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.148494</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.919932</td>\n",
       "      <td>0.880914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>280</td>\n",
       "      <td>139</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.938253</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>0.382143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>342</td>\n",
       "      <td>277</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.028012</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.667870</td>\n",
       "      <td>0.540936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>206</td>\n",
       "      <td>173</td>\n",
       "      <td>0.026807</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.973193</td>\n",
       "      <td>0.838150</td>\n",
       "      <td>0.703883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>320</td>\n",
       "      <td>266</td>\n",
       "      <td>0.063855</td>\n",
       "      <td>0.032530</td>\n",
       "      <td>0.936145</td>\n",
       "      <td>0.703008</td>\n",
       "      <td>0.584375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>284</td>\n",
       "      <td>182</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>0.933133</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.429577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>424</td>\n",
       "      <td>430</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.028313</td>\n",
       "      <td>0.900602</td>\n",
       "      <td>0.609302</td>\n",
       "      <td>0.617925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>551</td>\n",
       "      <td>512</td>\n",
       "      <td>0.105723</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.646098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>759</td>\n",
       "      <td>775</td>\n",
       "      <td>0.066867</td>\n",
       "      <td>0.161747</td>\n",
       "      <td>0.933133</td>\n",
       "      <td>0.846452</td>\n",
       "      <td>0.864295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>450</td>\n",
       "      <td>400</td>\n",
       "      <td>0.103614</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>0.896386</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>0.562222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>92</td>\n",
       "      <td>32</td>\n",
       "      <td>0.025301</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.974699</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_count  Pred_count     Error  Dummy_Diff  Accuarcy  Precision  \\\n",
       "0    CPD      423         441  0.067470    0.059940  0.932530   0.725624   \n",
       "1     CB      613         587  0.036145    0.148494  0.963855   0.919932   \n",
       "2    EWC      280         139  0.061747    0.022590  0.938253   0.769784   \n",
       "3   Exec      342         277  0.075000    0.028012  0.925000   0.667870   \n",
       "4    FWE      206         173  0.026807    0.035241  0.973193   0.838150   \n",
       "5     SP      320         266  0.063855    0.032530  0.936145   0.703008   \n",
       "6     RE      284         182  0.066867    0.018675  0.933133   0.670330   \n",
       "7    Sup      424         430  0.099398    0.028313  0.900602   0.609302   \n",
       "8     SW      551         512  0.105723    0.060241  0.894277   0.695312   \n",
       "9   TEPE      759         775  0.066867    0.161747  0.933133   0.846452   \n",
       "10   VMG      450         400  0.103614    0.031928  0.896386   0.632500   \n",
       "11   OTH       92          32  0.025301    0.002410  0.974699   0.625000   \n",
       "\n",
       "      Recall  \n",
       "0   0.756501  \n",
       "1   0.880914  \n",
       "2   0.382143  \n",
       "3   0.540936  \n",
       "4   0.703883  \n",
       "5   0.584375  \n",
       "6   0.429577  \n",
       "7   0.617925  \n",
       "8   0.646098  \n",
       "9   0.864295  \n",
       "10  0.562222  \n",
       "11  0.217391  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_conv1d['base']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv1d with pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Conv1d on the  w2v_base_model\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 107s 13ms/step - loss: 0.3550 - acc: 0.8799 - val_loss: 0.2717 - val_acc: 0.9070\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 103s 12ms/step - loss: 0.2582 - acc: 0.9070 - val_loss: 0.2228 - val_acc: 0.9173\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 103s 12ms/step - loss: 0.2248 - acc: 0.9159 - val_loss: 0.2080 - val_acc: 0.9231\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 102s 12ms/step - loss: 0.2113 - acc: 0.9200 - val_loss: 0.2028 - val_acc: 0.9253\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 97s 11ms/step - loss: 0.2020 - acc: 0.9239 - val_loss: 0.1978 - val_acc: 0.9265\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 95s 11ms/step - loss: 0.1944 - acc: 0.9258 - val_loss: 0.1910 - val_acc: 0.9284\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.1863 - acc: 0.9292 - val_loss: 0.1902 - val_acc: 0.9283\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.1806 - acc: 0.9305 - val_loss: 0.1911 - val_acc: 0.9290\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1751 - acc: 0.9324 - val_loss: 0.1862 - val_acc: 0.9294\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1691 - acc: 0.9343 - val_loss: 0.1871 - val_acc: 0.9302\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1651 - acc: 0.9356 - val_loss: 0.1861 - val_acc: 0.9314\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1596 - acc: 0.9381 - val_loss: 0.1855 - val_acc: 0.9295\n",
      "Training Conv1d on the  w2v_google_news\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.3683 - acc: 0.8778 - val_loss: 0.2814 - val_acc: 0.9072\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.2552 - acc: 0.9105 - val_loss: 0.2164 - val_acc: 0.9228\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.2068 - acc: 0.9228 - val_loss: 0.1933 - val_acc: 0.9287\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1811 - acc: 0.9316 - val_loss: 0.1816 - val_acc: 0.9333\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1657 - acc: 0.9364 - val_loss: 0.1762 - val_acc: 0.9353\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1513 - acc: 0.9412 - val_loss: 0.1750 - val_acc: 0.9352\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1400 - acc: 0.9460 - val_loss: 0.1713 - val_acc: 0.9361\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1283 - acc: 0.9500 - val_loss: 0.1723 - val_acc: 0.9366\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1203 - acc: 0.9532 - val_loss: 0.1771 - val_acc: 0.9353\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1106 - acc: 0.9571 - val_loss: 0.1784 - val_acc: 0.9353\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1018 - acc: 0.9610 - val_loss: 0.1775 - val_acc: 0.9352\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.0937 - acc: 0.9639 - val_loss: 0.1797 - val_acc: 0.9366\n",
      "Training Conv1d on the  fasttext_crawl\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.3559 - acc: 0.8810 - val_loss: 0.2594 - val_acc: 0.9109\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.2347 - acc: 0.9147 - val_loss: 0.2007 - val_acc: 0.9264\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1929 - acc: 0.9273 - val_loss: 0.1836 - val_acc: 0.9312\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1704 - acc: 0.9348 - val_loss: 0.1772 - val_acc: 0.9340\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1558 - acc: 0.9396 - val_loss: 0.1706 - val_acc: 0.9359\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1415 - acc: 0.9446 - val_loss: 0.1705 - val_acc: 0.9370\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1293 - acc: 0.9489 - val_loss: 0.1722 - val_acc: 0.9361\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1189 - acc: 0.9537 - val_loss: 0.1685 - val_acc: 0.9383\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1075 - acc: 0.9586 - val_loss: 0.1729 - val_acc: 0.9380\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.0980 - acc: 0.9617 - val_loss: 0.1738 - val_acc: 0.9395\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.0889 - acc: 0.9665 - val_loss: 0.1788 - val_acc: 0.9375\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.0812 - acc: 0.9695 - val_loss: 0.1790 - val_acc: 0.9369\n",
      "Training Conv1d on the  fasttext_wiki\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.3764 - acc: 0.8777 - val_loss: 0.3040 - val_acc: 0.9016\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.2700 - acc: 0.9061 - val_loss: 0.2260 - val_acc: 0.9200\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.2176 - acc: 0.9193 - val_loss: 0.2030 - val_acc: 0.9248\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1934 - acc: 0.9263 - val_loss: 0.1873 - val_acc: 0.9302\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 96s 11ms/step - loss: 0.1751 - acc: 0.9330 - val_loss: 0.1773 - val_acc: 0.9326\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1608 - acc: 0.9384 - val_loss: 0.1732 - val_acc: 0.9346\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1509 - acc: 0.9416 - val_loss: 0.1725 - val_acc: 0.9346\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 101s 12ms/step - loss: 0.1417 - acc: 0.9453 - val_loss: 0.1716 - val_acc: 0.9360\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 96s 11ms/step - loss: 0.1299 - acc: 0.9494 - val_loss: 0.1696 - val_acc: 0.9370\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 95s 11ms/step - loss: 0.1216 - acc: 0.9528 - val_loss: 0.1695 - val_acc: 0.9361\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.1146 - acc: 0.9555 - val_loss: 0.1703 - val_acc: 0.9381\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1056 - acc: 0.9594 - val_loss: 0.1687 - val_acc: 0.9376\n",
      "Training Conv1d on the  glove_twitter\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 72s 8ms/step - loss: 0.3611 - acc: 0.8782 - val_loss: 0.2810 - val_acc: 0.9004\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.2652 - acc: 0.9051 - val_loss: 0.2312 - val_acc: 0.9149\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 71s 8ms/step - loss: 0.2281 - acc: 0.9154 - val_loss: 0.2105 - val_acc: 0.9232\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.2045 - acc: 0.9232 - val_loss: 0.1958 - val_acc: 0.9282\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 71s 8ms/step - loss: 0.1862 - acc: 0.9292 - val_loss: 0.1891 - val_acc: 0.9298\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1736 - acc: 0.9338 - val_loss: 0.1874 - val_acc: 0.9291\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1613 - acc: 0.9392 - val_loss: 0.1831 - val_acc: 0.9322\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1533 - acc: 0.9413 - val_loss: 0.1819 - val_acc: 0.9315\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1436 - acc: 0.9450 - val_loss: 0.1829 - val_acc: 0.9335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1343 - acc: 0.9483 - val_loss: 0.1825 - val_acc: 0.9332\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1285 - acc: 0.9509 - val_loss: 0.1843 - val_acc: 0.9353\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 70s 8ms/step - loss: 0.1194 - acc: 0.9540 - val_loss: 0.1828 - val_acc: 0.9334\n",
      "Training Conv1d on the  glove_wiki\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.3514 - acc: 0.8819 - val_loss: 0.2581 - val_acc: 0.9101\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.2393 - acc: 0.9138 - val_loss: 0.2091 - val_acc: 0.9268\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.2025 - acc: 0.9250 - val_loss: 0.1922 - val_acc: 0.9299\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 91s 11ms/step - loss: 0.1802 - acc: 0.9313 - val_loss: 0.1821 - val_acc: 0.9327\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1643 - acc: 0.9374 - val_loss: 0.1803 - val_acc: 0.9345\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1504 - acc: 0.9426 - val_loss: 0.1766 - val_acc: 0.9357\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1390 - acc: 0.9465 - val_loss: 0.1772 - val_acc: 0.9370\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1270 - acc: 0.9512 - val_loss: 0.1772 - val_acc: 0.9374\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.1176 - acc: 0.9549 - val_loss: 0.1784 - val_acc: 0.9352\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1076 - acc: 0.9591 - val_loss: 0.1881 - val_acc: 0.9332\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.0985 - acc: 0.9624 - val_loss: 0.1883 - val_acc: 0.9342\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.0900 - acc: 0.9659 - val_loss: 0.1946 - val_acc: 0.9361\n",
      "Training Conv1d on the  glove_crawl\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.3425 - acc: 0.8835 - val_loss: 0.2480 - val_acc: 0.9109\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.2341 - acc: 0.9150 - val_loss: 0.2035 - val_acc: 0.9254\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1968 - acc: 0.9268 - val_loss: 0.1893 - val_acc: 0.9290\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1764 - acc: 0.9334 - val_loss: 0.1793 - val_acc: 0.9337\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1604 - acc: 0.9392 - val_loss: 0.1787 - val_acc: 0.9348\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 94s 11ms/step - loss: 0.1473 - acc: 0.9432 - val_loss: 0.1753 - val_acc: 0.9362\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1357 - acc: 0.9480 - val_loss: 0.1746 - val_acc: 0.9357\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1260 - acc: 0.9515 - val_loss: 0.1736 - val_acc: 0.9361\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.1161 - acc: 0.9556 - val_loss: 0.1834 - val_acc: 0.9319\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 93s 11ms/step - loss: 0.1065 - acc: 0.9589 - val_loss: 0.1861 - val_acc: 0.9358\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.0974 - acc: 0.9624 - val_loss: 0.1844 - val_acc: 0.9353\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 92s 11ms/step - loss: 0.0874 - acc: 0.9666 - val_loss: 0.1867 - val_acc: 0.9355\n"
     ]
    }
   ],
   "source": [
    "max_features = 12000\n",
    "maxlen = 700\n",
    "batch_size = 128\n",
    "embed_size = 300\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "epochs = 12\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "    print(\"Training Conv1d on the \", embedding)\n",
    "    \n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "    \n",
    "    # Neural Net Architecture\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(max_features, embed_size,\n",
    "                        weights=[embedding_matrix[embedding]], \n",
    "                        trainable=False,\n",
    "                        input_length = maxlen))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(hidden_dims))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train Model\n",
    "    model.fit(X_train_embed[embedding],\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, \n",
    "              validation_split=0.15)\n",
    "    t_end_train = time.time()\n",
    "    \n",
    "    model_conv1d[embedding] = model\n",
    "\n",
    "    Y_pred_conv1d[embedding] = model.predict(X_valid_embed[embedding])\n",
    "    \n",
    "    # Calculate and report results\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_conv1d[embedding])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>4580.003196</td>\n",
       "      <td>46.396283</td>\n",
       "      <td>0.481325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4564.827096</td>\n",
       "      <td>45.402777</td>\n",
       "      <td>0.507831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>4477.700824</td>\n",
       "      <td>49.579227</td>\n",
       "      <td>0.517771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4582.388079</td>\n",
       "      <td>42.911012</td>\n",
       "      <td>0.499096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>3269.476459</td>\n",
       "      <td>33.189079</td>\n",
       "      <td>0.497289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>3860.588047</td>\n",
       "      <td>41.263492</td>\n",
       "      <td>0.497892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>4357.161348</td>\n",
       "      <td>48.177288</td>\n",
       "      <td>0.513554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  4580.003196     46.396283          0.481325\n",
       "1  w2v_google_news  4564.827096     45.402777          0.507831\n",
       "2   fasttext_crawl  4477.700824     49.579227          0.517771\n",
       "3    fasttext_wiki  4582.388079     42.911012          0.499096\n",
       "4    glove_twitter  3269.476459     33.189079          0.497289\n",
       "5       glove_wiki  3860.588047     41.263492          0.497892\n",
       "6      glove_crawl  4357.161348     48.177288          0.513554"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_conv1d = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                               'train_time': train_time,\n",
    "                               'predict_time': predict_time,\n",
    "                               'overall_accuracy': accuarcies})\n",
    "\n",
    "results_conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional GRU Model with Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BiGRU on the  w2v_base_model\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 361s 36ms/step - loss: 0.3351 - acc: 0.8857 - val_loss: 0.2583 - val_acc: 0.9056\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 374s 38ms/step - loss: 0.2425 - acc: 0.9101 - val_loss: 0.2207 - val_acc: 0.9171\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 369s 37ms/step - loss: 0.2155 - acc: 0.9196 - val_loss: 0.2063 - val_acc: 0.9231\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 384s 39ms/step - loss: 0.2033 - acc: 0.9229 - val_loss: 0.1976 - val_acc: 0.9255\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 380s 38ms/step - loss: 0.1928 - acc: 0.9267 - val_loss: 0.1883 - val_acc: 0.9284\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 387s 39ms/step - loss: 0.1862 - acc: 0.9290 - val_loss: 0.1878 - val_acc: 0.9296\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 388s 39ms/step - loss: 0.1815 - acc: 0.9309 - val_loss: 0.1855 - val_acc: 0.9296\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 386s 39ms/step - loss: 0.1752 - acc: 0.9328 - val_loss: 0.1812 - val_acc: 0.9315\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 384s 39ms/step - loss: 0.1715 - acc: 0.9343 - val_loss: 0.1812 - val_acc: 0.9301\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 375s 38ms/step - loss: 0.1666 - acc: 0.9358 - val_loss: 0.1805 - val_acc: 0.9324\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 394s 40ms/step - loss: 0.1624 - acc: 0.9375 - val_loss: 0.1804 - val_acc: 0.9315\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 395s 40ms/step - loss: 0.1586 - acc: 0.9395 - val_loss: 0.1783 - val_acc: 0.9327\n",
      "Training BiGRU on the  w2v_google_news\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 415s 42ms/step - loss: 0.3677 - acc: 0.8767 - val_loss: 0.2829 - val_acc: 0.9029\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 439s 44ms/step - loss: 0.2566 - acc: 0.9083 - val_loss: 0.2258 - val_acc: 0.9172\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 372s 37ms/step - loss: 0.2194 - acc: 0.9181 - val_loss: 0.2030 - val_acc: 0.9234\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 370s 37ms/step - loss: 0.1981 - acc: 0.9261 - val_loss: 0.1914 - val_acc: 0.9273\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 374s 38ms/step - loss: 0.1841 - acc: 0.9305 - val_loss: 0.1838 - val_acc: 0.9308\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 385s 39ms/step - loss: 0.1735 - acc: 0.9345 - val_loss: 0.1773 - val_acc: 0.9340\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 391s 39ms/step - loss: 0.1664 - acc: 0.9366 - val_loss: 0.1731 - val_acc: 0.9351\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 401s 40ms/step - loss: 0.1587 - acc: 0.9389 - val_loss: 0.1705 - val_acc: 0.9361\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 360s 36ms/step - loss: 0.1513 - acc: 0.9422 - val_loss: 0.1701 - val_acc: 0.9356\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 352s 35ms/step - loss: 0.1454 - acc: 0.9439 - val_loss: 0.1682 - val_acc: 0.9370\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 348s 35ms/step - loss: 0.1393 - acc: 0.9462 - val_loss: 0.1662 - val_acc: 0.9377\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 351s 35ms/step - loss: 0.1348 - acc: 0.9479 - val_loss: 0.1674 - val_acc: 0.9365\n",
      "Training BiGRU on the  fasttext_crawl\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 351s 35ms/step - loss: 0.3544 - acc: 0.8779 - val_loss: 0.2603 - val_acc: 0.9071\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 343s 34ms/step - loss: 0.2347 - acc: 0.9143 - val_loss: 0.2059 - val_acc: 0.9227\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 371s 37ms/step - loss: 0.1980 - acc: 0.9258 - val_loss: 0.1851 - val_acc: 0.9297\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 374s 38ms/step - loss: 0.1799 - acc: 0.9318 - val_loss: 0.1777 - val_acc: 0.9331\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 364s 37ms/step - loss: 0.1676 - acc: 0.9361 - val_loss: 0.1703 - val_acc: 0.9347\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 374s 38ms/step - loss: 0.1586 - acc: 0.9397 - val_loss: 0.1686 - val_acc: 0.9365\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 356s 36ms/step - loss: 0.1502 - acc: 0.9425 - val_loss: 0.1644 - val_acc: 0.9376\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 428s 43ms/step - loss: 0.1419 - acc: 0.9453 - val_loss: 0.1646 - val_acc: 0.9377\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 382s 38ms/step - loss: 0.1359 - acc: 0.9478 - val_loss: 0.1627 - val_acc: 0.9380\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 373s 37ms/step - loss: 0.1285 - acc: 0.9505 - val_loss: 0.1617 - val_acc: 0.9385\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 354s 36ms/step - loss: 0.1225 - acc: 0.9530 - val_loss: 0.1634 - val_acc: 0.9380\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 403s 40ms/step - loss: 0.1158 - acc: 0.9556 - val_loss: 0.1642 - val_acc: 0.9380\n",
      "Training BiGRU on the  fasttext_wiki\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 476s 48ms/step - loss: 0.3763 - acc: 0.8754 - val_loss: 0.3070 - val_acc: 0.8914\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 382s 38ms/step - loss: 0.2653 - acc: 0.9050 - val_loss: 0.2279 - val_acc: 0.9157\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 390s 39ms/step - loss: 0.2201 - acc: 0.9176 - val_loss: 0.2022 - val_acc: 0.9248\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 371s 37ms/step - loss: 0.1993 - acc: 0.9247 - val_loss: 0.1907 - val_acc: 0.9280\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 360s 36ms/step - loss: 0.1860 - acc: 0.9298 - val_loss: 0.1832 - val_acc: 0.9315\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 349s 35ms/step - loss: 0.1767 - acc: 0.9331 - val_loss: 0.1780 - val_acc: 0.9328\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 351s 35ms/step - loss: 0.1681 - acc: 0.9355 - val_loss: 0.1729 - val_acc: 0.9347\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 345s 35ms/step - loss: 0.1618 - acc: 0.9379 - val_loss: 0.1701 - val_acc: 0.9351\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 340s 34ms/step - loss: 0.1559 - acc: 0.9405 - val_loss: 0.1700 - val_acc: 0.9348\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 341s 34ms/step - loss: 0.1504 - acc: 0.9421 - val_loss: 0.1682 - val_acc: 0.9361\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 338s 34ms/step - loss: 0.1468 - acc: 0.9436 - val_loss: 0.1663 - val_acc: 0.9366\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 342s 34ms/step - loss: 0.1415 - acc: 0.9456 - val_loss: 0.1670 - val_acc: 0.9355\n",
      "Training BiGRU on the  glove_twitter\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 291s 29ms/step - loss: 0.3612 - acc: 0.8750 - val_loss: 0.2893 - val_acc: 0.9022\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 284s 29ms/step - loss: 0.2677 - acc: 0.9046 - val_loss: 0.2362 - val_acc: 0.9123\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 280s 28ms/step - loss: 0.2288 - acc: 0.9152 - val_loss: 0.2115 - val_acc: 0.9216\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 268s 27ms/step - loss: 0.2045 - acc: 0.9242 - val_loss: 0.1965 - val_acc: 0.9263\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 267s 27ms/step - loss: 0.1877 - acc: 0.9301 - val_loss: 0.1913 - val_acc: 0.9274\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 267s 27ms/step - loss: 0.1754 - acc: 0.9343 - val_loss: 0.1864 - val_acc: 0.9294\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 267s 27ms/step - loss: 0.1662 - acc: 0.9377 - val_loss: 0.1804 - val_acc: 0.9317\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 268s 27ms/step - loss: 0.1560 - acc: 0.9410 - val_loss: 0.1790 - val_acc: 0.9327\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 268s 27ms/step - loss: 0.1470 - acc: 0.9443 - val_loss: 0.1778 - val_acc: 0.9337\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 270s 27ms/step - loss: 0.1389 - acc: 0.9472 - val_loss: 0.1795 - val_acc: 0.9337\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 267s 27ms/step - loss: 0.1314 - acc: 0.9502 - val_loss: 0.1785 - val_acc: 0.9333\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 266s 27ms/step - loss: 0.1222 - acc: 0.9541 - val_loss: 0.1811 - val_acc: 0.9346\n",
      "Training BiGRU on the  glove_wiki\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 329s 33ms/step - loss: 0.3489 - acc: 0.8770 - val_loss: 0.2647 - val_acc: 0.9077\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 320s 32ms/step - loss: 0.2447 - acc: 0.9122 - val_loss: 0.2200 - val_acc: 0.9201\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 341s 34ms/step - loss: 0.2086 - acc: 0.9232 - val_loss: 0.1990 - val_acc: 0.9271\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 320s 32ms/step - loss: 0.1865 - acc: 0.9307 - val_loss: 0.1860 - val_acc: 0.9309\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.1707 - acc: 0.9355 - val_loss: 0.1820 - val_acc: 0.9312\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.1586 - acc: 0.9402 - val_loss: 0.1745 - val_acc: 0.9349\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 319s 32ms/step - loss: 0.1487 - acc: 0.9435 - val_loss: 0.1737 - val_acc: 0.9343\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 319s 32ms/step - loss: 0.1382 - acc: 0.9478 - val_loss: 0.1725 - val_acc: 0.9357\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.1293 - acc: 0.9507 - val_loss: 0.1716 - val_acc: 0.9357\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 316s 32ms/step - loss: 0.1200 - acc: 0.9547 - val_loss: 0.1767 - val_acc: 0.9347\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.1114 - acc: 0.9576 - val_loss: 0.1780 - val_acc: 0.9348\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 321s 32ms/step - loss: 0.1019 - acc: 0.9619 - val_loss: 0.1801 - val_acc: 0.9339\n",
      "Training BiGRU on the  glove_crawl\n",
      "Train on 9958 samples, validate on 3320 samples\n",
      "Epoch 1/12\n",
      "9958/9958 [==============================] - 323s 32ms/step - loss: 0.3378 - acc: 0.8835 - val_loss: 0.2572 - val_acc: 0.9076\n",
      "Epoch 2/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.2340 - acc: 0.9153 - val_loss: 0.2053 - val_acc: 0.9254\n",
      "Epoch 3/12\n",
      "9958/9958 [==============================] - 317s 32ms/step - loss: 0.1964 - acc: 0.9269 - val_loss: 0.1876 - val_acc: 0.9296\n",
      "Epoch 4/12\n",
      "9958/9958 [==============================] - 382s 38ms/step - loss: 0.1784 - acc: 0.9330 - val_loss: 0.1813 - val_acc: 0.9311\n",
      "Epoch 5/12\n",
      "9958/9958 [==============================] - 359s 36ms/step - loss: 0.1653 - acc: 0.9375 - val_loss: 0.1752 - val_acc: 0.9346\n",
      "Epoch 6/12\n",
      "9958/9958 [==============================] - 360s 36ms/step - loss: 0.1539 - acc: 0.9412 - val_loss: 0.1699 - val_acc: 0.9362\n",
      "Epoch 7/12\n",
      "9958/9958 [==============================] - 369s 37ms/step - loss: 0.1445 - acc: 0.9450 - val_loss: 0.1687 - val_acc: 0.9362\n",
      "Epoch 8/12\n",
      "9958/9958 [==============================] - 385s 39ms/step - loss: 0.1355 - acc: 0.9475 - val_loss: 0.1669 - val_acc: 0.9369\n",
      "Epoch 9/12\n",
      "9958/9958 [==============================] - 377s 38ms/step - loss: 0.1268 - acc: 0.9515 - val_loss: 0.1672 - val_acc: 0.9368\n",
      "Epoch 10/12\n",
      "9958/9958 [==============================] - 425s 43ms/step - loss: 0.1195 - acc: 0.9540 - val_loss: 0.1689 - val_acc: 0.9378\n",
      "Epoch 11/12\n",
      "9958/9958 [==============================] - 375s 38ms/step - loss: 0.1119 - acc: 0.9572 - val_loss: 0.1717 - val_acc: 0.9368\n",
      "Epoch 12/12\n",
      "9958/9958 [==============================] - 364s 37ms/step - loss: 0.1041 - acc: 0.9606 - val_loss: 0.1737 - val_acc: 0.9374\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model and train and validate\n",
    "Y_pred_biGRU = {}\n",
    "model_biGRU = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "    print(\"Training BiGRU on the \", embedding)\n",
    "    \n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "    \n",
    "    # Deep Learning Architecture\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(max_words, embed_size, \n",
    "                  weights=[embedding_matrix[embedding]], \n",
    "                  trainable=False)(inp)\n",
    "\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1,\n",
    "                          recurrent_dropout=0.1))(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, padding=\"valid\", \n",
    "               kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    preds = Dense(12, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train and Predict Model\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    model.fit(X_train_embed[embedding],\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, \n",
    "              validation_data = (X_valid_embed[embedding],\n",
    "                                 Y_valid))\n",
    "    t_end_train = time.time()\n",
    "    \n",
    "    Y_pred_biGRU[embedding] = model.predict(X_valid_embed[embedding])\n",
    "    model_biGRU[embedding] = model\n",
    "\n",
    "    # Calculate and report results\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_biGRU[embedding])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>4580.003196</td>\n",
       "      <td>46.396283</td>\n",
       "      <td>0.481325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4564.827096</td>\n",
       "      <td>45.402777</td>\n",
       "      <td>0.507831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>4477.700824</td>\n",
       "      <td>49.579227</td>\n",
       "      <td>0.517771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4582.388079</td>\n",
       "      <td>42.911012</td>\n",
       "      <td>0.499096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>3269.476459</td>\n",
       "      <td>33.189079</td>\n",
       "      <td>0.497289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>3860.588047</td>\n",
       "      <td>41.263492</td>\n",
       "      <td>0.497892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>4357.161348</td>\n",
       "      <td>48.177288</td>\n",
       "      <td>0.513554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  4580.003196     46.396283          0.481325\n",
       "1  w2v_google_news  4564.827096     45.402777          0.507831\n",
       "2   fasttext_crawl  4477.700824     49.579227          0.517771\n",
       "3    fasttext_wiki  4582.388079     42.911012          0.499096\n",
       "4    glove_twitter  3269.476459     33.189079          0.497289\n",
       "5       glove_wiki  3860.588047     41.263492          0.497892\n",
       "6      glove_crawl  4357.161348     48.177288          0.513554"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_biGRU = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                             'train_time': train_time,\n",
    "                             'predict_time': predict_time,\n",
    "                             'overall_accuracy': accuarcies})\n",
    "\n",
    "results_biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5178 \n",
      "Hamming Loss: 0.062 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_count</th>\n",
       "      <th>Pred_count</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>423</td>\n",
       "      <td>429</td>\n",
       "      <td>0.064458</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.935542</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.754137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>613</td>\n",
       "      <td>600</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.147590</td>\n",
       "      <td>0.962952</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.889070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>280</td>\n",
       "      <td>165</td>\n",
       "      <td>0.058735</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.446429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>342</td>\n",
       "      <td>320</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.924699</td>\n",
       "      <td>0.643750</td>\n",
       "      <td>0.602339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>206</td>\n",
       "      <td>199</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.809045</td>\n",
       "      <td>0.781553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>320</td>\n",
       "      <td>219</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.940060</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>284</td>\n",
       "      <td>243</td>\n",
       "      <td>0.064759</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.935241</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>424</td>\n",
       "      <td>326</td>\n",
       "      <td>0.090964</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.909036</td>\n",
       "      <td>0.687117</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>551</td>\n",
       "      <td>539</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.069578</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.698730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>759</td>\n",
       "      <td>703</td>\n",
       "      <td>0.057229</td>\n",
       "      <td>0.171386</td>\n",
       "      <td>0.942771</td>\n",
       "      <td>0.904694</td>\n",
       "      <td>0.837945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>450</td>\n",
       "      <td>315</td>\n",
       "      <td>0.089458</td>\n",
       "      <td>0.046084</td>\n",
       "      <td>0.910542</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>92</td>\n",
       "      <td>35</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.975602</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_count  Pred_count     Error  Dummy_Diff  Accuarcy  Precision  \\\n",
       "0    CPD      423         429  0.064458    0.062952  0.935542   0.743590   \n",
       "1     CB      613         600  0.037048    0.147590  0.962952   0.908333   \n",
       "2    EWC      280         165  0.058735    0.025602  0.941265   0.757576   \n",
       "3   Exec      342         320  0.075301    0.027711  0.924699   0.643750   \n",
       "4    FWE      206         199  0.025000    0.037048  0.975000   0.809045   \n",
       "5     SP      320         219  0.059940    0.036446  0.940060   0.776256   \n",
       "6     RE      284         243  0.064759    0.020783  0.935241   0.641975   \n",
       "7    Sup      424         326  0.090964    0.036747  0.909036   0.687117   \n",
       "8     SW      551         539  0.096386    0.069578  0.903614   0.714286   \n",
       "9   TEPE      759         703  0.057229    0.171386  0.942771   0.904694   \n",
       "10   VMG      450         315  0.089458    0.046084  0.910542   0.742857   \n",
       "11   OTH       92          35  0.024398    0.003313  0.975602   0.657143   \n",
       "\n",
       "      Recall  \n",
       "0   0.754137  \n",
       "1   0.889070  \n",
       "2   0.446429  \n",
       "3   0.602339  \n",
       "4   0.781553  \n",
       "5   0.531250  \n",
       "6   0.549296  \n",
       "7   0.528302  \n",
       "8   0.698730  \n",
       "9   0.837945  \n",
       "10  0.520000  \n",
       "11  0.250000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_biGRU['fasttext_crawl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOW | LinearSVC</td>\n",
       "      <td>71.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.451205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  train_time  predict_time  overall_accuracy\n",
       "0  BOW | LinearSVC        71.4          13.1          0.451205"
      ]
     },
     "execution_count": 1092,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>6.191823</td>\n",
       "      <td>0.065399</td>\n",
       "      <td>0.360843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4.602850</td>\n",
       "      <td>0.222380</td>\n",
       "      <td>0.406325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>5.089044</td>\n",
       "      <td>0.190777</td>\n",
       "      <td>0.421687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4.718872</td>\n",
       "      <td>0.276683</td>\n",
       "      <td>0.398795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>7.091348</td>\n",
       "      <td>0.339133</td>\n",
       "      <td>0.354217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>9.596981</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>0.406024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>8.432222</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.409337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model    6.191823      0.065399          0.360843\n",
       "1  w2v_google_news    4.602850      0.222380          0.406325\n",
       "2   fasttext_crawl    5.089044      0.190777          0.421687\n",
       "3    fasttext_wiki    4.718872      0.276683          0.398795\n",
       "4    glove_twitter    7.091348      0.339133          0.354217\n",
       "5       glove_wiki    9.596981      0.359630          0.406024\n",
       "6      glove_crawl    8.432222      0.280792          0.409337"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>4580.003196</td>\n",
       "      <td>46.396283</td>\n",
       "      <td>0.481325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>4564.827096</td>\n",
       "      <td>45.402777</td>\n",
       "      <td>0.507831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>4477.700824</td>\n",
       "      <td>49.579227</td>\n",
       "      <td>0.517771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>4582.388079</td>\n",
       "      <td>42.911012</td>\n",
       "      <td>0.499096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>3269.476459</td>\n",
       "      <td>33.189079</td>\n",
       "      <td>0.497289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>3860.588047</td>\n",
       "      <td>41.263492</td>\n",
       "      <td>0.497892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>4357.161348</td>\n",
       "      <td>48.177288</td>\n",
       "      <td>0.513554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding   train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model  4580.003196     46.396283          0.481325\n",
       "1  w2v_google_news  4564.827096     45.402777          0.507831\n",
       "2   fasttext_crawl  4477.700824     49.579227          0.517771\n",
       "3    fasttext_wiki  4582.388079     42.911012          0.499096\n",
       "4    glove_twitter  3269.476459     33.189079          0.497289\n",
       "5       glove_wiki  3860.588047     41.263492          0.497892\n",
       "6      glove_crawl  4357.161348     48.177288          0.513554"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_biGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_stack = (Y_pred_biGRU['fasttext_crawl'] +\n",
    "                Y_pred_biGRU['glove_wiki'] +\n",
    "                Y_pred_biGRU['glove_twitter'] +\n",
    "                #Y_pred_biGRU['w2v_google_news'] +\n",
    "                Y_pred_conv1d['base'])/4\n",
    "\n",
    "\n",
    "# Y_pred_stack = (Y_pred_conv1d['fasttext_crawl'] +\n",
    "#                  Y_pred_biGRU['fasttext_crawl'] +\n",
    "#                  Y_pred_biGRU['glove_crawl'] +  \n",
    "#                  #Y_pred_conv1d['glove_crawl'] + \n",
    "#                  Y_pred_biGRU['w2v_google_news'] +\n",
    "#                  Y_pred_biGRU['glove_twitter'])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5355 \n",
      "Hamming Loss: 0.0587 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_count</th>\n",
       "      <th>Pred_count</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>423</td>\n",
       "      <td>398</td>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.938855</td>\n",
       "      <td>0.776382</td>\n",
       "      <td>0.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>613</td>\n",
       "      <td>588</td>\n",
       "      <td>0.031024</td>\n",
       "      <td>0.153614</td>\n",
       "      <td>0.968976</td>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.895595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>280</td>\n",
       "      <td>150</td>\n",
       "      <td>0.055422</td>\n",
       "      <td>0.028916</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.439286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>342</td>\n",
       "      <td>261</td>\n",
       "      <td>0.068976</td>\n",
       "      <td>0.034036</td>\n",
       "      <td>0.931024</td>\n",
       "      <td>0.716475</td>\n",
       "      <td>0.546784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>206</td>\n",
       "      <td>175</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.976807</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>320</td>\n",
       "      <td>226</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.940964</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>284</td>\n",
       "      <td>155</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.934639</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.390845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>424</td>\n",
       "      <td>377</td>\n",
       "      <td>0.087048</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>0.912952</td>\n",
       "      <td>0.679045</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>551</td>\n",
       "      <td>487</td>\n",
       "      <td>0.086747</td>\n",
       "      <td>0.079217</td>\n",
       "      <td>0.913253</td>\n",
       "      <td>0.770021</td>\n",
       "      <td>0.680581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>759</td>\n",
       "      <td>717</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>0.176205</td>\n",
       "      <td>0.947590</td>\n",
       "      <td>0.907950</td>\n",
       "      <td>0.857708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>450</td>\n",
       "      <td>340</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.544444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>92</td>\n",
       "      <td>25</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.976205</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.206522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_count  Pred_count     Error  Dummy_Diff  Accuarcy  Precision  \\\n",
       "0    CPD      423         398  0.061145    0.066265  0.938855   0.776382   \n",
       "1     CB      613         588  0.031024    0.153614  0.968976   0.933673   \n",
       "2    EWC      280         150  0.055422    0.028916  0.944578   0.820000   \n",
       "3   Exec      342         261  0.068976    0.034036  0.931024   0.716475   \n",
       "4    FWE      206         175  0.023193    0.038855  0.976807   0.868571   \n",
       "5     SP      320         226  0.059036    0.037349  0.940964   0.774336   \n",
       "6     RE      284         155  0.065361    0.020181  0.934639   0.716129   \n",
       "7    Sup      424         377  0.087048    0.040663  0.912952   0.679045   \n",
       "8     SW      551         487  0.086747    0.079217  0.913253   0.770021   \n",
       "9   TEPE      759         717  0.052410    0.176205  0.947590   0.907950   \n",
       "10   VMG      450         340  0.090361    0.045181  0.909639   0.720588   \n",
       "11   OTH       92          25  0.023795    0.003916  0.976205   0.760000   \n",
       "\n",
       "      Recall  \n",
       "0   0.730496  \n",
       "1   0.895595  \n",
       "2   0.439286  \n",
       "3   0.546784  \n",
       "4   0.737864  \n",
       "5   0.546875  \n",
       "6   0.390845  \n",
       "7   0.603774  \n",
       "8   0.680581  \n",
       "9   0.857708  \n",
       "10  0.544444  \n",
       "11  0.206522  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1d w2v_base_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-0ba9b52a03aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0membed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mold_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'conv1d '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mY_pred_conv1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred_conv1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mY_pred_conv1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1d w2v_base_model'"
     ]
    }
   ],
   "source": [
    "for embed in embeddings.keys():\n",
    "    old_key = 'conv1d ' + embed\n",
    "    Y_pred_conv1d[embed] = Y_pred_conv1d[old_key]\n",
    "    del Y_pred_conv1d[old_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': array([[1.2711417e-04, 2.4600495e-03, 1.7030057e-02, ..., 3.2564994e-02,\n",
       "         1.6254587e-01, 1.0030006e-02],\n",
       "        [3.8379949e-01, 1.0156614e-03, 8.5396461e-02, ..., 5.8045064e-04,\n",
       "         6.5005109e-02, 3.0366657e-02],\n",
       "        [8.4304921e-02, 1.3882749e-05, 1.0885628e-02, ..., 9.1778864e-05,\n",
       "         5.4829597e-01, 7.0083933e-04],\n",
       "        ...,\n",
       "        [1.7480870e-03, 5.3420203e-04, 4.0169382e-03, ..., 1.6855884e-03,\n",
       "         3.0703151e-01, 3.1490476e-04],\n",
       "        [9.9842441e-01, 9.5998366e-05, 2.7889886e-04, ..., 7.7683985e-04,\n",
       "         1.2977942e-03, 9.1575901e-04],\n",
       "        [9.1305608e-01, 9.9902356e-01, 1.3370297e-03, ..., 1.4695381e-03,\n",
       "         2.8829582e-03, 1.5807690e-02]], dtype=float32)}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in model_conv1d.keys():\n",
    "    if key == 'base':\n",
    "        embed = 'glove_crawl'\n",
    "    else:\n",
    "        embed = key\n",
    "        \n",
    "    Y_pred_conv1d[key] = model_conv1d[key].predict(X_valid_embed[embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_temp = {}\n",
    "for key in Y_pred_conv1d.keys():\n",
    "    new_key = \"conv1d \"+key\n",
    "    Y_pred_temp[new_key] = Y_pred_conv1d[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_stack = Y_pred_temp.update(Y_pred_biGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1d base': array([[1.2711417e-04, 2.4600495e-03, 1.7030057e-02, ..., 3.2564994e-02,\n",
       "         1.6254587e-01, 1.0030006e-02],\n",
       "        [3.8379949e-01, 1.0156614e-03, 8.5396461e-02, ..., 5.8045064e-04,\n",
       "         6.5005109e-02, 3.0366657e-02],\n",
       "        [8.4304921e-02, 1.3882749e-05, 1.0885628e-02, ..., 9.1778864e-05,\n",
       "         5.4829597e-01, 7.0083933e-04],\n",
       "        ...,\n",
       "        [1.7480870e-03, 5.3420203e-04, 4.0169382e-03, ..., 1.6855884e-03,\n",
       "         3.0703151e-01, 3.1490476e-04],\n",
       "        [9.9842441e-01, 9.5998366e-05, 2.7889886e-04, ..., 7.7683985e-04,\n",
       "         1.2977942e-03, 9.1575901e-04],\n",
       "        [9.1305608e-01, 9.9902356e-01, 1.3370297e-03, ..., 1.4695381e-03,\n",
       "         2.8829582e-03, 1.5807690e-02]], dtype=float32),\n",
       " 'conv1d w2v_base_model': array([[7.7351285e-03, 4.1114190e-03, 7.9594404e-02, ..., 3.4883314e-01,\n",
       "         3.0147806e-01, 1.0436573e-02],\n",
       "        [5.2717380e-02, 4.9021583e-02, 2.5817883e-01, ..., 6.8409648e-03,\n",
       "         1.5531059e-02, 1.3957788e-01],\n",
       "        [4.4010583e-02, 5.0913142e-03, 2.4161281e-02, ..., 6.6176648e-03,\n",
       "         8.2854915e-01, 6.8362686e-03],\n",
       "        ...,\n",
       "        [3.8072281e-03, 3.0615330e-03, 5.2563846e-02, ..., 4.4988680e-01,\n",
       "         2.8366438e-01, 3.8474202e-03],\n",
       "        [9.9597329e-01, 1.3592394e-02, 4.5932401e-03, ..., 6.5926893e-04,\n",
       "         4.7399038e-03, 5.6400816e-03],\n",
       "        [4.2401341e-01, 9.9354482e-01, 1.3515508e-02, ..., 1.7004061e-01,\n",
       "         2.5310628e-02, 1.9449625e-02]], dtype=float32),\n",
       " 'conv1d w2v_google_news': array([[3.3715712e-03, 2.7453497e-02, 2.5656346e-02, ..., 1.2000491e-02,\n",
       "         2.9006910e-01, 2.8676879e-02],\n",
       "        [1.9111462e-01, 9.4757125e-02, 5.6513675e-02, ..., 5.7502097e-04,\n",
       "         5.8365259e-02, 1.9844288e-01],\n",
       "        [1.9667095e-02, 8.8167035e-05, 4.9419678e-04, ..., 2.0249912e-03,\n",
       "         8.6133397e-01, 3.8750889e-03],\n",
       "        ...,\n",
       "        [4.6213558e-03, 3.0157443e-02, 2.1455698e-01, ..., 3.8254041e-02,\n",
       "         7.5738740e-01, 3.9681219e-02],\n",
       "        [9.9951315e-01, 3.5166496e-03, 8.7898911e-04, ..., 2.2950188e-04,\n",
       "         6.6747604e-04, 6.0417634e-03],\n",
       "        [2.4288633e-01, 9.9972099e-01, 8.0239596e-03, ..., 5.2359025e-03,\n",
       "         2.7993850e-03, 5.2636001e-02]], dtype=float32),\n",
       " 'conv1d fasttext_crawl': array([[3.0655174e-03, 2.5597515e-02, 4.5952289e-03, ..., 1.0085305e-02,\n",
       "         1.4350478e-01, 5.3675089e-02],\n",
       "        [1.8503111e-02, 1.0506061e-02, 2.4917655e-01, ..., 9.8620274e-04,\n",
       "         5.3524887e-03, 3.6138153e-01],\n",
       "        [2.1489052e-02, 5.7106394e-05, 3.4387428e-03, ..., 4.5087910e-04,\n",
       "         4.3216363e-01, 2.4660354e-02],\n",
       "        ...,\n",
       "        [1.1559703e-04, 2.8156149e-04, 3.9606929e-01, ..., 1.2647134e-03,\n",
       "         3.3753538e-01, 1.5770077e-03],\n",
       "        [9.9917895e-01, 3.7789182e-04, 1.5293253e-03, ..., 4.6825284e-04,\n",
       "         1.9171096e-03, 6.4206179e-03],\n",
       "        [6.8854189e-01, 9.9960357e-01, 3.9797012e-02, ..., 6.0485052e-03,\n",
       "         4.2856741e-03, 6.5428697e-02]], dtype=float32),\n",
       " 'conv1d fasttext_wiki': array([[6.8033608e-03, 1.9189030e-02, 1.9285535e-02, ..., 1.4717866e-01,\n",
       "         1.7049332e-01, 2.4633123e-02],\n",
       "        [3.4121752e-02, 1.0831559e-03, 1.8605283e-01, ..., 2.4000623e-03,\n",
       "         8.3942786e-03, 1.8010359e-01],\n",
       "        [6.5004155e-02, 3.3585166e-04, 2.6216253e-03, ..., 1.2117670e-03,\n",
       "         3.7180763e-01, 3.8863462e-03],\n",
       "        ...,\n",
       "        [7.5946883e-03, 6.9350875e-03, 6.9912598e-02, ..., 4.3199345e-02,\n",
       "         6.4126784e-01, 6.8807690e-03],\n",
       "        [9.9864763e-01, 2.1524266e-03, 2.3569649e-03, ..., 1.2475123e-04,\n",
       "         1.7256095e-03, 3.3867450e-03],\n",
       "        [5.9933501e-01, 9.9803907e-01, 4.8052766e-03, ..., 1.0330258e-01,\n",
       "         9.5792981e-03, 7.9959752e-03]], dtype=float32),\n",
       " 'conv1d glove_twitter': array([[3.2522471e-03, 9.0179183e-03, 4.7558047e-02, ..., 2.6648962e-01,\n",
       "         2.7401518e-02, 1.9675411e-02],\n",
       "        [1.2309861e-01, 3.9588823e-03, 3.0745488e-01, ..., 1.9378439e-04,\n",
       "         1.1073126e-02, 1.5832521e-01],\n",
       "        [2.8323501e-02, 7.5342556e-05, 3.8083456e-03, ..., 3.7177734e-03,\n",
       "         7.7693611e-01, 2.3105158e-03],\n",
       "        ...,\n",
       "        [4.6362460e-02, 1.4324590e-02, 4.2791826e-01, ..., 2.7658519e-01,\n",
       "         1.6851710e-01, 4.2432975e-03],\n",
       "        [9.9737984e-01, 8.2999718e-04, 4.7928556e-03, ..., 5.0418566e-05,\n",
       "         1.9806006e-03, 4.2352257e-03],\n",
       "        [6.6701394e-01, 9.9222904e-01, 1.8724655e-03, ..., 3.0710172e-02,\n",
       "         3.5854792e-03, 5.3599929e-03]], dtype=float32),\n",
       " 'conv1d glove_wiki': array([[5.27287368e-03, 8.53424985e-03, 2.26238161e-01, ...,\n",
       "         3.54316719e-02, 5.97850569e-02, 5.71399629e-02],\n",
       "        [1.07412916e-02, 1.41595872e-02, 7.79462904e-02, ...,\n",
       "         1.10099430e-03, 1.19280983e-02, 2.80992895e-01],\n",
       "        [2.61493511e-02, 8.06587705e-05, 1.46664074e-03, ...,\n",
       "         3.80045734e-03, 5.56771994e-01, 5.18985675e-04],\n",
       "        ...,\n",
       "        [5.29782905e-04, 5.17688517e-04, 3.59365880e-01, ...,\n",
       "         1.76246539e-01, 7.29084074e-01, 1.87657401e-03],\n",
       "        [9.99594152e-01, 1.04096637e-03, 1.08763762e-03, ...,\n",
       "         1.66763421e-04, 3.11358250e-04, 2.51504127e-03],\n",
       "        [2.95900941e-01, 9.99186456e-01, 1.09858974e-03, ...,\n",
       "         1.09313525e-01, 3.82471626e-04, 1.47006009e-02]], dtype=float32),\n",
       " 'conv1d glove_crawl': array([[1.55250984e-03, 7.77618811e-02, 4.60695885e-02, ...,\n",
       "         6.02113456e-02, 1.63049791e-02, 5.68980388e-02],\n",
       "        [7.45477760e-03, 7.55981654e-02, 1.04158014e-01, ...,\n",
       "         1.24820392e-03, 2.99364422e-02, 4.46881466e-02],\n",
       "        [6.19139262e-02, 2.39909766e-03, 6.11463562e-04, ...,\n",
       "         5.22109866e-03, 9.82832611e-01, 6.83588395e-03],\n",
       "        ...,\n",
       "        [7.49650702e-04, 1.90328266e-02, 1.82818532e-01, ...,\n",
       "         3.85197718e-03, 9.07170951e-01, 5.52367826e-04],\n",
       "        [9.99208033e-01, 3.82636953e-03, 5.64052083e-04, ...,\n",
       "         5.70603443e-05, 4.84504882e-04, 2.96407845e-03],\n",
       "        [5.33230186e-01, 9.99838948e-01, 8.51927791e-03, ...,\n",
       "         4.92308987e-03, 7.16351159e-03, 4.90164338e-03]], dtype=float32),\n",
       " 'w2v_base_model': array([[6.70712208e-03, 2.33163591e-03, 1.17806859e-01, ...,\n",
       "         1.71942502e-01, 3.98391038e-02, 1.23508601e-02],\n",
       "        [8.03113505e-02, 3.02832723e-02, 1.58611491e-01, ...,\n",
       "         9.80965327e-04, 1.20928241e-02, 6.73646033e-02],\n",
       "        [9.48831439e-02, 3.21817258e-03, 2.50763949e-02, ...,\n",
       "         5.85566787e-03, 6.30987823e-01, 1.48931779e-02],\n",
       "        ...,\n",
       "        [5.05924970e-03, 1.10797547e-02, 4.26909104e-02, ...,\n",
       "         1.93987980e-01, 3.45349371e-01, 3.50428117e-03],\n",
       "        [9.94822145e-01, 1.02689806e-02, 1.72989275e-02, ...,\n",
       "         6.02683751e-04, 1.13342060e-02, 1.19473785e-02],\n",
       "        [5.28276145e-01, 9.97509241e-01, 1.80284288e-02, ...,\n",
       "         4.99513485e-02, 7.97947422e-02, 1.06824143e-02]], dtype=float32),\n",
       " 'w2v_google_news': array([[1.19210072e-02, 2.07746518e-03, 3.48258056e-02, ...,\n",
       "         1.27247330e-02, 8.27513635e-02, 4.07893099e-02],\n",
       "        [2.47543067e-01, 3.67598631e-03, 4.00306173e-02, ...,\n",
       "         1.02215903e-02, 1.76364239e-02, 4.73020449e-02],\n",
       "        [1.25495553e-01, 1.75629475e-03, 2.86916327e-02, ...,\n",
       "         2.71311402e-03, 9.82826412e-01, 2.67277844e-03],\n",
       "        ...,\n",
       "        [1.14086010e-02, 6.06844726e-04, 1.73163384e-01, ...,\n",
       "         7.25568132e-03, 2.37782419e-01, 3.97164084e-04],\n",
       "        [9.99543846e-01, 7.19774654e-03, 2.64210766e-03, ...,\n",
       "         5.87052607e-04, 9.96325444e-03, 1.18221641e-02],\n",
       "        [6.94587946e-01, 9.97987151e-01, 2.30347309e-02, ...,\n",
       "         6.45351177e-03, 2.69585196e-02, 1.54068135e-02]], dtype=float32),\n",
       " 'fasttext_crawl': array([[6.41004089e-03, 1.03387395e-02, 7.96657987e-03, ...,\n",
       "         7.39773549e-03, 1.83410615e-01, 1.08881658e-02],\n",
       "        [1.59289334e-02, 7.61934975e-03, 5.59317023e-02, ...,\n",
       "         4.83737793e-03, 5.21950144e-03, 2.73966528e-02],\n",
       "        [1.06184587e-01, 4.83905373e-04, 9.92350373e-03, ...,\n",
       "         9.67481639e-03, 8.88842463e-01, 7.69743929e-04],\n",
       "        ...,\n",
       "        [2.46345215e-02, 1.88876335e-02, 5.92397936e-02, ...,\n",
       "         3.48110721e-02, 3.19729000e-01, 3.79722507e-04],\n",
       "        [9.97598350e-01, 3.58924805e-03, 1.35442102e-03, ...,\n",
       "         1.25202889e-04, 3.50781600e-03, 9.67699941e-03],\n",
       "        [7.59335399e-01, 9.99387741e-01, 5.49366279e-03, ...,\n",
       "         1.28656914e-02, 7.77950557e-03, 1.77697162e-03]], dtype=float32),\n",
       " 'fasttext_wiki': array([[2.9789854e-03, 6.2368017e-02, 1.3740415e-02, ..., 8.1069894e-02,\n",
       "         3.7486747e-01, 3.5824012e-02],\n",
       "        [7.8364186e-02, 5.2682433e-02, 4.4093445e-02, ..., 6.6100331e-03,\n",
       "         3.9290626e-02, 6.9696810e-03],\n",
       "        [2.8490734e-01, 9.4451732e-04, 9.1118328e-03, ..., 9.5379708e-04,\n",
       "         8.5930520e-01, 2.4187895e-02],\n",
       "        ...,\n",
       "        [5.5159651e-02, 1.9616498e-02, 2.7981071e-02, ..., 3.5795487e-02,\n",
       "         3.3699930e-01, 1.6870454e-04],\n",
       "        [9.9961013e-01, 1.9497353e-03, 5.6317844e-03, ..., 1.7555113e-04,\n",
       "         3.7277641e-03, 5.3286324e-03],\n",
       "        [8.1160247e-01, 9.8655838e-01, 1.3269735e-02, ..., 3.5472143e-02,\n",
       "         1.4411153e-02, 4.9980329e-03]], dtype=float32),\n",
       " 'glove_twitter': array([[1.28298597e-02, 2.42642360e-03, 5.99532723e-02, ...,\n",
       "         3.87520194e-02, 9.66362357e-02, 1.31356101e-02],\n",
       "        [1.50650069e-01, 1.85297208e-03, 2.13720009e-01, ...,\n",
       "         2.59952657e-02, 1.81168299e-02, 3.89889851e-02],\n",
       "        [1.57607764e-01, 7.70446262e-04, 4.97730775e-03, ...,\n",
       "         1.91486627e-03, 8.26841116e-01, 2.01491639e-03],\n",
       "        ...,\n",
       "        [1.63585320e-02, 1.17157206e-01, 2.78874524e-02, ...,\n",
       "         8.99711717e-03, 4.35923308e-01, 2.13982025e-03],\n",
       "        [9.99770105e-01, 1.68327824e-03, 4.35523223e-03, ...,\n",
       "         5.45640301e-04, 3.35264532e-03, 1.73546164e-03],\n",
       "        [8.24298024e-01, 9.98094499e-01, 1.54318777e-03, ...,\n",
       "         2.79854480e-02, 1.15149105e-02, 1.55356142e-03]], dtype=float32),\n",
       " 'glove_wiki': array([[1.8083673e-02, 3.2288211e-03, 9.2225000e-02, ..., 2.4495397e-02,\n",
       "         4.9342860e-02, 3.7566087e-01],\n",
       "        [1.0373384e-02, 3.1363100e-02, 2.8324941e-01, ..., 1.0141496e-03,\n",
       "         1.2867181e-01, 5.6251138e-02],\n",
       "        [7.5367212e-02, 3.7461933e-04, 1.3901017e-03, ..., 7.0154114e-05,\n",
       "         9.7920185e-01, 5.6909886e-03],\n",
       "        ...,\n",
       "        [1.7890409e-03, 3.5596427e-03, 6.3199741e-03, ..., 1.7265392e-02,\n",
       "         8.6845315e-01, 2.0638756e-03],\n",
       "        [9.9953163e-01, 2.0078984e-03, 8.6305913e-04, ..., 1.4295542e-04,\n",
       "         8.9906948e-03, 8.7101996e-04],\n",
       "        [4.8758537e-01, 9.9989617e-01, 1.1822019e-02, ..., 4.9117915e-02,\n",
       "         2.0484155e-02, 6.4996034e-03]], dtype=float32),\n",
       " 'glove_crawl': array([[7.6731765e-03, 1.8756511e-02, 2.0718735e-01, ..., 5.8995225e-03,\n",
       "         2.2862799e-01, 1.4535616e-01],\n",
       "        [1.3806079e-02, 3.7451155e-02, 2.7530316e-01, ..., 4.5644734e-03,\n",
       "         7.7723493e-03, 2.5156397e-02],\n",
       "        [7.2004693e-03, 3.7210964e-04, 7.1481743e-04, ..., 2.9516051e-04,\n",
       "         9.0551692e-01, 3.1915787e-03],\n",
       "        ...,\n",
       "        [1.3806479e-03, 3.7336957e-02, 3.0067857e-02, ..., 3.7115102e-03,\n",
       "         1.9946434e-01, 1.0946775e-03],\n",
       "        [9.9967802e-01, 2.6300899e-03, 3.8393545e-03, ..., 1.0338653e-03,\n",
       "         4.0851333e-03, 9.7635231e-04],\n",
       "        [4.1650093e-01, 9.9966180e-01, 7.2628260e-03, ..., 2.6532933e-02,\n",
       "         4.7337601e-04, 3.3390468e-03]], dtype=float32)}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>conv1d glove_wiki</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.531024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>conv1d fasttext_crawl</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.530422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.529819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d w2v_google_news</td>\n",
       "      <td>0.528916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d glove_wiki</td>\n",
       "      <td>0.528614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    embed1                  embed2  accuracy\n",
       "104      conv1d glove_wiki             glove_crawl  0.531024\n",
       "59   conv1d fasttext_crawl             glove_crawl  0.530422\n",
       "209             glove_wiki             glove_crawl  0.529819\n",
       "2              conv1d base  conv1d w2v_google_news  0.528916\n",
       "6              conv1d base       conv1d glove_wiki  0.528614"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1_list = []\n",
    "embed2_list = []\n",
    "acc2_list = []\n",
    "\n",
    "for embed1 in Y_pred_temp.keys():\n",
    "    for embed2 in Y_pred_temp.keys():\n",
    "        Y_pred_stack = (Y_pred_temp[embed1] + Y_pred_temp[embed2])/2\n",
    "        acc = metrics.accuracy_score(Y_valid, np.round(Y_pred_stack))\n",
    "        acc2_list.append(acc)\n",
    "        embed1_list.append(embed1)\n",
    "        embed2_list.append(embed2)\n",
    "\n",
    "            \n",
    "embeds_df = pd.DataFrame({'embed1': embed1_list,\n",
    "                          'embed2': embed2_list,\n",
    "                          'accuracy': acc2_list})\n",
    "embeds_df.drop_duplicates('accuracy').sort_values(by = 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d glove_wiki</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.535241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d fasttext_crawl</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.534639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>conv1d fasttext_crawl</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.534337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>conv1d w2v_google_news</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.534036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.533434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     embed1                 embed2          embed3  accuracy\n",
       "100             conv1d base      conv1d glove_wiki  fasttext_crawl  0.535241\n",
       "55              conv1d base  conv1d fasttext_crawl  fasttext_crawl  0.534639\n",
       "839   conv1d fasttext_crawl         fasttext_crawl     glove_crawl  0.534337\n",
       "614  conv1d w2v_google_news         fasttext_crawl     glove_crawl  0.534036\n",
       "149             conv1d base        w2v_google_news     glove_crawl  0.533434"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1_list = []\n",
    "embed2_list = []\n",
    "embed3_list = []\n",
    "acc2_list = []\n",
    "\n",
    "for embed1 in Y_pred_temp.keys():\n",
    "    for embed2 in Y_pred_temp.keys():\n",
    "        for embed3 in Y_pred_temp.keys():\n",
    "            Y_pred_stack = (Y_pred_temp[embed1] + \n",
    "                            Y_pred_temp[embed2] +\n",
    "                            Y_pred_temp[embed3])/3\n",
    "            acc = metrics.accuracy_score(Y_valid, np.round(Y_pred_stack))\n",
    "            acc2_list.append(acc)\n",
    "            embed1_list.append(embed1)\n",
    "            embed2_list.append(embed2)\n",
    "            embed3_list.append(embed3)\n",
    "\n",
    "            \n",
    "embeds_df = pd.DataFrame({'embed1': embed1_list,\n",
    "                          'embed2': embed2_list,\n",
    "                          'embed3': embed3_list,\n",
    "                          'accuracy': acc2_list})\n",
    "embeds_df.drop_duplicates('accuracy').sort_values(by = 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>embed4</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22709</th>\n",
       "      <td>conv1d glove_wiki</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.540060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.539157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d fasttext_wiki</td>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.537349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11639</th>\n",
       "      <td>conv1d fasttext_crawl</td>\n",
       "      <td>conv1d glove_wiki</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.537048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d w2v_google_news</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.536747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      embed1                  embed2           embed3  \\\n",
       "22709      conv1d glove_wiki          fasttext_crawl       glove_wiki   \n",
       "2187             conv1d base         w2v_google_news   fasttext_crawl   \n",
       "1049             conv1d base    conv1d fasttext_wiki  w2v_google_news   \n",
       "11639  conv1d fasttext_crawl       conv1d glove_wiki   fasttext_crawl   \n",
       "612              conv1d base  conv1d w2v_google_news   fasttext_crawl   \n",
       "\n",
       "              embed4  accuracy  \n",
       "22709    glove_crawl  0.540060  \n",
       "2187   glove_twitter  0.539157  \n",
       "1049     glove_crawl  0.537349  \n",
       "11639    glove_crawl  0.537048  \n",
       "612    glove_twitter  0.536747  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1_list = []\n",
    "embed2_list = []\n",
    "embed3_list = []\n",
    "embed4_list = []\n",
    "acc2_list = []\n",
    "\n",
    "for embed1 in Y_pred_temp.keys():\n",
    "    for embed2 in Y_pred_temp.keys():\n",
    "        for embed3 in Y_pred_temp.keys():\n",
    "            for embed4 in Y_pred_temp.keys():\n",
    "                Y_pred_stack = (Y_pred_temp[embed1] + \n",
    "                                Y_pred_temp[embed2] +\n",
    "                                Y_pred_temp[embed3] +\n",
    "                                Y_pred_temp[embed4])/4\n",
    "                acc = metrics.accuracy_score(Y_valid, np.round(Y_pred_stack))\n",
    "                acc2_list.append(acc)\n",
    "                embed1_list.append(embed1)\n",
    "                embed2_list.append(embed2)\n",
    "                embed3_list.append(embed3)\n",
    "                embed4_list.append(embed4)\n",
    "\n",
    "            \n",
    "embeds_df = pd.DataFrame({'embed1': embed1_list,\n",
    "                          'embed2': embed2_list,\n",
    "                          'embed3': embed3_list,\n",
    "                          'embed4': embed4_list,\n",
    "                          'accuracy': acc2_list})\n",
    "embeds_df.drop_duplicates('accuracy').sort_values(by = 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed1</th>\n",
       "      <th>embed2</th>\n",
       "      <th>embed3</th>\n",
       "      <th>embed4</th>\n",
       "      <th>embed5</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36193</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.540361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12312</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d fasttext_crawl</td>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.539759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29413</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.539458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36659</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.539157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>conv1d base</td>\n",
       "      <td>conv1d w2v_google_news</td>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.538554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            embed1                  embed2           embed3          embed4  \\\n",
       "36193  conv1d base          fasttext_crawl   fasttext_crawl   glove_twitter   \n",
       "12312  conv1d base   conv1d fasttext_crawl  w2v_google_news  fasttext_crawl   \n",
       "29413  conv1d base          w2v_base_model   fasttext_crawl  fasttext_crawl   \n",
       "36659  conv1d base          fasttext_crawl    glove_twitter      glove_wiki   \n",
       "9179   conv1d base  conv1d w2v_google_news   fasttext_crawl   fasttext_wiki   \n",
       "\n",
       "              embed5  accuracy  \n",
       "36193     glove_wiki  0.540361  \n",
       "12312  glove_twitter  0.539759  \n",
       "29413     glove_wiki  0.539458  \n",
       "36659    glove_crawl  0.539157  \n",
       "9179     glove_crawl  0.538554  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1_list = []\n",
    "embed2_list = []\n",
    "embed3_list = []\n",
    "embed4_list = []\n",
    "embed5_list = []\n",
    "acc2_list = []\n",
    "\n",
    "for embed1 in Y_pred_temp.keys():\n",
    "    for embed2 in Y_pred_temp.keys():\n",
    "        for embed3 in Y_pred_temp.keys():\n",
    "            for embed4 in Y_pred_temp.keys():\n",
    "                for embed5 in Y_pred_temp.keys():\n",
    "                    Y_pred_stack = (Y_pred_temp[embed1] + \n",
    "                                    Y_pred_temp[embed2] +\n",
    "                                    Y_pred_temp[embed3] +\n",
    "                                    Y_pred_temp[embed4] +\n",
    "                                    Y_pred_temp[embed5])/5\n",
    "                    acc = metrics.accuracy_score(Y_valid, np.round(Y_pred_stack))\n",
    "                    acc2_list.append(acc)\n",
    "                    embed1_list.append(embed1)\n",
    "                    embed2_list.append(embed2)\n",
    "                    embed3_list.append(embed3)\n",
    "                    embed4_list.append(embed4)\n",
    "                    embed5_list.append(embed5)\n",
    "\n",
    "            \n",
    "embeds_df = pd.DataFrame({'embed1': embed1_list,\n",
    "                          'embed2': embed2_list,\n",
    "                          'embed3': embed3_list,\n",
    "                          'embed4': embed4_list,\n",
    "                          'embed5': embed5_list,\n",
    "                          'accuracy': acc2_list})\n",
    "embeds_df.drop_duplicates('accuracy').sort_values(by = 'accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5283 \n",
      "Hamming Loss: 0.0608 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_count</th>\n",
       "      <th>Pred_count</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>423</td>\n",
       "      <td>367</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.937952</td>\n",
       "      <td>0.795640</td>\n",
       "      <td>0.690307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>613</td>\n",
       "      <td>604</td>\n",
       "      <td>0.034639</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.965361</td>\n",
       "      <td>0.912252</td>\n",
       "      <td>0.898858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>280</td>\n",
       "      <td>135</td>\n",
       "      <td>0.058133</td>\n",
       "      <td>0.026205</td>\n",
       "      <td>0.941867</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.396429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>342</td>\n",
       "      <td>290</td>\n",
       "      <td>0.071687</td>\n",
       "      <td>0.031325</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>0.679310</td>\n",
       "      <td>0.576023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>206</td>\n",
       "      <td>185</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.038253</td>\n",
       "      <td>0.976205</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.757282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>320</td>\n",
       "      <td>275</td>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.035241</td>\n",
       "      <td>0.938855</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>284</td>\n",
       "      <td>159</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.019578</td>\n",
       "      <td>0.934036</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.394366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>424</td>\n",
       "      <td>379</td>\n",
       "      <td>0.091867</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.908133</td>\n",
       "      <td>0.656992</td>\n",
       "      <td>0.587264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>551</td>\n",
       "      <td>483</td>\n",
       "      <td>0.090964</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.909036</td>\n",
       "      <td>0.757764</td>\n",
       "      <td>0.664247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>759</td>\n",
       "      <td>732</td>\n",
       "      <td>0.056928</td>\n",
       "      <td>0.171687</td>\n",
       "      <td>0.943072</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.857708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>450</td>\n",
       "      <td>344</td>\n",
       "      <td>0.087952</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>0.912048</td>\n",
       "      <td>0.729651</td>\n",
       "      <td>0.557778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>92</td>\n",
       "      <td>24</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.195652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_count  Pred_count     Error  Dummy_Diff  Accuarcy  Precision  \\\n",
       "0    CPD      423         367  0.062048    0.065361  0.937952   0.795640   \n",
       "1     CB      613         604  0.034639    0.150000  0.965361   0.912252   \n",
       "2    EWC      280         135  0.058133    0.026205  0.941867   0.822222   \n",
       "3   Exec      342         290  0.071687    0.031325  0.928313   0.679310   \n",
       "4    FWE      206         185  0.023795    0.038253  0.976205   0.843243   \n",
       "5     SP      320         275  0.061145    0.035241  0.938855   0.712727   \n",
       "6     RE      284         159  0.065964    0.019578  0.934036   0.704403   \n",
       "7    Sup      424         379  0.091867    0.035843  0.908133   0.656992   \n",
       "8     SW      551         483  0.090964    0.075000  0.909036   0.757764   \n",
       "9   TEPE      759         732  0.056928    0.171687  0.943072   0.889344   \n",
       "10   VMG      450         344  0.087952    0.047590  0.912048   0.729651   \n",
       "11   OTH       92          24  0.024096    0.003614  0.975904   0.750000   \n",
       "\n",
       "      Recall  \n",
       "0   0.690307  \n",
       "1   0.898858  \n",
       "2   0.396429  \n",
       "3   0.576023  \n",
       "4   0.757282  \n",
       "5   0.612500  \n",
       "6   0.394366  \n",
       "7   0.587264  \n",
       "8   0.664247  \n",
       "9   0.857708  \n",
       "10  0.557778  \n",
       "11  0.195652  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Accuracies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>0.469578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>0.506928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.515361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>0.506627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.492169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.502108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.507831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Embedding  Accuracies\n",
       "0   w2v_base_model    0.469578\n",
       "1  w2v_google_news    0.506928\n",
       "2   fasttext_crawl    0.515361\n",
       "3    fasttext_wiki    0.506627\n",
       "4    glove_twitter    0.492169\n",
       "5       glove_wiki    0.502108\n",
       "6      glove_crawl    0.507831"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for embed in embeddings.keys():\n",
    "    accuracies.append(metrics.accuracy_score(Y_valid, np.round(Y_pred_conv1d[embed])))\n",
    "    \n",
    "results_conv1d = pd.DataFrame({'Embedding': list(embeddings.keys()),\n",
    "                               'Accuracies': accuracies})\n",
    "\n",
    "results_conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the Precision! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "prob_adj = []\n",
    "non_zero_percent = []\n",
    "\n",
    "for i in np.arange(-0.49,0.5,0.01):\n",
    "    \n",
    "    prob_adj.append(min((0.5 + i),1))\n",
    "    predictions = np.round(Y_pred_stack - i)\n",
    "    \n",
    "    size = predictions.shape[0]\n",
    "    zero_size = (predictions[predictions.sum(axis = 1) == 0,:].shape[0])\n",
    "    \n",
    "    non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "    non_zero_valid = Y_valid[predictions.sum(axis = 1) != 0,:]\n",
    "    \n",
    "    accuracy.append(metrics.accuracy_score(non_zero_valid, non_zero_pred))\n",
    "    non_zero_percent.append(round(1 - zero_size/size, 4))\n",
    "\n",
    "results_tradeoff = pd.DataFrame({'prob_adj': prob_adj,\n",
    "                                 'accuracy':accuracy,\n",
    "                                 'non_zero_percent':non_zero_percent})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = results_tradeoff.plot.scatter(x = 'non_zero_percent',\n",
    "                              y = 'accuracy',\n",
    "                              c = 'prob_adj')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred_stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fead36a3dbc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheme_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mzero_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred_stack' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = np.round(Y_pred_stack)\n",
    "\n",
    "a = theme_results(Y_valid, predictions)\n",
    "size = predictions.shape[0]\n",
    "zero_size = (predictions[predictions.sum(axis = 1) == 0,:].shape[0])\n",
    "print(\"Total comments:\", size, \n",
    "      \"\\nTotal Predictions:\", size - zero_size, \n",
    "      \"\\nPercent Pred non-zero:\", round(1 - zero_size/size, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.687 \n",
      "Hamming Loss: 0.0404 \n",
      "Hamming Loss (pred. zeros): 0.1142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_count</th>\n",
       "      <th>Pred_count</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>195</td>\n",
       "      <td>158</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.951299</td>\n",
       "      <td>0.879747</td>\n",
       "      <td>0.712821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>437</td>\n",
       "      <td>384</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.241558</td>\n",
       "      <td>0.957792</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.864989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>71</td>\n",
       "      <td>27</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>0.022078</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.977922</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>120</td>\n",
       "      <td>82</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>0.050649</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>119</td>\n",
       "      <td>69</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.521008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.959091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>116</td>\n",
       "      <td>80</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>0.966234</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>242</td>\n",
       "      <td>150</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.549587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>546</td>\n",
       "      <td>524</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.944156</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.901099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>112</td>\n",
       "      <td>56</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.953247</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.987662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_count  Pred_count     Error  Dummy_Diff  Accuarcy  Precision  \\\n",
       "0    CPD      195         158  0.048701    0.077922  0.951299   0.879747   \n",
       "1     CB      437         384  0.042208    0.241558  0.957792   0.984375   \n",
       "2    EWC       71          27  0.031169    0.014935  0.968831   0.925926   \n",
       "3   Exec       61          33  0.022078    0.017532  0.977922   0.909091   \n",
       "4    FWE      120          82  0.027273    0.050649  0.972727   0.975610   \n",
       "5     SP      119          69  0.041558    0.035714  0.958442   0.898551   \n",
       "6     RE       71           8  0.040909    0.005195  0.959091   1.000000   \n",
       "7    Sup      116          80  0.033766    0.041558  0.966234   0.900000   \n",
       "8     SW      242         150  0.081818    0.075325  0.918182   0.886667   \n",
       "9   TEPE      546         524  0.055844    0.298701  0.944156   0.938931   \n",
       "10   VMG      112          56  0.046753    0.025974  0.953247   0.857143   \n",
       "11   OTH       20           1  0.012338    0.000649  0.987662   1.000000   \n",
       "\n",
       "      Recall  \n",
       "0   0.712821  \n",
       "1   0.864989  \n",
       "2   0.352113  \n",
       "3   0.491803  \n",
       "4   0.666667  \n",
       "5   0.521008  \n",
       "6   0.112676  \n",
       "7   0.620690  \n",
       "8   0.549587  \n",
       "9   0.901099  \n",
       "10  0.428571  \n",
       "11  0.050000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "non_zero_valid = Y_valid[predictions.sum(axis = 1) != 0,:]\n",
    "\n",
    "theme_results(non_zero_valid, non_zero_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
