{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aaronquinton/Documents/UBC-MDS/Capstone/BCstats/DSCI_591_capstone-BCStats'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change working directory to be project root\n",
    "import os\n",
    "#os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "# Custom functions for preprocessing and data preparation\n",
    "from src.data.preprocessing_text import (\n",
    "    clean_text, clean_numbers, replace_typical_misspell, remove_stopwords,\n",
    "    balance_themes, preprocess_for_embed, preprocess_for_bow\n",
    ")\n",
    "\n",
    "from src.features.word_vectors import (\n",
    "    build_vocab, check_coverage, get_average_embeddings\n",
    ")\n",
    "\n",
    "from src.models.eval import theme_results, investigate_results\n",
    "\n",
    "# Functions for preprocessing and data preparation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Training Word embeddings and pre-trained embeddings\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Training LSTM Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Conv1D, GlobalAveragePooling1D\n",
    "from keras.layers import GRU, concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "# Classification alogrithms\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import multilayer_perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Read in Data and Embeddings </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Filepaths\n",
    "# Data Files\n",
    "fname_rawdata2015 = \"data/interim/train_2015-qualitative-data.csv\"\n",
    "fname_rawdata2018 = \"data/interim/train_2018-qualitative-data.csv\"\n",
    "fname_quant = \"data/processed/tidy_quant_questions.csv\"\n",
    "fname_legend = \"references/data-dictionaries/survey_mc_legend.csv\"\n",
    "\n",
    "# Pre-trained Embeddings\n",
    "fname_fasttext_crawl = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                       \"crawl-300d-2M.vec\"\n",
    "fname_fasttext_wiki = \"./references/pretrained_embeddings.nosync/fasttext/\" \\\n",
    "                      \"wiki-news-300d-1M.vec\"\n",
    "fname_w2v_googlenews = \"./references/pretrained_embeddings.nosync/\" \\\n",
    "                       \"GoogleNews-vectors-negative300.bin\"\n",
    "fname_glove_twitter = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.twitter.27B.200d.w2v.txt\"\n",
    "fname_glove_wiki = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.6B.300d.w2v.txt\"\n",
    "fname_glove_crawl = \"./references/pretrained_embeddings.nosync/glove/\" \\\n",
    "                      \"glove.840B.300d.w2v.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data\n",
    "df = pd.read_csv(fname_rawdata2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to load embeddings: 2958.4 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Read in pre-trained embeddings\n",
    "w2v_google_news = KeyedVectors.load_word2vec_format(fname_w2v_googlenews,\n",
    "                                                    binary=True)\n",
    "fasttext_crawl = KeyedVectors.load_word2vec_format(fname_fasttext_crawl,\n",
    "                                                   unicode_errors='ignore')\n",
    "fasttext_wiki = KeyedVectors.load_word2vec_format(fname_fasttext_wiki,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_twitter = KeyedVectors.load_word2vec_format(fname_glove_twitter,\n",
    "                                                  unicode_errors='ignore')\n",
    "glove_wiki = KeyedVectors.load_word2vec_format(fname_glove_wiki,\n",
    "                                               unicode_errors='ignore')\n",
    "glove_crawl = KeyedVectors.load_word2vec_format(fname_glove_crawl,\n",
    "                                                unicode_errors='ignore')\n",
    "\n",
    "t_end = time.time()\n",
    "print(\"Elapsed time to load embeddings: %.1f s\" % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Preprocessing and Data Preperation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userid = df[['_telkey', '2018 Comment']]\n",
    "df_userid = df_userid.rename(columns = {'_telkey':'USERID'})\n",
    "\n",
    "df = df[['2018 Comment']].join(df.loc[:,'CPD':'OTH'])\n",
    "df = df.rename(columns = {'2018 Comment' : 'comment'})\n",
    "\n",
    "Y = np.array(df.loc[:,\"CPD\":\"OTH\"])\n",
    "\n",
    "themes = df.loc[:,'CPD':'OTH'].columns.tolist()\n",
    "\n",
    "# Split the data\n",
    "df_X_train, df_X_valid, Y_train, Y_valid = train_test_split(\n",
    "        df.comment, Y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958,)\n",
      "(9958, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df_X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Quantitative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant = pd.read_csv(fname_quant).query(\"survey_year == 2018\")\n",
    "df_legend = pd.read_csv(fname_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quant_train = df_userid.loc[df_X_train.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')\n",
    "\n",
    "df_quant_valid = df_userid.loc[df_X_valid.index] \\\n",
    "                          .merge(df_quant, how='left', on='USERID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab relevant question responses for each theme\n",
    "X_train_quant = {}\n",
    "X_valid_quant = {}\n",
    "\n",
    "for i, theme in enumerate(themes):\n",
    "    \n",
    "    codel = (i)*10\n",
    "    codeu = (i+2)*10 - 1\n",
    "    col_quant = list(df_legend.loc[df_legend.subtheme_code.between(codel,codeu)] \\\n",
    "                              .new_column_name)\n",
    "\n",
    "    X_train_quant[theme] = np.array(df_quant_train[col_quant])\n",
    "    X_valid_quant[theme] = np.array(df_quant_valid[col_quant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean response for that question\n",
    "for theme in themes:\n",
    "    for i in range(X_valid_quant[theme].shape[1]):\n",
    "        mean_replace = np.nanmean(X_valid_quant[theme], axis = 0)[i]\n",
    "        X_valid_quant[theme][:,i][np.isnan(X_valid_quant[theme][:,i])] = mean_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_quant = np.array(df_quant_valid.iloc[:,3:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean response for that column\n",
    "for i in range(X_valid_quant.shape[1]):\n",
    "    mean_replace = np.nanmean(X_valid_quant, axis = 0)[i]\n",
    "    X_valid_quant[:,i][np.isnan(X_valid_quant[:,i])] = mean_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3320, 17)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_quant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = preprocess_for_embed(df.comment, 'w2v_base_model')\n",
    "\n",
    "w2v_base_model = Word2Vec(comments, \n",
    "                     size=300, \n",
    "                     window=5, \n",
    "                     min_count=1,\n",
    "                     sg=1, \n",
    "                     negative=4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pretrained embeddings\n",
    "embeddings = {'w2v_base_model': w2v_base_model,\n",
    "              'w2v_google_news': w2v_google_news, \n",
    "              'fasttext_crawl': fasttext_crawl,\n",
    "              'fasttext_wiki': fasttext_wiki,\n",
    "              'glove_twitter': glove_twitter,\n",
    "              'glove_wiki': glove_wiki,\n",
    "              'glove_crawl': glove_crawl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Vocab Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13278/13278 [00:00<00:00, 86084.02it/s]\n",
      "100%|██████████| 13673/13673 [00:00<00:00, 40466.79it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88164.98it/s]\n",
      "100%|██████████| 17246/17246 [00:03<00:00, 5679.35it/s] \n",
      "100%|██████████| 13278/13278 [00:00<00:00, 91469.55it/s]\n",
      "100%|██████████| 17500/17500 [00:01<00:00, 10368.71it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 88333.35it/s]\n",
      "100%|██████████| 17500/17500 [00:02<00:00, 6214.14it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 90237.65it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4575.48it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 92607.72it/s]\n",
      "100%|██████████| 13673/13673 [00:02<00:00, 4979.80it/s]\n",
      "100%|██████████| 13278/13278 [00:00<00:00, 89359.93it/s]\n",
      "100%|██████████| 17500/17500 [00:06<00:00, 2735.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>vocab_coverage</th>\n",
       "      <th>text_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>0.939870</td>\n",
       "      <td>0.996661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>0.953943</td>\n",
       "      <td>0.997412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>0.938514</td>\n",
       "      <td>0.996345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>0.887954</td>\n",
       "      <td>0.990666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>0.913479</td>\n",
       "      <td>0.994892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>0.953543</td>\n",
       "      <td>0.997421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  vocab_coverage  text_coverage\n",
       "0   w2v_base_model        1.000000       1.000000\n",
       "1  w2v_google_news        0.939870       0.996661\n",
       "2   fasttext_crawl        0.953943       0.997412\n",
       "3    fasttext_wiki        0.938514       0.996345\n",
       "4    glove_twitter        0.887954       0.990666\n",
       "5       glove_wiki        0.913479       0.994892\n",
       "6      glove_crawl        0.953543       0.997421"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coverage of vocab words in embedding\n",
    "oov = {}\n",
    "vocab_coverage = []\n",
    "text_coverage = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    comments = preprocess_for_embed(df.comment, embedding)\n",
    "    vocab = build_vocab(comments)\n",
    "        \n",
    "    a, b, oov[embedding] = check_coverage(vocab, embeddings[embedding])\n",
    "    \n",
    "    vocab_coverage.append(a)\n",
    "    text_coverage.append(b)\n",
    "\n",
    "pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "              'vocab_coverage': vocab_coverage, \n",
    "              'text_coverage': text_coverage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v_base_model\n",
      "[]\n",
      "w2v_google_news\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('BCWS', 23)]\n",
      "fasttext_crawl\n",
      "[('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32)]\n",
      "fasttext_wiki\n",
      "[('MCFD', 128), ('CYMH', 54), ('BCTS', 37), ('FLNRORD', 35), ('GCPE', 33)]\n",
      "glove_twitter\n",
      "[('2', 402), ('1', 302), ('3', 236), ('4', 171), ('5', 151)]\n",
      "glove_wiki\n",
      "[('####', 181), ('mcfd', 131), ('cymh', 54), ('#####', 49), ('bcts', 37)]\n",
      "glove_crawl\n",
      "[('CYMH', 54), ('FLNRORD', 35), ('GCPE', 33), ('CSNR', 32), ('STIIP', 20)]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the out of vocab words for each embedding\n",
    "for i in oov.keys():\n",
    "    print(i)\n",
    "    print(oov[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Feature Engineering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Count Vectorizer to build bag of word arrays to train on\n",
    "vectorizer = CountVectorizer(stop_words= 'english',\n",
    "                             ngram_range=(1,5), \n",
    "                             min_df=2)   \n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(preprocess_for_bow(df_X_train))\n",
    "X_valid_bow = vectorizer.transform(preprocess_for_bow(df_X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9958, 31422)\n",
      "(3320, 31422)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)\n",
    "print(X_valid_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Average Word Vectors per Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_avg_wv = {}\n",
    "X_valid_avg_wv = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    \n",
    "    # Adjust features based on twitter embeddings \n",
    "    if embedding == 'glove_twitter':\n",
    "        n_features = 200\n",
    "    else:\n",
    "        n_features = 300\n",
    "    \n",
    "    # Preprocess comment data\n",
    "    comments_train = preprocess_for_embed(df_X_train, embedding)\n",
    "    comments_valid = preprocess_for_embed(df_X_valid, embedding)\n",
    "    \n",
    "    # Get average embeddings for each comment\n",
    "    # train\n",
    "    X_train_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_train])\n",
    "    \n",
    "    # valid\n",
    "    X_valid_avg_wv[embedding] = np.array(\n",
    "        [get_average_embeddings(comment, embeddings[embedding], n_features)\n",
    "         for comment in comments_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 300)\n",
      "(3320, 200)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_avg_wv['w2v_base_model'].shape)\n",
    "print(X_valid_avg_wv['glove_twitter'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style = \"color:Darkblue\"> Classification Models </span>\n",
    "### Baseline Classifier - BOW | Linear SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyper Parameters for BOW | Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.02, 0.1, 0.5, 2.5, 12.5, 1]\n",
      "tol: [8e-05, 0.0004, 0.002, 0.01, 0.05, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for BOW | Linear SVC\n",
      "{'classifier': LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=2000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.05,\n",
      "     verbose=0), 'classifier__C': 0.5, 'classifier__tol': 0.05} 0.4243824061056437\n",
      "Elapsed Training time: 5454.6 s \n",
      "Elapsed Predict time: 0.1 s\n"
     ]
    }
   ],
   "source": [
    "# t_start = time.time()\n",
    "# print(\"Grid Search for BOW | Linear SVC\")\n",
    "\n",
    "# parameters = [\n",
    "#     {\n",
    "#         'classifier':[LinearSVC(max_iter=2000)],\n",
    "#         'classifier__tol': tol,\n",
    "#         'classifier__C': C,    \n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# clf1 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "# clf1.fit(X_train_bow, Y_train)\n",
    "\n",
    "# t_end_train = time.time()\n",
    "\n",
    "# print(clf1.best_params_, clf1.best_score_)\n",
    "# # Calculate and print elapsed time\n",
    "# t_end = time.time()\n",
    "# print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final BOW | Linear SVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bag of words Model with Linear SVC\n",
      "Elapsed Training time: 71.4 s \n",
      "Elapsed Predict time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Training Bag of words Model with Linear SVC\")\n",
    "\n",
    "model_bow = BinaryRelevance(\n",
    "    classifier = LinearSVC(C = 0.5, tol = 0.2)\n",
    ")\n",
    "\n",
    "model_bow.fit(X_train_bow, Y_train)\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_bow = model_bow.predict(X_valid_bow).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4512 \n",
      "Hamming Loss: 0.0721 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.112048</td>\n",
       "      <td>0.073193</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.926807</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.652482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.174096</td>\n",
       "      <td>0.043072</td>\n",
       "      <td>0.141566</td>\n",
       "      <td>0.956928</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.854812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.932229</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.432143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.089157</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.918675</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.538012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.974096</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.082229</td>\n",
       "      <td>0.065964</td>\n",
       "      <td>0.030422</td>\n",
       "      <td>0.934036</td>\n",
       "      <td>0.684982</td>\n",
       "      <td>0.584375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.075602</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.924398</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.426056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.111145</td>\n",
       "      <td>0.105723</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.894277</td>\n",
       "      <td>0.598916</td>\n",
       "      <td>0.521226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.134639</td>\n",
       "      <td>0.115060</td>\n",
       "      <td>0.050904</td>\n",
       "      <td>0.884940</td>\n",
       "      <td>0.689038</td>\n",
       "      <td>0.558984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.211145</td>\n",
       "      <td>0.071687</td>\n",
       "      <td>0.156928</td>\n",
       "      <td>0.928313</td>\n",
       "      <td>0.871612</td>\n",
       "      <td>0.805007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.108434</td>\n",
       "      <td>0.113855</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.534483</td>\n",
       "      <td>0.336957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.112048  0.073193    0.054217  0.926807   \n",
       "1     CB      0.184639         0.174096  0.043072    0.141566  0.956928   \n",
       "2    EWC      0.084337         0.056325  0.067771    0.016566  0.932229   \n",
       "3   Exec      0.103012         0.089157  0.081325    0.021687  0.918675   \n",
       "4    FWE      0.062048         0.054217  0.025904    0.036145  0.974096   \n",
       "5     SP      0.096386         0.082229  0.065964    0.030422  0.934036   \n",
       "6     RE      0.085542         0.062952  0.075602    0.009940  0.924398   \n",
       "7    Sup      0.127711         0.111145  0.105723    0.021988  0.894277   \n",
       "8     SW      0.165964         0.134639  0.115060    0.050904  0.884940   \n",
       "9   TEPE      0.228614         0.211145  0.071687    0.156928  0.928313   \n",
       "10   VMG      0.135542         0.108434  0.113855    0.021687  0.886145   \n",
       "11   OTH      0.027711         0.017470  0.026506    0.001205  0.973494   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.741935  0.652482  \n",
       "1    0.906574  0.854812  \n",
       "2    0.647059  0.432143  \n",
       "3    0.621622  0.538012  \n",
       "4    0.833333  0.728155  \n",
       "5    0.684982  0.584375  \n",
       "6    0.578947  0.426056  \n",
       "7    0.598916  0.521226  \n",
       "8    0.689038  0.558984  \n",
       "9    0.871612  0.805007  \n",
       "10   0.600000  0.480000  \n",
       "11   0.534483  0.336957  "
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, Y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_pred: (3320, 12)\n",
      "Zeros predicted: (466, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_pred:\",Y_pred_bow.shape)\n",
    "print(\"Zeros predicted:\",Y_pred_bow[Y_pred_bow.sum(axis = 1) == 0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Vectors | LogReg SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyperparameters for Avg WV | LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = (5.0**np.arange(-1,4)/10).tolist()\n",
    "# C.append(1)\n",
    "\n",
    "# tol = (5.0**np.arange(-3,2)/100).tolist()\n",
    "# tol.append(0.0001)\n",
    "\n",
    "# print('C:', C)\n",
    "# print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding in embeddings.keys():\n",
    "    \n",
    "#     print(\"Grid Search on: \", embedding)\n",
    "#     t_start = time.time()\n",
    "\n",
    "#     parameters = [\n",
    "#         {\n",
    "#             'classifier':[LogisticRegression(solver = 'lbfgs', max_iter=500)],\n",
    "#             'classifier__tol': tol,\n",
    "#             'classifier__C': C,\n",
    "        \n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     clf2 = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 2)\n",
    "#     clf2.fit(X_train_avg_wv[embedding], Y_train)\n",
    "\n",
    "#     t_end_train = time.time()\n",
    "\n",
    "#     print(clf2.best_params_, clf2.best_score_)\n",
    "#     # Calculate and print elapsed time\n",
    "#     t_end = time.time()\n",
    "#     print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "#       \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Avg WV | LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "      <th>train_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v_base_model</td>\n",
       "      <td>16.752789</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.345181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w2v_google_news</td>\n",
       "      <td>10.903381</td>\n",
       "      <td>0.129260</td>\n",
       "      <td>0.402108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fasttext_crawl</td>\n",
       "      <td>20.404690</td>\n",
       "      <td>0.119333</td>\n",
       "      <td>0.408133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fasttext_wiki</td>\n",
       "      <td>7.214360</td>\n",
       "      <td>0.103724</td>\n",
       "      <td>0.392470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glove_twitter</td>\n",
       "      <td>51.912930</td>\n",
       "      <td>0.060164</td>\n",
       "      <td>0.340964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>glove_wiki</td>\n",
       "      <td>46.241062</td>\n",
       "      <td>0.091611</td>\n",
       "      <td>0.389157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>glove_crawl</td>\n",
       "      <td>39.054376</td>\n",
       "      <td>0.114515</td>\n",
       "      <td>0.400301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding  train_time  predict_time  overall_accuracy\n",
       "0   w2v_base_model   16.752789      0.163054          0.345181\n",
       "1  w2v_google_news   10.903381      0.129260          0.402108\n",
       "2   fasttext_crawl   20.404690      0.119333          0.408133\n",
       "3    fasttext_wiki    7.214360      0.103724          0.392470\n",
       "4    glove_twitter   51.912930      0.060164          0.340964\n",
       "5       glove_wiki   46.241062      0.091611          0.389157\n",
       "6      glove_crawl   39.054376      0.114515          0.400301"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_avg_wv = {}\n",
    "model_avg_wv = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "\n",
    "    clf = BinaryRelevance(\n",
    "        classifier = LogisticRegression(solver = 'lbfgs', max_iter=500, C = 7.5,\n",
    "                                        tol = 0.05)\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train_avg_wv[embedding], Y_train)\n",
    "    t_end_train = time.time()\n",
    "\n",
    "    Y_pred_avg_wv[embedding] = clf.predict_proba(X_valid_avg_wv[embedding]) \\\n",
    "                                  .toarray()\n",
    "    model_avg_wv[embedding] = clf\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             Y_pred_avg_wv[embedding]))\n",
    "\n",
    "results_avg_wv = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                               'train_time': train_time,\n",
    "                               'predict_time': predict_time,\n",
    "                               'overall_accuracy': accuarcies})\n",
    "\n",
    "results_avg_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Build Embedding Matrices and prepare data for deep \n",
    "# learning Models\n",
    "max_words = 12000\n",
    "maxlen = 700\n",
    "\n",
    "# dictionaries for each embedding\n",
    "embedding_matrix = {}\n",
    "tokenizer = {}\n",
    "X_train_lstm = {}\n",
    "X_valid_lstm = {}\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "\n",
    "    # Preprocess text data based on embedding\n",
    "    X_train = np.array(preprocess_for_embed(df_X_train,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    X_valid = np.array(preprocess_for_embed(df_X_valid,\n",
    "                                            embedding,\n",
    "                                            split = False))\n",
    "    \n",
    "    # Tokenize and pad numbers for LSTM Model\n",
    "    tokenizer[embedding] = Tokenizer(num_words=max_words)\n",
    "    tokenizer[embedding].fit_on_texts(X_train)\n",
    "    \n",
    "    tokenized_train = tokenizer[embedding].texts_to_sequences(X_train)\n",
    "    tokenized_test = tokenizer[embedding].texts_to_sequences(X_valid)\n",
    "\n",
    "    X_train_lstm[embedding] = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "    X_valid_lstm[embedding] = pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "    \n",
    "    \n",
    "    # Build Embedding Matrices\n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "\n",
    "    word_index = tokenizer[embedding].word_index\n",
    "    \n",
    "    num_words = min(max_words, len(word_index) + 1)\n",
    "    embedding_matrix[embedding] = np.zeros((num_words, embed_size),\n",
    "                                           dtype='float32')\n",
    "\n",
    "    for word, i in word_index.items():\n",
    "\n",
    "        if i >= max_words:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            embedding_vector = embeddings[embedding][word]\n",
    "\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[embedding][i] = embedding_vector\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM on the  w2v_base_model\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 406s 48ms/step - loss: 0.3523 - acc: 0.8816 - val_loss: 0.2781 - val_acc: 0.9024\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 305s 36ms/step - loss: 0.2576 - acc: 0.9058 - val_loss: 0.2284 - val_acc: 0.9168\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 303s 36ms/step - loss: 0.2270 - acc: 0.9159 - val_loss: 0.2113 - val_acc: 0.9221\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 302s 36ms/step - loss: 0.2111 - acc: 0.9210 - val_loss: 0.2038 - val_acc: 0.9265\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 299s 35ms/step - loss: 0.2031 - acc: 0.9240 - val_loss: 0.1971 - val_acc: 0.9277\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 344s 41ms/step - loss: 0.1952 - acc: 0.9263 - val_loss: 0.1971 - val_acc: 0.9258\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 362s 43ms/step - loss: 0.1898 - acc: 0.9280 - val_loss: 0.1991 - val_acc: 0.9261\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 308s 36ms/step - loss: 0.1862 - acc: 0.9290 - val_loss: 0.1882 - val_acc: 0.9292\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 297s 35ms/step - loss: 0.1796 - acc: 0.9318 - val_loss: 0.1870 - val_acc: 0.9318\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 312s 37ms/step - loss: 0.1763 - acc: 0.9324 - val_loss: 0.1857 - val_acc: 0.9316\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 298s 35ms/step - loss: 0.1725 - acc: 0.9341 - val_loss: 0.1851 - val_acc: 0.9330\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 293s 35ms/step - loss: 0.1671 - acc: 0.9358 - val_loss: 0.1831 - val_acc: 0.9337\n",
      "Training LSTM on the  w2v_google_news\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 299s 35ms/step - loss: 0.3781 - acc: 0.8729 - val_loss: 0.2907 - val_acc: 0.8989\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 291s 34ms/step - loss: 0.2618 - acc: 0.9054 - val_loss: 0.2307 - val_acc: 0.9164\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 281s 33ms/step - loss: 0.2244 - acc: 0.9158 - val_loss: 0.2083 - val_acc: 0.9241\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 282s 33ms/step - loss: 0.2035 - acc: 0.9228 - val_loss: 0.2023 - val_acc: 0.9262\n",
      "Epoch 5/12\n",
      "8464/8464 [==============================] - 284s 34ms/step - loss: 0.1902 - acc: 0.9279 - val_loss: 0.1877 - val_acc: 0.9298\n",
      "Epoch 6/12\n",
      "8464/8464 [==============================] - 300s 35ms/step - loss: 0.1787 - acc: 0.9327 - val_loss: 0.1845 - val_acc: 0.9321\n",
      "Epoch 7/12\n",
      "8464/8464 [==============================] - 305s 36ms/step - loss: 0.1713 - acc: 0.9354 - val_loss: 0.1798 - val_acc: 0.9342\n",
      "Epoch 8/12\n",
      "8464/8464 [==============================] - 300s 36ms/step - loss: 0.1632 - acc: 0.9376 - val_loss: 0.1809 - val_acc: 0.9334\n",
      "Epoch 9/12\n",
      "8464/8464 [==============================] - 304s 36ms/step - loss: 0.1588 - acc: 0.9392 - val_loss: 0.1764 - val_acc: 0.9360\n",
      "Epoch 10/12\n",
      "8464/8464 [==============================] - 315s 37ms/step - loss: 0.1527 - acc: 0.9418 - val_loss: 0.1732 - val_acc: 0.9362\n",
      "Epoch 11/12\n",
      "8464/8464 [==============================] - 285s 34ms/step - loss: 0.1463 - acc: 0.9444 - val_loss: 0.1719 - val_acc: 0.9379\n",
      "Epoch 12/12\n",
      "8464/8464 [==============================] - 282s 33ms/step - loss: 0.1417 - acc: 0.9460 - val_loss: 0.1717 - val_acc: 0.9383\n",
      "Training LSTM on the  fasttext_crawl\n",
      "Train on 8464 samples, validate on 1494 samples\n",
      "Epoch 1/12\n",
      "8464/8464 [==============================] - 338s 40ms/step - loss: 0.3605 - acc: 0.8763 - val_loss: 0.2708 - val_acc: 0.9068\n",
      "Epoch 2/12\n",
      "8464/8464 [==============================] - 287s 34ms/step - loss: 0.2471 - acc: 0.9111 - val_loss: 0.2150 - val_acc: 0.9231\n",
      "Epoch 3/12\n",
      "8464/8464 [==============================] - 293s 35ms/step - loss: 0.2078 - acc: 0.9226 - val_loss: 0.1967 - val_acc: 0.9293\n",
      "Epoch 4/12\n",
      "8464/8464 [==============================] - 352s 42ms/step - loss: 0.1872 - acc: 0.9290 - val_loss: 0.1883 - val_acc: 0.9304\n",
      "Epoch 5/12\n",
      "5376/8464 [==================>...........] - ETA: 1:56 - loss: 0.1737 - acc: 0.9337"
     ]
    }
   ],
   "source": [
    "# Build LSTM Model and train and validate\n",
    "Y_pred_lstm = {}\n",
    "model_lstm = {}\n",
    "train_time = []\n",
    "predict_time = []\n",
    "accuarcies = []\n",
    "\n",
    "for embedding in embeddings.keys():\n",
    "    t_start = time.time()\n",
    "    print(\"Training LSTM on the \", embedding)\n",
    "    \n",
    "    if embedding == 'glove_twitter':\n",
    "        embed_size = 200\n",
    "    else:\n",
    "        embed_size = 300\n",
    "    \n",
    "    # Deep Learning Architecture\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(max_words, embed_size, \n",
    "                  weights=[embedding_matrix[embedding]], \n",
    "                  trainable=False)(inp)\n",
    "\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1,\n",
    "                          recurrent_dropout=0.1))(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=3, padding=\"valid\", \n",
    "               kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    preds = Dense(12, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, preds)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer= 'adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train and Predict Model\n",
    "    batch_size = 128\n",
    "    epochs = 12\n",
    "    model.fit(X_train_lstm[embedding],\n",
    "              Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs, \n",
    "              validation_split=0.15)\n",
    "    t_end_train = time.time()\n",
    "    \n",
    "    Y_pred_lstm[embedding] = model.predict(X_valid_lstm[embedding])\n",
    "    model_lstm[embedding] = model\n",
    "\n",
    "    # Calculate and report results\n",
    "    t_end = time.time()\n",
    "    train_time.append(t_end_train - t_start)\n",
    "    predict_time.append(t_end - t_end_train)\n",
    "    \n",
    "    accuarcies.append(metrics.accuracy_score(Y_valid,\n",
    "                                             np.round(Y_pred_lstm[embedding])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lstm = pd.DataFrame({'embedding': list(embeddings.keys()),\n",
    "                             'train_time': train_time,\n",
    "                             'predict_time': predict_time,\n",
    "                             'overall_accuracy': accuarcies})\n",
    "\n",
    "results_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.491 \n",
      "Hamming Loss: 0.0653 \n",
      "Hamming Loss (pred. zeros): 0.1191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.127410</td>\n",
       "      <td>0.100301</td>\n",
       "      <td>0.065663</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.934337</td>\n",
       "      <td>0.807808</td>\n",
       "      <td>0.635934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.184639</td>\n",
       "      <td>0.176205</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.146084</td>\n",
       "      <td>0.961446</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.872757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.937048</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.346429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>0.098494</td>\n",
       "      <td>0.079217</td>\n",
       "      <td>0.023795</td>\n",
       "      <td>0.920783</td>\n",
       "      <td>0.620795</td>\n",
       "      <td>0.593567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.062048</td>\n",
       "      <td>0.056928</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>0.977410</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.776699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.068072</td>\n",
       "      <td>0.062651</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.937349</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.528125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.051506</td>\n",
       "      <td>0.070181</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.929819</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.390845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.106627</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.893373</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.613208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.165964</td>\n",
       "      <td>0.111747</td>\n",
       "      <td>0.098795</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.901205</td>\n",
       "      <td>0.800539</td>\n",
       "      <td>0.539020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.212349</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.171988</td>\n",
       "      <td>0.943373</td>\n",
       "      <td>0.904965</td>\n",
       "      <td>0.840580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.135542</td>\n",
       "      <td>0.113253</td>\n",
       "      <td>0.093373</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.906627</td>\n",
       "      <td>0.686170</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.973494</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.097826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.127410         0.100301  0.065663    0.061747  0.934337   \n",
       "1     CB      0.184639         0.176205  0.038554    0.146084  0.961446   \n",
       "2    EWC      0.084337         0.037048  0.062952    0.021386  0.937048   \n",
       "3   Exec      0.103012         0.098494  0.079217    0.023795  0.920783   \n",
       "4    FWE      0.062048         0.056928  0.022590    0.039458  0.977410   \n",
       "5     SP      0.096386         0.068072  0.062651    0.033735  0.937349   \n",
       "6     RE      0.085542         0.051506  0.070181    0.015361  0.929819   \n",
       "7    Sup      0.127711         0.135542  0.106627    0.021084  0.893373   \n",
       "8     SW      0.165964         0.111747  0.098795    0.067169  0.901205   \n",
       "9   TEPE      0.228614         0.212349  0.056627    0.171988  0.943373   \n",
       "10   VMG      0.135542         0.113253  0.093373    0.042169  0.906627   \n",
       "11   OTH      0.027711         0.004217  0.026506    0.001205  0.973494   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.807808  0.635934  \n",
       "1    0.914530  0.872757  \n",
       "2    0.788618  0.346429  \n",
       "3    0.620795  0.593567  \n",
       "4    0.846561  0.776699  \n",
       "5    0.747788  0.528125  \n",
       "6    0.649123  0.390845  \n",
       "7    0.577778  0.613208  \n",
       "8    0.800539  0.539020  \n",
       "9    0.904965  0.840580  \n",
       "10   0.686170  0.573333  \n",
       "11   0.642857  0.097826  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid, np.round(Y_pred_lstm['fasttext_crawl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3320, 12)\n",
      "(3320, 84)\n",
      "(3320, 84)\n",
      "(3320, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3320, 197)"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacked predictions of various models\n",
    "X_train_stack_wv = np.hstack(tuple(Y_pred_avg_wv.values()))\n",
    "X_train_stack_lstm = np.hstack(tuple(Y_pred_lstm.values()))\n",
    "X_train_stack_bow = Y_pred_bow\n",
    "\n",
    "X_train_stack = np.hstack((X_train_stack_bow,\n",
    "                           X_train_stack_wv,\n",
    "                           X_train_stack_lstm,\n",
    "                           X_valid_quant))\n",
    "\n",
    "# Shapes of each model\n",
    "print(X_train_stack_bow.shape)\n",
    "print(X_train_stack_lstm.shape)\n",
    "print(X_train_stack_wv.shape)\n",
    "print(X_valid_quant.shape)\n",
    "\n",
    "X_train_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta, X_valid_meta, Y_train_meta, Y_valid_meta = train_test_split(\n",
    "    X_train_stack, Y_valid, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2324, 197)\n",
      "(996, 197)\n",
      "(2324, 12)\n",
      "(996, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_meta.shape)\n",
    "print(X_valid_meta.shape)\n",
    "print(Y_train_meta.shape)\n",
    "print(Y_valid_meta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Hyper Parameters of Stacking | LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: [0.02, 0.1, 0.5, 2.5, 12.5, 1]\n",
      "tol: [8e-05, 0.0004, 0.002, 0.01, 0.05, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "C = [0.25, 0.5, 0.75, 1]\n",
    "C.append(1)\n",
    "\n",
    "tol = [0.005, 0.01, 0.02, 0.05]\n",
    "tol.append(0.0001)\n",
    "\n",
    "print('C:', C)\n",
    "print('tol:', tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Stack\n",
      "{'classifier': LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
      "          tol=0.01, verbose=0, warm_start=False), 'classifier__C': 0.5, 'classifier__penalty': 'l1', 'classifier__tol': 0.01} 0.5266781411359724\n",
      "Elapsed Training time: 449.0 s \n",
      "Elapsed Predict time: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Grid Search for stacked LogReg\")\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'classifier':[LogisticRegression(solver = 'liblinear', max_iter=500,\n",
    "                                         penalty = 'l1')],\n",
    "        'classifier__tol': tol,\n",
    "        'classifier__C': C,\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(BinaryRelevance(), parameters, scoring = 'accuracy', cv = 3)\n",
    "clf.fit(X_train_meta, Y_train_meta)\n",
    "\n",
    "t_end_train = time.time()\n",
    "\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Stack\n",
      "Elapsed Training time: 3.9 s \n",
      "Elapsed Predict time: 0.1 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "print(\"Training on Stack\")\n",
    "\n",
    "model_stack = BinaryRelevance(\n",
    "    classifier = LogisticRegression(penalty='l1', solver='liblinear', C = 0.5, tol = 0.01)\n",
    ")\n",
    "\n",
    "model_stack.fit(X_train_meta, Y_train_meta)\n",
    "\n",
    "t_end_train = time.time()\n",
    "\n",
    "Y_pred_stack = model_stack.predict_proba(X_valid_meta).toarray()\n",
    "\n",
    "# Calculate and print elapsed time\n",
    "t_end = time.time()\n",
    "print(\"Elapsed Training time: %.1f s\" % (t_end_train - t_start),\n",
    "      \"\\nElapsed Predict time: %.1f s\" % (t_end - t_end_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.5291 \n",
      "Hamming Loss: 0.0582 \n",
      "Hamming Loss (pred. zeros): 0.1166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.124498</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>0.061245</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.938755</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.179719</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.145582</td>\n",
       "      <td>0.965863</td>\n",
       "      <td>0.896175</td>\n",
       "      <td>0.916201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.087349</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>0.057229</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.942771</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.436782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.080321</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.941767</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.619565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>0.040161</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.094378</td>\n",
       "      <td>0.071285</td>\n",
       "      <td>0.049197</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.950803</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.617021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.079317</td>\n",
       "      <td>0.044177</td>\n",
       "      <td>0.059237</td>\n",
       "      <td>0.020080</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.405063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>0.098394</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>0.910643</td>\n",
       "      <td>0.683673</td>\n",
       "      <td>0.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.158635</td>\n",
       "      <td>0.124498</td>\n",
       "      <td>0.098394</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.233936</td>\n",
       "      <td>0.218876</td>\n",
       "      <td>0.059237</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.940763</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.841202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.095382</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.918675</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.974900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.124498         0.105422  0.061245    0.063253  0.938755   \n",
       "1     CB      0.179719         0.183735  0.034137    0.145582  0.965863   \n",
       "2    EWC      0.087349         0.046185  0.057229    0.030120  0.942771   \n",
       "3   Exec      0.092369         0.080321  0.058233    0.034137  0.941767   \n",
       "4    FWE      0.066265         0.052209  0.026104    0.040161  0.973896   \n",
       "5     SP      0.094378         0.071285  0.049197    0.045181  0.950803   \n",
       "6     RE      0.079317         0.044177  0.059237    0.020080  0.940763   \n",
       "7    Sup      0.125502         0.098394  0.089357    0.036145  0.910643   \n",
       "8     SW      0.158635         0.124498  0.098394    0.060241  0.901606   \n",
       "9   TEPE      0.233936         0.218876  0.059237    0.174699  0.940763   \n",
       "10   VMG      0.126506         0.095382  0.081325    0.045181  0.918675   \n",
       "11   OTH      0.031124         0.010040  0.025100    0.006024  0.974900   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.800000  0.677419  \n",
       "1    0.896175  0.916201  \n",
       "2    0.826087  0.436782  \n",
       "3    0.712500  0.619565  \n",
       "4    0.884615  0.696970  \n",
       "5    0.816901  0.617021  \n",
       "6    0.727273  0.405063  \n",
       "7    0.683673  0.536000  \n",
       "8    0.741935  0.582278  \n",
       "9    0.899083  0.841202  \n",
       "10   0.736842  0.555556  \n",
       "11   0.800000  0.258065  "
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_results(Y_valid_meta, np.round(Y_pred_stack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the Precision! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.4167 \n",
      "Hamming Loss: 0.0709 \n",
      "Hamming Loss (pred. zeros): 0.1166\n",
      "Total comments: 996 \n",
      "Total Predictions: 629 \n",
      "Percent Pred non-zero: 0.6315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.124498</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.179719</td>\n",
       "      <td>0.156627</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.134538</td>\n",
       "      <td>0.954819</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.810056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.087349</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.071285</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.229885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.070281</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.929719</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.293478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.066265</td>\n",
       "      <td>0.044177</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>0.034137</td>\n",
       "      <td>0.967871</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.094378</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>0.071285</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.287234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.079317</td>\n",
       "      <td>0.014056</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.930723</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.151899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.125502</td>\n",
       "      <td>0.028112</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>0.896586</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.158635</td>\n",
       "      <td>0.057229</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.886546</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.322785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.233936</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.160643</td>\n",
       "      <td>0.926707</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.729614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.029116</td>\n",
       "      <td>0.099398</td>\n",
       "      <td>0.027108</td>\n",
       "      <td>0.900602</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.031124</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.976908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.124498         0.058233  0.078313    0.046185  0.921687   \n",
       "1     CB      0.179719         0.156627  0.045181    0.134538  0.954819   \n",
       "2    EWC      0.087349         0.024096  0.071285    0.016064  0.928715   \n",
       "3   Exec      0.092369         0.032129  0.070281    0.022088  0.929719   \n",
       "4    FWE      0.066265         0.044177  0.032129    0.034137  0.967871   \n",
       "5     SP      0.094378         0.031124  0.071285    0.023092  0.928715   \n",
       "6     RE      0.079317         0.014056  0.069277    0.010040  0.930723   \n",
       "7    Sup      0.125502         0.028112  0.103414    0.022088  0.896586   \n",
       "8     SW      0.158635         0.057229  0.113454    0.045181  0.886546   \n",
       "9   TEPE      0.233936         0.180723  0.073293    0.160643  0.926707   \n",
       "10   VMG      0.126506         0.029116  0.099398    0.027108  0.900602   \n",
       "11   OTH      0.031124         0.008032  0.023092    0.008032  0.976908   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.896552  0.419355  \n",
       "1    0.929487  0.810056  \n",
       "2    0.833333  0.229885  \n",
       "3    0.843750  0.293478  \n",
       "4    0.886364  0.590909  \n",
       "5    0.870968  0.287234  \n",
       "6    0.857143  0.151899  \n",
       "7    0.892857  0.200000  \n",
       "8    0.894737  0.322785  \n",
       "9    0.944444  0.729614  \n",
       "10   0.965517  0.222222  \n",
       "11   1.000000  0.258065  "
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.round(Y_pred_stack - 0.40)\n",
    "#predictions = np.round(Y_pred_lstm['fasttext_crawl']-0.495)\n",
    "\n",
    "a = theme_results(Y_valid_meta, predictions)\n",
    "size = predictions.shape[0]\n",
    "zero_size = (predictions[predictions.sum(axis = 1) == 0,:].shape[0])\n",
    "print(\"Total comments:\", size, \n",
    "      \"\\nTotal Predictions:\", size - zero_size, \n",
    "      \"\\nPercent Pred non-zero:\", round(1 - zero_size/size, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.6486 \n",
      "Hamming Loss: 0.0441 \n",
      "Hamming Loss (pred. zeros): 0.1166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Y_proportion</th>\n",
       "      <th>Pred_proportion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Dummy_Diff</th>\n",
       "      <th>Accuarcy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPD</td>\n",
       "      <td>0.125596</td>\n",
       "      <td>0.092210</td>\n",
       "      <td>0.052464</td>\n",
       "      <td>0.073132</td>\n",
       "      <td>0.947536</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CB</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>0.213037</td>\n",
       "      <td>0.963434</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.923567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EWC</td>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.038156</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.963434</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exec</td>\n",
       "      <td>0.066773</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.968203</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWE</td>\n",
       "      <td>0.085851</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.968203</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP</td>\n",
       "      <td>0.095390</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RE</td>\n",
       "      <td>0.060413</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.955485</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sup</td>\n",
       "      <td>0.095390</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>0.060413</td>\n",
       "      <td>0.034976</td>\n",
       "      <td>0.939587</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SW</td>\n",
       "      <td>0.146264</td>\n",
       "      <td>0.090620</td>\n",
       "      <td>0.074722</td>\n",
       "      <td>0.071542</td>\n",
       "      <td>0.925278</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.554348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEPE</td>\n",
       "      <td>0.305246</td>\n",
       "      <td>0.286169</td>\n",
       "      <td>0.050874</td>\n",
       "      <td>0.254372</td>\n",
       "      <td>0.949126</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VMG</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>0.046105</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.042925</td>\n",
       "      <td>0.958665</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OTH</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.990461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Y_proportion  Pred_proportion     Error  Dummy_Diff  Accuarcy  \\\n",
       "0    CPD      0.125596         0.092210  0.052464    0.073132  0.947536   \n",
       "1     CB      0.249603         0.248013  0.036566    0.213037  0.963434   \n",
       "2    EWC      0.062003         0.038156  0.036566    0.025437  0.963434   \n",
       "3   Exec      0.066773         0.050874  0.031797    0.034976  0.968203   \n",
       "4    FWE      0.085851         0.069952  0.031797    0.054054  0.968203   \n",
       "5     SP      0.095390         0.049285  0.058824    0.036566  0.941176   \n",
       "6     RE      0.060413         0.022258  0.044515    0.015898  0.955485   \n",
       "7    Sup      0.095390         0.044515  0.060413    0.034976  0.939587   \n",
       "8     SW      0.146264         0.090620  0.074722    0.071542  0.925278   \n",
       "9   TEPE      0.305246         0.286169  0.050874    0.254372  0.949126   \n",
       "10   VMG      0.084261         0.046105  0.041335    0.042925  0.958665   \n",
       "11   OTH      0.022258         0.012719  0.009539    0.012719  0.990461   \n",
       "\n",
       "    Precision    Recall  \n",
       "0    0.896552  0.658228  \n",
       "1    0.929487  0.923567  \n",
       "2    0.833333  0.512821  \n",
       "3    0.843750  0.642857  \n",
       "4    0.886364  0.722222  \n",
       "5    0.870968  0.450000  \n",
       "6    0.857143  0.315789  \n",
       "7    0.892857  0.416667  \n",
       "8    0.894737  0.554348  \n",
       "9    0.944444  0.885417  \n",
       "10   0.965517  0.528302  \n",
       "11   1.000000  0.571429  "
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_pred = predictions[predictions.sum(axis = 1) != 0,:]\n",
    "non_zero_valid = Y_valid_meta[predictions.sum(axis = 1) != 0,:]\n",
    "\n",
    "theme_results(non_zero_valid, non_zero_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
